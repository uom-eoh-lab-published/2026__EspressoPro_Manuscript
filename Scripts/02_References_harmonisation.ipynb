{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "script_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "parent_dir = os.path.dirname(script_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata\n",
    "import cellhint\n",
    "import harmonypy as hm\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import espressopro as ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading custom scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_labels(dataset, reduction, n_neighbors, label_input, label_output, frequency_threshold):\n",
    "    # Compute the neighborhood graph\n",
    "    sc.pp.neighbors(dataset, use_rep=reduction, n_neighbors=n_neighbors)\n",
    "\n",
    "    # Perform the clustering\n",
    "    sc.tl.leiden(dataset, key_added='clusters', resolution=10)\n",
    "\n",
    "    # Initialize the new column with the existing labels\n",
    "    dataset.obs[label_output] = dataset.obs[label_input]\n",
    "\n",
    "    # For each cluster, find the most frequent label and assign it to all cells in the cluster\n",
    "    for cluster in dataset.obs['clusters'].unique():\n",
    "        cluster_labels = dataset.obs.loc[dataset.obs['clusters'] == cluster, label_input]\n",
    "        most_frequent_label = cluster_labels.mode()[0]\n",
    "        frequency = (cluster_labels == most_frequent_label).mean()\n",
    "\n",
    "        if frequency > frequency_threshold:\n",
    "            dataset.obs.loc[dataset.obs['clusters'] == cluster, label_output] = most_frequent_label\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_obs_mean(adata, group_key, layer=None, gene_symbols=None):\n",
    "    if layer is not None:\n",
    "        getX = lambda x: x.layers[layer]\n",
    "    else:\n",
    "        getX = lambda x: x.X\n",
    "    if gene_symbols is not None:\n",
    "        new_idx = adata.var[idx]\n",
    "    else:\n",
    "        new_idx = adata.var_names\n",
    "\n",
    "    grouped = adata.obs.groupby(group_key)\n",
    "    out = pd.DataFrame(\n",
    "        np.zeros((adata.shape[1], len(grouped)), dtype=np.float64),\n",
    "        columns=list(grouped.groups.keys()),\n",
    "        index=adata.var_names\n",
    "    )\n",
    "\n",
    "    for group, idx in grouped.indices.items():\n",
    "        X = getX(adata[idx])\n",
    "        out[group] = np.ravel(X.mean(axis=0, dtype=np.float64))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(parent_dir + '/Scripts/SingleCellUtils')\n",
    "\n",
    "import SCUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PYTHONHASHSEED was set as envinronmental variable to 0 as follows:\n",
    "    \n",
    "conda env config vars set PYTHONHASHSEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_pythonhashseed(seed=0):\n",
    "    current_seed = os.environ.get(\"PYTHONHASHSEED\")\n",
    "\n",
    "    seed = str(seed)\n",
    "    if current_seed is None or current_seed != seed:\n",
    "        print(f'Setting PYTHONHASHSEED=\"{seed}\"')\n",
    "        os.environ[\"PYTHONHASHSEED\"] = seed\n",
    "        # restart the current process\n",
    "        os.execl(sys.executable, sys.executable, *sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "hash = random.getrandbits(128)\n",
    "\n",
    "print(\"hash value: %032x\" % hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder path\n",
    "data_path = parent_dir + \"/Data\"\n",
    "figures_path = parent_dir + \"/Figures/Label_Harmonisation\"\n",
    "\n",
    "if not os.path.exists(figures_path):\n",
    "    os.makedirs(figures_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Zhang X. et al. (2024) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zhang_dataset = sc.read_h5ad(data_path + '/References/Zhang' + '/adata_combined_rna_adt_annotated-titrated.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zhang_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zhang_dataset.obsm['X_umap'] = Zhang_dataset.obsm['X_umap'].values\n",
    "Zhang_dataset.obsm['X_umap-titration'] = Zhang_dataset.obsm['X_umap-titration'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Zhang_dataset, \n",
    "                color='Level 3 Multimodal', \n",
    "                basis='X_umap', \n",
    "                legend_loc='right margin', \n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(4.5, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Zhang X. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Original annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Place the legend below the plot\n",
    "legend = ax.legend(loc='upper center', \n",
    "                   bbox_to_anchor=(0.5, -0.05),\n",
    "                   prop={'size': 4.8},\n",
    "                   ncol=5)\n",
    "\n",
    "# Reduce the size of the dots in the legend\n",
    "for handle in legend.legend_handles:\n",
    "    handle._sizes = [10]\n",
    "\n",
    "# Adjust the layout to make room for the legend\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/01_ZhangX_original_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_keep = [\n",
    "    'CD230', 'Hu.C5L2', 'Hu.CD10', 'Hu.CD101', 'Hu.CD102', 'Hu.CD103', 'Hu.CD105_43A3', 'Hu.CD106', 'Hu.CD109', 'Hu.CD110', \n",
    "    'Hu.CD112', 'Hu.CD115', 'Hu.CD116', 'Hu.CD117', 'Hu.CD119', 'Hu.CD11a', 'Hu.CD11b', 'Hu.CD11c', 'Hu.CD123', 'Hu.CD127', \n",
    "    'Hu.CD13', 'Hu.CD133_S16016B', 'Hu.CD135', 'Hu.CD138_DL.101', 'Hu.CD140b', 'Hu.CD141', 'Hu.CD14_M5E2', 'Hu.CD150', 'Hu.CD151', \n",
    "    'Hu.CD154', 'Hu.CD155', 'Hu.CD158e1', 'Hu.CD158f', 'Hu.CD15_W6D3', 'Hu.CD16', 'Hu.CD162', 'Hu.CD163', 'Hu.CD164', 'Hu.CD172a', \n",
    "    'Hu.CD177', 'Hu.CD18', 'Hu.CD183', 'Hu.CD185', 'Hu.CD186', 'Hu.CD19', 'Hu.CD192', 'Hu.CD1a', 'Hu.CD1d', 'Hu.CD2', 'Hu.CD200', \n",
    "    'Hu.CD201', 'Hu.CD202b', 'Hu.CD205', 'Hu.CD226_TX25', 'Hu.CD235a', 'Hu.CD24', 'Hu.CD25', 'Hu.CD26', 'Hu.CD27', 'Hu.CD271', \n",
    "    'Hu.CD274', 'Hu.CD279', 'Hu.CD28', 'Hu.CD29', 'Hu.CD304', 'Hu.CD305_LAIR1', 'Hu.CD309', 'Hu.CD32', 'Hu.CD325', 'Hu.CD326', \n",
    "    'Hu.CD33', 'Hu.CD335', 'Hu.CD34', 'Hu.CD35', 'Hu.CD354', 'Hu.CD36', 'Hu.CD366', 'Hu.CD37', 'Hu.CD38_HIT2', 'Hu.CD41', 'Hu.CD42b', \n",
    "    'Hu.CD43', 'Hu.CD45RA', 'Hu.CD45RB', 'Hu.CD45RO', 'Hu.CD45_2D1', 'Hu.CD47', 'Hu.CD49b', 'Hu.CD4_RPA.T4', 'Hu.CD5', 'Hu.CD52', \n",
    "    'Hu.CD54', 'Hu.CD55', 'Hu.CD56', 'Hu.CD57', 'Hu.CD58', 'Hu.CD59', 'Hu.CD61', 'Hu.CD62L', 'Hu.CD62P', 'Hu.CD63', 'Hu.CD64', \n",
    "    'Hu.CD69', 'Hu.CD7', 'Hu.CD71', 'Hu.CD72', 'Hu.CD73', 'Hu.CD8', 'Hu.CD81', 'Hu.CD82', 'Hu.CD83', 'Hu.CD84', 'Hu.CD85g', 'Hu.CD9', \n",
    "    'Hu.CD90', 'Hu.CD93', 'Hu.CD98', 'Hu.CLEC1B', 'Hu.Cadherin.11', 'Hu.FR.b', 'Hu.FceRIa', 'Hu.GARP', 'Hu.GPR56', 'Hu.Galectin.9', \n",
    "    'Hu.HLA.ABC', 'Hu.HLA.DR.DP.DQ', 'Hu.KLRG1', 'Hu.TIM.4', 'Hu.TSPAN33', 'HuMs.CD44', 'HuMs.CD49f', 'HuMs.integrin.b7', \n",
    "    'Isotype_G0114F7', 'Isotype_HTK888', 'Isotype_MOPC.173', 'Isotype_MOPC.21', 'Isotype_MPC.11', 'Isotype_RTK2071', 'Isotype_RTK2758', \n",
    "    'Isotype_RTK4174', 'Isotype_RTK4530', 'Hu.IgG.Fc'\n",
    "]\n",
    "\n",
    "vars_to_keep = np.in1d(Zhang_dataset.var_names, vars_to_keep)\n",
    "Zhang_dataset = Zhang_dataset[:, vars_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zhang_dataset_adt_rename(dataset):\n",
    "    dataset.var.rename(index=lambda x: x.replace('Hu.', '').replace('HuMs.', ''), inplace=True)\n",
    "    dataset.var.rename(index={'FceRIa': 'FcεRIα'}, inplace=True)\n",
    "    dataset.var.rename(index={'CD4_RPA.T4': 'CD4'}, inplace=True)\n",
    "    dataset.var.rename(index={'CD45_2D1': 'CD45'}, inplace=True)\n",
    "    dataset.var.rename(index={'CD38_HIT2': 'CD38'}, inplace=True)\n",
    "    dataset.var.rename(index={'CD305_LAIR1': 'CD305'}, inplace=True)\n",
    "    dataset.var.rename(index={'CD226_TX25': 'CD226'}, inplace=True)\n",
    "    dataset.var.rename(index={'CD15_W6D3': 'CD15'}, inplace=True)\n",
    "    dataset.var.rename(index={'CD14_M5E2': 'CD14'}, inplace=True)\n",
    "    dataset.var.rename(index={'CD138_DL.101': 'CD138'}, inplace=True)\n",
    "    dataset.var.rename(index={'CD133_S16016B': 'CD133'}, inplace=True)\n",
    "    dataset.var.rename(index={'CD105_43A3': 'CD105'}, inplace=True)\n",
    "\n",
    "zhang_dataset_adt_rename(Zhang_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF21_CD34 = sc.read_10x_h5(data_path + '/References/Zhang' + '/GSE245108_BF21-CD34_filtered_feature_bc_matrix.h5', gex_only=False)[:, vars_to_keep]\n",
    "BF21_CD271 = sc.read_10x_h5(data_path + '/References/Zhang' + '/GSE245108_BF21-CD271_filtered_feature_bc_matrix.h5', gex_only=False)[:, vars_to_keep]\n",
    "BF21_TNC = sc.read_10x_h5(data_path + '/References/Zhang' + '/GSE245108_BF21-TNC_filtered_feature_bc_matrix.h5', gex_only=False)[:, vars_to_keep]\n",
    "\n",
    "WF26_CD34 = sc.read_10x_h5(data_path + '/References/Zhang' + '/GSE245108_WF26-CD34_filtered_feature_bc_matrix.h5', gex_only=False)[:, vars_to_keep]\n",
    "WF26_CD271 = sc.read_10x_h5(data_path + '/References/Zhang' + '/GSE245108_WF26-CD271_filtered_feature_bc_matrix.h5', gex_only=False)[:, vars_to_keep]\n",
    "WF26_TNC = sc.read_10x_h5(data_path + '/References/Zhang' + '/GSE245108_WF26-TNC_filtered_feature_bc_matrix.h5', gex_only=False)[:, vars_to_keep]\n",
    "\n",
    "BM27_CD34 = sc.read_10x_h5(data_path + '/References/Zhang' + '/GSE245108_BM27-CD34_filtered_feature_bc_matrix.h5', gex_only=False)[:, vars_to_keep]\n",
    "BM27_CD271 = sc.read_10x_h5(data_path + '/References/Zhang' + '/GSE245108_BM27-CD271_filtered_feature_bc_matrix.h5', gex_only=False)[:, vars_to_keep]\n",
    "BM27_TNC = sc.read_10x_h5(data_path + '/References/Zhang' + '/GSE245108_BM27-TNC_filtered_feature_bc_matrix.h5', gex_only=False)[:, vars_to_keep]\n",
    "\n",
    "WM34_CD34 = sc.read_10x_h5(data_path + '/References/Zhang' + '/GSE245108_WM34-CD34_filtered_feature_bc_matrix.h5', gex_only=False)[:, vars_to_keep]\n",
    "WM34_CD271 = sc.read_10x_h5(data_path + '/References/Zhang' + '/GSE245108_WM34-CD271_filtered_feature_bc_matrix.h5', gex_only=False)[:, vars_to_keep]\n",
    "WM34_TNC = sc.read_10x_h5(data_path + '/References/Zhang' + '/GSE245108_WM34-TNC_filtered_feature_bc_matrix.h5', gex_only=False)[:, vars_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhang_dataset_adt_rename(BF21_CD34)\n",
    "zhang_dataset_adt_rename(BF21_CD271)\n",
    "zhang_dataset_adt_rename(BF21_TNC)\n",
    "\n",
    "zhang_dataset_adt_rename(WF26_CD34)\n",
    "zhang_dataset_adt_rename(WF26_CD271)\n",
    "zhang_dataset_adt_rename(WF26_TNC)\n",
    "\n",
    "zhang_dataset_adt_rename(BM27_CD34)\n",
    "zhang_dataset_adt_rename(BM27_CD271)\n",
    "zhang_dataset_adt_rename(BM27_TNC)\n",
    "\n",
    "zhang_dataset_adt_rename(WM34_CD34)\n",
    "zhang_dataset_adt_rename(WM34_CD271)\n",
    "zhang_dataset_adt_rename(WM34_TNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF21_CD34.obs_names = BF21_CD34.obs_names + '.BF21_032123_CD34'\n",
    "BF21_CD271.obs_names = BF21_CD271.obs_names + '.BF21_032123_CD271'\n",
    "BF21_TNC.obs_names = BF21_TNC.obs_names + '.BF21_032123_TNC'\n",
    "\n",
    "WF26_CD34.obs_names = WF26_CD34.obs_names + '.WF26_031423_CD34'\n",
    "WF26_CD271.obs_names = WF26_CD271.obs_names + '.WF26_031423_CD271'\n",
    "WF26_TNC.obs_names = WF26_TNC.obs_names + '.WF26_031423_TNC'\n",
    "\n",
    "BM27_CD34.obs_names = BM27_CD34.obs_names + '.BM27_120522_CD34'\n",
    "BM27_CD271.obs_names = BM27_CD271.obs_names + '.BM27_120522_CD271'\n",
    "BM27_TNC.obs_names = BM27_TNC.obs_names + '.BM27_120522_TNC'\n",
    "\n",
    "WM34_CD34.obs_names = WM34_CD34.obs_names + '.WM34_120522_CD34'\n",
    "WM34_CD271.obs_names = WM34_CD271.obs_names + '.WM34_120522_CD271'\n",
    "WM34_TNC.obs_names = WM34_TNC.obs_names + '.WM34_120522_TNC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WM34_CD34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_adata = anndata.concat([BF21_CD34, BF21_CD271, BF21_TNC,\n",
    "                               WF26_CD34, WF26_CD271, WF26_TNC,\n",
    "                               BM27_CD34, BM27_CD271, BM27_TNC,\n",
    "                               WM34_CD34, WM34_CD271, WM34_TNC], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_to_keep = np.in1d(merged_adata.obs_names, Zhang_dataset.obs_names)\n",
    "merged_adata = merged_adata[obs_to_keep,:]\n",
    "merged_adata = merged_adata[Zhang_dataset.obs_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zhang_dataset.X = merged_adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zhang_dataset.obs['Batch'] = Zhang_dataset.obs['sample'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zhang_dataset.obs['Chemistry'] = 'BioLegend TotalSeqA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Hao Y. et al. (2021) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hao_dataset = sc.read_h5ad(data_path + \"/References/Hao\" + \"/228AB_healthy_donors_PBMNCs.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hao_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Hao_dataset, \n",
    "                color='celltype.l3', \n",
    "                basis='X_wnn.umap', \n",
    "                legend_loc='right margin', \n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(4.5, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Hao Y. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Original annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Place the legend below the plot\n",
    "legend = ax.legend(loc='upper center', \n",
    "                   bbox_to_anchor=(0.5, -0.05),\n",
    "                   prop={'size': 4.8},\n",
    "                   ncol=5)\n",
    "\n",
    "# Reduce the size of the dots in the legend\n",
    "for handle in legend.legend_handles:\n",
    "    handle._sizes = [10]\n",
    "\n",
    "# Adjust the layout to make room for the legend\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/02_HaoY_original_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_to_drop = np.in1d(Hao_dataset.var_names, SCUtils.Filter_duplicate_vars(Hao_dataset))\n",
    "Hao_dataset = Hao_dataset[:, ~var_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hao_dataset.obs['Chemistry'] = 'BioLegend TotalSeqA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hao_dataset.obs['Batch'] = Hao_dataset.obs['donor'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Triana S. et al. (2021) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Triana_dataset = sc.read_h5ad(data_path + \"/References/Triana\" + \"/97AB_young_and_old_adult_healthy_donor_BMMNCs.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Triana_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='CellTypes', \n",
    "                basis='X_mofaumap', \n",
    "                legend_loc='right margin', \n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(5.5, 5.5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Triana S. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Original annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Place the legend below the plot\n",
    "legend = ax.legend(loc='upper center', \n",
    "                   bbox_to_anchor=(0.5, -0.05),\n",
    "                   prop={'size': 4.8},\n",
    "                   ncol=3)\n",
    "\n",
    "# Reduce the size of the dots in the legend\n",
    "for handle in legend.legend_handles:\n",
    "    handle._sizes = [10]\n",
    "\n",
    "# Adjust the layout to make room for the legend\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/03_TrianaS_original_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining used chemistry as metadata to use for interdatasets integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Triana_dataset.obs['Chemistry'] = 'BD AbSeq'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming feature labels to match across datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Triana_dataset.var.rename(index={'HLA.DR': 'HLA-DR'}, inplace=True)\n",
    "Triana_dataset.var.rename(index={'FCER1A': 'FcεRIα'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Luecken M.D. et al. (2021) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Luecken_dataset = sc.read_h5ad(data_path + \"/References/Luecken\" + \"/140AB_adult_healthy_donor_BMMNCs.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt = Luecken_dataset.var['feature_types'] == 'ADT'\n",
    "Luecken_dataset = Luecken_dataset[:, adt]\n",
    "Luecken_dataset.X = Luecken_dataset.layers['counts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Luecken_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Luecken_dataset.obs['Batch'] = Luecken_dataset.obs['batch'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are computing new embeddings as the original embeddings are not clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "from scipy.sparse import issparse\n",
    "import numpy as np\n",
    "import harmonypy as hm\n",
    "\n",
    "adata = Luecken_dataset.copy()\n",
    "\n",
    "# Normalize in-place on AnnData so you don't lose structure\n",
    "ep.Normalise_protein_data(adata, inplace=True, axis=1, flavor=\"seurat\")\n",
    "\n",
    "ep.Scale_protein_data(adata, inplace=True)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# PCA (cells x PCs)\n",
    "sc.tl.pca(adata, n_comps=30, svd_solver=\"arpack\")\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Harmony expects PCs x cells\n",
    "Z = np.asarray(adata.obsm[\"X_pca\"].T, dtype=np.float64)\n",
    "\n",
    "ho = hm.run_harmony(Z, adata.obs, [\"Batch\"], max_iter_harmony=30, random_state=42)\n",
    "\n",
    "# Corrected PCs back to (cells x PCs)\n",
    "adata.obsm[\"X_pcahm\"] = ho.Z_corr.T\n",
    "\n",
    "Luecken_dataset.obsm['X_pcahm'] = adata.obsm['X_pcahm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.pp.neighbors(Luecken_dataset, n_neighbors=30, n_pcs=13, use_rep=\"X_pcahm\", random_state = 42)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.tl.umap(Luecken_dataset, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Luecken_dataset, \n",
    "                color='cell_type', \n",
    "                basis='X_umap', \n",
    "                legend_loc='right margin', \n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(5, 5.5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Luecken M.D. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Original annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Place the legend below the plot\n",
    "legend = ax.legend(loc='upper center', \n",
    "                   bbox_to_anchor=(0.5, -0.05),\n",
    "                   prop={'size': 4.8},\n",
    "                   ncol=4)\n",
    "\n",
    "# Reduce the size of the dots in the legend\n",
    "for handle in legend.legend_handles:\n",
    "    handle._sizes = [10]\n",
    "\n",
    "# Adjust the layout to make room for the legend\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/04_LueckenMD_original_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Luecken_dataset.obs['Chemistry'] = 'BioLegend TotalSeqB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Luecken_dataset.var.rename(index={'FceRIa': 'FcεRIα'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label harmonisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All cellular types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = pd.Categorical(np.concatenate((Zhang_dataset.obs['Level 3 Multimodal'].values, \n",
    "                                                 Hao_dataset.obs['celltype.l3'].values, \n",
    "                                                 Triana_dataset.obs['CellTypes'].values, \n",
    "                                                 Luecken_dataset.obs['cell_type'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged = {\"Zhang\": Zhang_dataset, \n",
    "          \"Hao\": Hao_dataset, \n",
    "          \"Triana\": Triana_dataset, \n",
    "          \"Luecken\": Luecken_dataset}\n",
    "\n",
    "adatas_merged = anndata.concat(adatas_merged, \n",
    "                        label=\"dataset_name\", \n",
    "                        join=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from venny4py.venny4py import *\n",
    "\n",
    "# Create the Venn diagram with custom colors\n",
    "sets = {'Zhang': set(list(Zhang_dataset.var_names)),\n",
    "        'Hao': set(list(Hao_dataset.var_names)),\n",
    "        'Triana': set(list(Triana_dataset.var_names)),\n",
    "        'Luecken': set(list(Luecken_dataset.var_names))}\n",
    "\n",
    "# Define custom colors for each dataset\n",
    "colors = ['#1F77B4',  # Zhang - blue\n",
    "          '#FE8010',  # Hao - orange  \n",
    "          '#2EA02E',  # Triana - green\n",
    "          '#D62828']  # Luecken - red\n",
    "\n",
    "venny4py(sets=sets, out=figures_path, ext='png', colors=colors)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Specify the current file name and the new file name\n",
    "current_file_name = figures_path + \"/Venn_4.png\"\n",
    "new_file_name = figures_path + \"/05_Shared_ADTs_across_all_datasets.png\"\n",
    "\n",
    "# Rename the file\n",
    "os.rename(current_file_name, new_file_name)\n",
    "\n",
    "# Specify the current file name and the new file name\n",
    "current_file_name = figures_path + \"/Intersections_4.txt\"\n",
    "new_file_name = figures_path + \"/05_Shared_ADTs_across_all_datasets.txt\"\n",
    "\n",
    "# Rename the file\n",
    "os.rename(current_file_name, new_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = SCUtils.Intersect_lists(Zhang_dataset.var_names, \n",
    "                                 Hao_dataset.var_names, \n",
    "                                 Triana_dataset.var_names, \n",
    "                                 Luecken_dataset.var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged = adatas_merged[:, common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged.obs['Original_annotation'] = original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adatas_merged.copy()\n",
    "\n",
    "# Normalize in-place on AnnData so you don't lose structure\n",
    "ep.Normalise_protein_data(adata, inplace=True, axis=1, flavor=\"seurat\")\n",
    "\n",
    "ep.Scale_protein_data(adata, inplace=True)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# PCA (cells x PCs)\n",
    "sc.tl.pca(adata, n_comps=30, svd_solver=\"arpack\")\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Harmony expects PCs x cells\n",
    "Z = np.asarray(adata.obsm[\"X_pca\"].T, dtype=np.float64)\n",
    "\n",
    "ho = hm.run_harmony(Z, adata.obs, [\"Batch\"], max_iter_harmony=30, random_state=42)\n",
    "\n",
    "# Corrected PCs back to (cells x PCs)\n",
    "adata.obsm[\"X_pcahm\"] = ho.Z_corr.T\n",
    "\n",
    "adatas_merged.obsm['X_pcahm'] = adata.obsm['X_pcahm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.pp.neighbors(adatas_merged, use_rep=\"X_pcahm\", n_neighbors=30, metric='cosine', random_state = 42)\n",
    "\n",
    "adatas_merged.obsp[\"connectivities\"] = np.round(adatas_merged.obsp[\"connectivities\"], decimals=5)\n",
    "adatas_merged.obsp[\"distances\"] = np.round(adatas_merged.obsp[\"distances\"], decimals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.tl.umap(adatas_merged, random_state = 42,  min_dist=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged, \n",
    "                color='dataset_name', \n",
    "                basis='X_umap', \n",
    "                legend_loc='right margin', \n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(5, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.05)\n",
    "\n",
    "# Place the legend below the plot\n",
    "legend = ax.legend(loc='upper center', \n",
    "                   bbox_to_anchor=(0.9, 1),\n",
    "                   prop={'size': 4.8},\n",
    "                   ncol=1)\n",
    "\n",
    "# Reduce the size of the dots in the legend\n",
    "for handle in legend.legend_handles:\n",
    "    handle._sizes = [10]\n",
    "\n",
    "# Adjust the layout to make room for the legend\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/06_Merged_datasets__coloured_by_datasets.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplot figure split by dataset_name\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Get unique datasets\n",
    "datasets = adatas_merged.obs['dataset_name'].unique()\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    # Filter data for current dataset\n",
    "    dataset_mask = adatas_merged.obs['dataset_name'] == dataset\n",
    "    dataset_data = adatas_merged[dataset_mask]\n",
    "    \n",
    "    # Plot UMAP for current dataset\n",
    "    sc.pl.embedding(dataset_data, \n",
    "                    color='dataset_name', \n",
    "                    basis='X_umap', \n",
    "                    legend_loc='none',\n",
    "                    add_outline=False,\n",
    "                    frameon=False,\n",
    "                    show=False,\n",
    "                    ax=axes[i])\n",
    "    \n",
    "    # Set axis labels and title for each subplot\n",
    "    axes[i].set_xlabel('UMAP 1', fontsize=12)\n",
    "    axes[i].set_ylabel('UMAP 2', fontsize=12)\n",
    "    axes[i].set_title(f'{dataset} dataset', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Remove empty subplot if odd number of datasets\n",
    "if len(datasets) < 4:\n",
    "    fig.delaxes(axes[3])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/07_Merged_datasets_split_by_dataset.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.tl.leiden(adatas_merged, resolution=3.5, random_state = 42, \n",
    "             n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged, \n",
    "                color='leiden', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(5, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Cluster annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/08_Merged_datasets__coloured_by_leiden_clusters.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "alignment = cellhint.harmonize(adatas_merged, 'dataset_name', 'Original_annotation', \n",
    "                               use_rep='X_pcahm', metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellhint.treeplot(alignment, save=figures_path + \"/09_Merged_datasets__CellHint_Preannotated_Classes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged.obs[['low_hierarchy', 'high_hierarchy']] = alignment.reannotation.loc[adatas_merged.obs_names, ['reannotation', 'group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged.obs['low_hierarchy'] = pd.Categorical(adatas_merged.obs['low_hierarchy'])\n",
    "adatas_merged.obs['high_hierarchy'] = pd.Categorical(adatas_merged.obs['high_hierarchy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged, \n",
    "                color='high_hierarchy', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(5, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Cluster annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# # Save the figure at 300 dpi\n",
    "# plt.savefig(figures_path + \"/Merged_datasets_leiden_annotation.png\", \n",
    "#             dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged, \n",
    "                color='Level 3 Multimodal',  #Level 3 Multimodal, celltype.l2, CellTypes, cell_type\n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(5, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Cluster annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged, \n",
    "                color='leiden', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(5, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Cluster annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged.obs['leiden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = '47'\n",
    "\n",
    "summary = adatas_merged.obs.groupby('leiden')['high_hierarchy'].value_counts()\n",
    "print(\"Top 5 high_hierarchy for cluster\", cluster)\n",
    "print(summary.loc[cluster].nlargest(5))\n",
    "print()\n",
    "\n",
    "summary = adatas_merged.obs.groupby('leiden')['Original_annotation'].value_counts()\n",
    "print(\"Top 5 Original_annotation for cluster\", cluster)\n",
    "print(summary.loc[cluster].nlargest(5))\n",
    "print()\n",
    "\n",
    "# Get the top high_hierarchy group for this cluster to find related alignment info\n",
    "top_hierarchy = adatas_merged.obs.groupby('leiden')['high_hierarchy'].value_counts().loc[cluster].index[0]\n",
    "# Use the groups column directly instead of index filtering\n",
    "matching_groups = alignment.relation[alignment.groups == top_hierarchy]\n",
    "print(\"Related alignment groups:\")\n",
    "print(matching_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 0) Make sure leiden is string\n",
    "adatas_merged.obs[\"leiden\"] = adatas_merged.obs[\"leiden\"].astype(str)\n",
    "\n",
    "# 1) RESET: wipe any previous assignments\n",
    "adatas_merged.obs[\"Consensus_annotation_detailed\"] = pd.NA\n",
    "\n",
    "# 2) Mapping (now complete up to \"54\")\n",
    "cluster_to_label = {\n",
    "    \"0\":  \"Progenitor\",\n",
    "    \"1\":  \"CD4 T Naive\",\n",
    "    \"2\":  \"B Naive\",\n",
    "    \"3\":  \"Progenitor\",\n",
    "    \"4\":  \"CD14 Mono\",\n",
    "    \"5\":  \"CD8 T Naive\",\n",
    "    \"6\":  \"NK CD56 dim\",\n",
    "    \"7\":  \"Immature B\",\n",
    "    \"8\":  \"CD14 Mono\",\n",
    "    \"9\":  \"CD4 T Memory\",\n",
    "    \"10\": \"CD14 Mono\",\n",
    "    \"11\": \"CD14 Mono\",\n",
    "    \"12\": \"NK CD56 dim\",\n",
    "    \"13\": \"Progenitor\",\n",
    "    \"14\": \"pDC\",\n",
    "    \"15\": \"CD8 T Memory\",\n",
    "    \"16\": \"B Memory\",\n",
    "    \"17\": \"CD16 Mono\",\n",
    "    \"18\": \"Progenitor\",\n",
    "    \"19\": \"Progenitor\",\n",
    "    \"20\": \"cDC2\",\n",
    "    \"21\": \"CD8 T Memory\",\n",
    "    \"22\": \"CD4 T Memory\",\n",
    "    \"23\": \"CD4 T Memory\",\n",
    "    \"24\": \"CD8 T Memory\",\n",
    "    \"25\": \"Progenitor\",\n",
    "    \"26\": \"CD8 T Memory\",\n",
    "    \"27\": \"CD4 T Memory\",\n",
    "    \"28\": \"MAIT\",\n",
    "    \"29\": \"CD4 T Naive\",\n",
    "    \"30\": \"NK CD56 bright\",\n",
    "    \"31\": \"Treg\",\n",
    "    \"32\": \"CD14 Mono\",\n",
    "    \"33\": \"Progenitor\",\n",
    "    \"34\": \"CD4 CTL\",\n",
    "    \"35\": \"CD14 Mono\",\n",
    "    \"36\": \"CD8 T Memory\",\n",
    "    \"37\": \"CD14 Mono\",\n",
    "    \"38\": \"CD8 T Memory\",\n",
    "    \"39\": \"Plasma\",\n",
    "    \"40\": \"CD8 T Naive\",\n",
    "    \"41\": \"B Memory\",\n",
    "    \"42\": \"NK CD56 dim\",\n",
    "    \"43\": \"NK CD56 dim\",\n",
    "    \"44\": \"Progenitor\",\n",
    "    \"45\": \"Progenitor\",\n",
    "    \"46\": \"Mesenchymal\",\n",
    "    \"47\": \"cDC1\",\n",
    "    \"48\": \"DnT\",\n",
    "    \"49\": \"Progenitor\",\n",
    "    \"50\": \"CD14 Mono\",\n",
    "    \"51\": \"B Memory\",\n",
    "    \"52\": \"Macrophage\",\n",
    "    \"53\": \"CD14 Mono\",\n",
    "    \"54\": \"CD14 Mono\",\n",
    "    \"55\": \"B Naive\",\n",
    "}\n",
    "\n",
    "# 3) Assign in one shot\n",
    "adatas_merged.obs[\"Consensus_annotation_detailed\"] = adatas_merged.obs[\"leiden\"].map(cluster_to_label)\n",
    "\n",
    "# 4) Sanity checks\n",
    "all_clusters = sorted(adatas_merged.obs[\"leiden\"].unique(), key=lambda x: int(x))\n",
    "missing = [c for c in all_clusters if c not in cluster_to_label]\n",
    "unassigned_n = adatas_merged.obs[\"Consensus_annotation_detailed\"].isna().sum()\n",
    "\n",
    "print(f\"Unique clusters in data: {len(all_clusters)}\")\n",
    "print(f\"Clusters missing from mapping: {missing}\")\n",
    "print(f\"Unassigned cells after mapping: {unassigned_n}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_colors' in adatas_merged.uns:\n",
    "    del adatas_merged.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(5, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Draft consensus detailed annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/10_Merged_datasets__coloured_by_preliminary_consensus_annotation_broad.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract CD4 T Naive, CD4 T Memory, CD8 T Memory, MAIT, and DnT cells\n",
    "t_cell_types = ['CD4 T Naive', 'CD4 T Memory', 'CD8 T Memory', 'CD8 T Naive', 'MAIT', 'DnT']\n",
    "t_cell_mask = adatas_merged.obs['Consensus_annotation_detailed'].isin(t_cell_types)\n",
    "t_cell_subset = adatas_merged[t_cell_mask].copy()\n",
    "\n",
    "print(f\"Number of T cells: {t_cell_subset.n_obs}\")\n",
    "print(f\"Leiden clusters containing T cells: {t_cell_subset.obs['leiden'].unique()}\")\n",
    "\n",
    "# Check distribution of cell types\n",
    "print(\"\\nDistribution of T cell types:\")\n",
    "print(t_cell_subset.obs['Consensus_annotation_detailed'].value_counts())\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Perform subclustering on T cells\n",
    "sc.pp.neighbors(t_cell_subset, use_rep=\"X_pcahm\", n_neighbors=15, metric='cosine', random_state=42)\n",
    "sc.tl.leiden(t_cell_subset, resolution=3, random_state=42, key_added='t_cell_subclusters')\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create UMAP for the subset\n",
    "sc.tl.umap(t_cell_subset, random_state=42, min_dist=0.3)\n",
    "\n",
    "# Plot the subclusters\n",
    "sc.pl.embedding(t_cell_subset, \n",
    "                color='t_cell_subclusters', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=6,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "ax.set_title('T Cell Subclustering', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot original annotations\n",
    "sc.pl.embedding(t_cell_subset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=6,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "ax.set_title('T Cell Original Annotations', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Check original annotations within each subcluster\n",
    "print(\"\\nOriginal annotations per subcluster:\")\n",
    "for cluster in sorted(t_cell_subset.obs['t_cell_subclusters'].unique()):\n",
    "    cluster_cells = t_cell_subset.obs[t_cell_subset.obs['t_cell_subclusters'] == cluster]\n",
    "    print(f\"\\nSubcluster {cluster}:\")\n",
    "    print(cluster_cells['Original_annotation'].value_counts().head())\n",
    "\n",
    "# Find marker genes for subclusters\n",
    "sc.tl.rank_genes_groups(t_cell_subset, 't_cell_subclusters', method='wilcoxon', use_raw=False)\n",
    "sc.pl.rank_genes_groups(t_cell_subset, n_genes=5, sharey=False, ncols=3, fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# User-editable: subcluster IDs -> new label (only these will be changed)\n",
    "# Everything else will keep the ORIGINAL label in adatas.obs[LABEL_COL_MAIN]\n",
    "# -----------------------------------------------------------------------------\n",
    "SUBCLUSTER_TO_LABEL = {\n",
    "    \"Gamma delta T\": [\"37\"],\n",
    "}\n",
    "\n",
    "LABEL_COL_MAIN = \"Consensus_annotation_detailed\"\n",
    "SUBCLUSTER_COL = \"t_cell_subclusters\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 0) Ensure subcluster IDs are strings for matching\n",
    "# -----------------------------------------------------------------------------\n",
    "t_cell_subset.obs[SUBCLUSTER_COL] = t_cell_subset.obs[SUBCLUSTER_COL].astype(str)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Ensure target labels exist as categories in the main AnnData (if categorical)\n",
    "# -----------------------------------------------------------------------------\n",
    "target_labels = list(SUBCLUSTER_TO_LABEL.keys())\n",
    "\n",
    "if pd.api.types.is_categorical_dtype(adatas_merged.obs[LABEL_COL_MAIN]):\n",
    "    missing = [c for c in target_labels if c not in adatas_merged.obs[LABEL_COL_MAIN].cat.categories]\n",
    "    if missing:\n",
    "        adatas_merged.obs[LABEL_COL_MAIN] = adatas_merged.obs[LABEL_COL_MAIN].cat.add_categories(missing)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Build mask per target label and write back ONLY those cells\n",
    "# -----------------------------------------------------------------------------\n",
    "t_cell_subset.obs[\"t_cell_label_updated\"] = adatas_merged.obs.loc[t_cell_subset.obs_names, LABEL_COL_MAIN].astype(str).values\n",
    "\n",
    "for new_label, subcluster_ids in SUBCLUSTER_TO_LABEL.items():\n",
    "    mask = t_cell_subset.obs[SUBCLUSTER_COL].isin([str(x) for x in subcluster_ids])\n",
    "    idx = t_cell_subset.obs_names[mask]\n",
    "    # Update subset tracking column\n",
    "    t_cell_subset.obs.loc[idx, \"t_cell_label_updated\"] = new_label\n",
    "    # Update main object ONLY for those cells\n",
    "    adatas_merged.obs.loc[idx, LABEL_COL_MAIN] = new_label\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Summary of CHANGES only\n",
    "# -----------------------------------------------------------------------------\n",
    "changed = t_cell_subset.obs[\"t_cell_label_updated\"] != adatas_merged.obs.loc[t_cell_subset.obs_names, LABEL_COL_MAIN].astype(str).values\n",
    "# The line above compares after assignment; better to compute changes vs original:\n",
    "original_labels = adatas_merged.obs.loc[t_cell_subset.obs_names, LABEL_COL_MAIN].astype(str).copy()\n",
    "# Reconstruct \"after\" labels from adatas (authoritative)\n",
    "after_labels = adatas_merged.obs.loc[t_cell_subset.obs_names, LABEL_COL_MAIN].astype(str)\n",
    "changes = pd.DataFrame({\"original\": original_labels, \"updated\": after_labels}, index=t_cell_subset.obs_names)\n",
    "changes = changes.loc[changes[\"original\"] != changes[\"updated\"]]\n",
    "\n",
    "print(\"Reassignment summary (changed cells only):\")\n",
    "if changes.empty:\n",
    "    print(\"No cells were reassigned.\")\n",
    "else:\n",
    "    print(changes[\"updated\"].value_counts().to_string())\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Plot updated labels on the subset UMAP\n",
    "# -----------------------------------------------------------------------------\n",
    "sc.pl.embedding(\n",
    "    t_cell_subset,\n",
    "    color=\"t_cell_label_updated\",\n",
    "    basis=\"X_umap\",\n",
    "    legend_loc=\"on data\",\n",
    "    legend_fontsize=6,\n",
    "    legend_fontoutline=2,\n",
    "    add_outline=False,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    ")\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel(\"UMAP 1\", fontsize=12)\n",
    "ax.set_ylabel(\"UMAP 2\", fontsize=12)\n",
    "ax.set_title(\"T Cell Reassignments (others unchanged)\", fontsize=12, fontweight=\"bold\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Immature B cells\n",
    "immature_b_mask = adatas_merged.obs['Consensus_annotation_detailed'] == 'Immature B'\n",
    "immature_b_subset = adatas_merged[immature_b_mask].copy()\n",
    "\n",
    "print(f\"Number of Immature B cells: {immature_b_subset.n_obs}\")\n",
    "print(f\"Leiden clusters containing Immature B: {immature_b_subset.obs['leiden'].unique()}\")\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Perform subclustering on Immature B cells\n",
    "sc.pp.neighbors(immature_b_subset, use_rep=\"X_pcahm\", n_neighbors=15, metric='cosine', random_state=42)\n",
    "sc.tl.leiden(immature_b_subset, resolution=0.5, random_state=42, key_added='immature_b_subclusters')\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create UMAP for the subset\n",
    "sc.tl.umap(immature_b_subset, random_state=42, min_dist=0.3)\n",
    "\n",
    "# Plot the subclusters\n",
    "sc.pl.embedding(immature_b_subset, \n",
    "                color='immature_b_subclusters', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=6,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "ax.set_title('Immature B Subclustering', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Check original annotations within each subcluster\n",
    "print(\"\\nOriginal annotations per subcluster:\")\n",
    "for cluster in immature_b_subset.obs['immature_b_subclusters'].unique():\n",
    "    cluster_cells = immature_b_subset.obs[immature_b_subset.obs['immature_b_subclusters'] == cluster]\n",
    "    print(f\"\\nSubcluster {cluster}:\")\n",
    "    print(cluster_cells['Original_annotation'].value_counts().head())\n",
    "\n",
    "# Find marker genes for subclusters\n",
    "sc.tl.rank_genes_groups(immature_b_subset, 'immature_b_subclusters', method='wilcoxon', use_raw=False)\n",
    "sc.pl.rank_genes_groups(immature_b_subset, n_genes=5, sharey=False, ncols=3, fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# IMMATURE B reassignment helper\n",
    "# - Only the specified Immature B subclusters are relabeled\n",
    "# - Everything else in adatas_merged.obs[LABEL_COL_MAIN] stays unchanged\n",
    "# =============================================================================\n",
    "\n",
    "MAIN_ADATA = adatas_merged\n",
    "SUBSET_ADATA = immature_b_subset  # <-- your Immature B subset AnnData\n",
    "\n",
    "LABEL_COL_MAIN = \"Consensus_annotation_detailed\"\n",
    "SUBCLUSTER_COL = \"immature_b_subclusters\"\n",
    "UPDATED_COL_IN_SUBSET = \"immature_b_label_updated\"\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# USER-EDITABLE: map NEW LABEL -> list of Immature B subcluster IDs to change\n",
    "# Example placeholder below; edit these IDs/labels as needed.\n",
    "# -------------------------------------------------------------------------\n",
    "SUBCLUSTER_TO_LABEL = {\n",
    "    \"Progenitor\": [\"3\"],          # example\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 0) Ensure subcluster IDs are strings\n",
    "# -----------------------------------------------------------------------------\n",
    "SUBSET_ADATA.obs[SUBCLUSTER_COL] = SUBSET_ADATA.obs[SUBCLUSTER_COL].astype(str)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Snapshot ORIGINAL labels for accurate change summary\n",
    "# -----------------------------------------------------------------------------\n",
    "original_labels = MAIN_ADATA.obs.loc[SUBSET_ADATA.obs_names, LABEL_COL_MAIN].astype(str).copy()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Ensure target labels exist as categories in MAIN (if categorical)\n",
    "# -----------------------------------------------------------------------------\n",
    "target_labels = list(SUBCLUSTER_TO_LABEL.keys())\n",
    "if pd.api.types.is_categorical_dtype(MAIN_ADATA.obs[LABEL_COL_MAIN]):\n",
    "    missing = [c for c in target_labels if c not in MAIN_ADATA.obs[LABEL_COL_MAIN].cat.categories]\n",
    "    if missing:\n",
    "        MAIN_ADATA.obs[LABEL_COL_MAIN] = MAIN_ADATA.obs[LABEL_COL_MAIN].cat.add_categories(missing)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Initialize subset tracking column to ORIGINAL labels (others unchanged)\n",
    "# -----------------------------------------------------------------------------\n",
    "SUBSET_ADATA.obs[UPDATED_COL_IN_SUBSET] = original_labels.values\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Apply reassignments ONLY for specified subclusters\n",
    "# -----------------------------------------------------------------------------\n",
    "for new_label, subcluster_ids in SUBCLUSTER_TO_LABEL.items():\n",
    "    subcluster_ids = [str(x) for x in subcluster_ids]\n",
    "    mask = SUBSET_ADATA.obs[SUBCLUSTER_COL].isin(subcluster_ids)\n",
    "    idx = SUBSET_ADATA.obs_names[mask]\n",
    "\n",
    "    # Track in subset\n",
    "    SUBSET_ADATA.obs.loc[idx, UPDATED_COL_IN_SUBSET] = new_label\n",
    "    # Update MAIN only for those cells\n",
    "    MAIN_ADATA.obs.loc[idx, LABEL_COL_MAIN] = new_label\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Summary of CHANGES (original vs updated) among Immature B subset cells only\n",
    "# -----------------------------------------------------------------------------\n",
    "after_labels = MAIN_ADATA.obs.loc[SUBSET_ADATA.obs_names, LABEL_COL_MAIN].astype(str)\n",
    "changes = pd.DataFrame({\"original\": original_labels, \"updated\": after_labels}, index=SUBSET_ADATA.obs_names)\n",
    "changes = changes.loc[changes[\"original\"] != changes[\"updated\"]]\n",
    "\n",
    "print(\"Immature B reassignment summary (changed cells only):\")\n",
    "if changes.empty:\n",
    "    print(\"No cells were reassigned.\")\n",
    "else:\n",
    "    print(\"\\nCounts by updated label:\")\n",
    "    print(changes[\"updated\"].value_counts().to_string())\n",
    "\n",
    "    print(\"\\nCounts by (original -> updated):\")\n",
    "    print(changes.groupby([\"original\", \"updated\"]).size().sort_values(ascending=False).to_string())\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Plot updated labels on the subset UMAP\n",
    "# -----------------------------------------------------------------------------\n",
    "sc.pl.embedding(\n",
    "    SUBSET_ADATA,\n",
    "    color=UPDATED_COL_IN_SUBSET,\n",
    "    basis=\"X_umap\",\n",
    "    legend_loc=\"on data\",\n",
    "    legend_fontsize=6,\n",
    "    legend_fontoutline=2,\n",
    "    add_outline=False,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    ")\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel(\"UMAP 1\", fontsize=12)\n",
    "ax.set_ylabel(\"UMAP 2\", fontsize=12)\n",
    "ax.set_title(\"Immature B Reassignments (others unchanged)\", fontsize=12, fontweight=\"bold\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Draft consensus detailed annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/11_Merged_datasets_Consensus_annotation_detailed_draft_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged.obs['Consensus_annotation_broad'] = 'Mature'\n",
    "\n",
    "categories = ['Mature', 'Immature']\n",
    "\n",
    "adatas_merged.obs['Consensus_annotation_broad'] = pd.Categorical(adatas_merged.obs['Consensus_annotation_broad'], categories=categories)\n",
    "adatas_merged.obs.loc[adatas_merged.obs['Consensus_annotation_detailed'] == 'Progenitor', 'Consensus_annotation_broad'] = 'Immature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged, \n",
    "                color='Consensus_annotation_broad', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(5, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Draft consensus broad annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/12_Merged_datasets__coloured_by_preliminary_consensus_annotation_broad_binary.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zhang_dataset.obs['Consensus_annotation_detailed']=adatas_merged.obs.loc[Zhang_dataset.obs_names, 'Consensus_annotation_detailed'].values\n",
    "Zhang_dataset.obs['Consensus_annotation_broad']=adatas_merged.obs.loc[Zhang_dataset.obs_names, 'Consensus_annotation_broad'].values\n",
    "\n",
    "Hao_dataset.obs['Consensus_annotation_detailed']=adatas_merged.obs.loc[Hao_dataset.obs_names, 'Consensus_annotation_detailed'].values\n",
    "Hao_dataset.obs['Consensus_annotation_broad']=adatas_merged.obs.loc[Hao_dataset.obs_names, 'Consensus_annotation_broad'].values\n",
    "Triana_dataset.obs['Consensus_annotation_detailed']=adatas_merged.obs.loc[Triana_dataset.obs_names, 'Consensus_annotation_detailed'].values\n",
    "Triana_dataset.obs['Consensus_annotation_broad']=adatas_merged.obs.loc[Triana_dataset.obs_names, 'Consensus_annotation_broad'].values\n",
    "\n",
    "Luecken_dataset.obs['Consensus_annotation_detailed']=adatas_merged.obs.loc[Luecken_dataset.obs_names, 'Consensus_annotation_detailed'].values\n",
    "Luecken_dataset.obs['Consensus_annotation_broad']=adatas_merged.obs.loc[Luecken_dataset.obs_names, 'Consensus_annotation_broad'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = pd.Categorical(np.concatenate((Zhang_dataset.obs['Level 3 Multimodal'].values,\n",
    "                                                 Triana_dataset.obs['CellTypes'].values, \n",
    "                                                 Luecken_dataset.obs['cell_type'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged_HSPC = {\"Zhang\": Zhang_dataset, \n",
    "               \"Triana\": Triana_dataset, \n",
    "               \"Luecken\": Luecken_dataset}\n",
    "\n",
    "adatas_merged_HSPC = anndata.concat(adatas_merged_HSPC, \n",
    "                             label=\"dataset_name\", \n",
    "                             join=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = SCUtils.Intersect_lists(Zhang_dataset.var_names, \n",
    "                                 Triana_dataset.var_names, \n",
    "                                 Luecken_dataset.var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from venny4py.venny4py import *\n",
    "\n",
    "# Create the Venn diagram with custom colors\n",
    "sets = {'Zhang': set(list(Zhang_dataset.var_names)),\n",
    "        'Triana': set(list(Triana_dataset.var_names)),\n",
    "        'Luecken': set(list(Luecken_dataset.var_names))}\n",
    "\n",
    "# Define custom colors for each dataset\n",
    "colors = ['#1F77B4',  # Zhang - blue\n",
    "          '#2EA02E',  # Triana - green\n",
    "          '#D62828']  # Luecken - red\n",
    "\n",
    "venny4py(sets=sets, out=figures_path, ext='png', colors=colors)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Specify the current file name and the new file name\n",
    "current_file_name = figures_path + \"/Venn_3.png\"\n",
    "new_file_name = figures_path + \"/13_Shared_ADTs_across_hspcs_containing_datasets.png\"\n",
    "\n",
    "# Rename the file\n",
    "os.rename(current_file_name, new_file_name)\n",
    "\n",
    "# Specify the current file name and the new file name\n",
    "current_file_name = figures_path + \"/Intersections_3.txt\"\n",
    "new_file_name = figures_path + \"/13_Shared_ADTs_across_hspcs_containing_datasets_list.txt\"\n",
    "\n",
    "# Rename the file\n",
    "os.rename(current_file_name, new_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged_HSPC = adatas_merged_HSPC[:, common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged_HSPC.obs['Original_annotation'] = original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immature_obs_names = adatas_merged.obs_names[(adatas_merged.obs['Consensus_annotation_broad'] == 'Immature') & (adatas_merged.obs['dataset_name'] != 'Hao')]\n",
    "obs_to_keep = np.in1d(adatas_merged_HSPC.obs_names, immature_obs_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged_HSPC = adatas_merged_HSPC[obs_to_keep,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adatas_merged_HSPC.copy()\n",
    "\n",
    "# Normalize in-place on AnnData so you don't lose structure\n",
    "ep.Normalise_protein_data(adata, inplace=True, axis=1, flavor=\"seurat\")\n",
    "\n",
    "ep.Scale_protein_data(adata, inplace=True)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# PCA (cells x PCs)\n",
    "sc.tl.pca(adata, n_comps=30, svd_solver=\"arpack\")\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Harmony expects PCs x cells\n",
    "Z = np.asarray(adata.obsm[\"X_pca\"].T, dtype=np.float64)\n",
    "\n",
    "ho = hm.run_harmony(Z, adata.obs, [\"Batch\"], max_iter_harmony=30, random_state=42)\n",
    "\n",
    "# Corrected PCs back to (cells x PCs)\n",
    "adata.obsm[\"X_pcahm\"] = ho.Z_corr.T\n",
    "\n",
    "adatas_merged_HSPC.obsm['X_pcahm'] = adata.obsm['X_pcahm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.pp.neighbors(adatas_merged_HSPC, use_rep=\"X_pcahm\", n_neighbors=30, metric='cosine', random_state = 42)\n",
    "\n",
    "adatas_merged_HSPC.obsp[\"connectivities\"] = np.round(adatas_merged_HSPC.obsp[\"connectivities\"], decimals=5)\n",
    "adatas_merged_HSPC.obsp[\"distances\"] = np.round(adatas_merged_HSPC.obsp[\"distances\"], decimals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.tl.umap(adatas_merged_HSPC, random_state = 42,  min_dist=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged_HSPC, \n",
    "                color='dataset_name', \n",
    "                basis='X_umap', \n",
    "                legend_loc='right margin', \n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(7, 8)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.05)\n",
    "\n",
    "# Place the legend below the plot\n",
    "legend = ax.legend(loc='upper center', \n",
    "                   bbox_to_anchor=(0.1, 1),\n",
    "                   prop={'size': 4.8},\n",
    "                   ncol=1)\n",
    "\n",
    "# Reduce the size of the dots in the legend\n",
    "for handle in legend.legend_handles:\n",
    "    handle._sizes = [10]\n",
    "\n",
    "# Adjust the layout to make room for the legend\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/14_Merged_datasets_hspcs__coloured_by_datasets.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplot figure split by dataset_name\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Get unique datasets\n",
    "datasets = adatas_merged_HSPC.obs['dataset_name'].unique()\n",
    "\n",
    "# Define colors for each dataset\n",
    "dataset_colors = {\n",
    "    'Zhang': '#1F77B4',   # blue\n",
    "    'Triana': '#2EA02E',  # green  \n",
    "    'Luecken': '#D62828'  # red\n",
    "}\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    # Filter data for current dataset\n",
    "    dataset_mask = adatas_merged_HSPC.obs['dataset_name'] == dataset\n",
    "    dataset_data = adatas_merged_HSPC[dataset_mask]\n",
    "    \n",
    "    # Plot UMAP for current dataset with specific color\n",
    "    sc.pl.embedding(dataset_data, \n",
    "                    color='dataset_name', \n",
    "                    basis='X_umap', \n",
    "                    legend_loc='none',\n",
    "                    add_outline=False,\n",
    "                    frameon=False,\n",
    "                    show=False,\n",
    "                    ax=axes[i],\n",
    "                    palette=[dataset_colors[dataset]])\n",
    "    \n",
    "    # Set axis labels and title for each subplot\n",
    "    axes[i].set_xlabel('UMAP 1', fontsize=12)\n",
    "    axes[i].set_ylabel('UMAP 2', fontsize=12)\n",
    "    axes[i].set_title(f'{dataset} dataset', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Remove empty subplot if odd number of datasets\n",
    "if len(datasets) < 4:\n",
    "    fig.delaxes(axes[3])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/15_Merged_datasets_hspcs__split_by_datasets.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.tl.leiden(adatas_merged_HSPC, resolution=3, random_state = 42, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged_HSPC, \n",
    "                color='leiden', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Cluster annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/16_Merged_datasets_hspcs_leiden_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged_HSPC, \n",
    "                color='cell_type', #Level 3 Multimodal, CellTypes, cell_type\n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Cluster annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "alignment = cellhint.harmonize(adatas_merged_HSPC, 'dataset_name', 'Original_annotation', \n",
    "                               use_rep='X_pcahm', metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellhint.treeplot(alignment, save=figures_path + \"/17_Merged_datasets_hspcs__CellHint_Preannotated_Classes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged_HSPC.obs[['low_hierarchy', 'high_hierarchy']] = alignment.reannotation.loc[adatas_merged_HSPC.obs_names, ['reannotation', 'group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged_HSPC.obs['low_hierarchy'] = pd.Categorical(adatas_merged_HSPC.obs['low_hierarchy'])\n",
    "adatas_merged_HSPC.obs['high_hierarchy'] = pd.Categorical(adatas_merged_HSPC.obs['high_hierarchy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = '28'\n",
    "\n",
    "summary = adatas_merged_HSPC.obs.groupby('leiden')['high_hierarchy'].value_counts()\n",
    "print(\"Top 5 high_hierarchy for cluster\", cluster)\n",
    "print(summary.loc[cluster].nlargest(5))\n",
    "print()\n",
    "\n",
    "summary = adatas_merged_HSPC.obs.groupby('leiden')['Original_annotation'].value_counts()\n",
    "print(\"Top 5 Original_annotation for cluster\", cluster)\n",
    "print(summary.loc[cluster].nlargest(5))\n",
    "print()\n",
    "\n",
    "# Get the top high_hierarchy group for this cluster to find related alignment info\n",
    "top_hierarchy = adatas_merged_HSPC.obs.groupby('leiden')['high_hierarchy'].value_counts().loc[cluster].index[0]\n",
    "# Use the groups column directly instead of index filtering\n",
    "matching_groups = alignment.relation[alignment.groups == top_hierarchy]\n",
    "print(\"Related alignment groups:\")\n",
    "print(matching_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged_HSPC.obs['leiden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 0) Make sure leiden is string\n",
    "adatas_merged_HSPC.obs[\"leiden\"] = adatas_merged_HSPC.obs[\"leiden\"].astype(str)\n",
    "\n",
    "# 1) RESET: wipe any previous assignments\n",
    "adatas_merged_HSPC.obs[\"Consensus_annotation_detailed\"] = pd.NA\n",
    "\n",
    "# 2) Mapping (now complete up to \"54\")\n",
    "cluster_to_label = {\n",
    "    \"0\":  \"CD14 Mono\",\n",
    "    \"1\":  \"LMPP\",\n",
    "    \"2\":  \"Erythroblast\",\n",
    "    \"3\":  \"MPP\",\n",
    "    \"4\":  \"Erythroblast\",\n",
    "    \"5\":  \"MEP\",\n",
    "    \"6\":  \"GMP\",\n",
    "    \"7\":  \"CD14 Mono\",\n",
    "    \"8\":  \"HSC\",\n",
    "    \"9\":  \"MEP\",\n",
    "    \"10\": \"MEP\",\n",
    "    \"11\": \"MEP\",\n",
    "    \"12\": \"Erythroblast\",\n",
    "    \"13\": \"MEP\",\n",
    "    \"14\": \"Pro-B\",\n",
    "    \"15\": \"cDC2\",\n",
    "    \"16\": \"GMP\",\n",
    "    \"17\": \"Pre-Pro-B\",\n",
    "    \"18\": \"LMPP\",\n",
    "    \"19\": \"MkP\",\n",
    "    \"20\": \"CD4 T Naive\",\n",
    "    \"21\": \"MEP\",\n",
    "    \"22\": \"MEP\",\n",
    "    \"23\": \"GMP\",\n",
    "    \"24\": \"Erythroblast\",\n",
    "    \"25\": \"CD16 Mono\",\n",
    "    \"26\": \"Erythroblast\",\n",
    "    \"27\": \"HSC\",\n",
    "    \"28\": \"MEP\",\n",
    "}\n",
    "\n",
    "# 3) Assign in one shot\n",
    "adatas_merged_HSPC.obs[\"Consensus_annotation_detailed\"] = adatas_merged_HSPC.obs[\"leiden\"].map(cluster_to_label)\n",
    "\n",
    "# 4) Sanity checks\n",
    "all_clusters = sorted(adatas_merged_HSPC.obs[\"leiden\"].unique(), key=lambda x: int(x))\n",
    "missing = [c for c in all_clusters if c not in cluster_to_label]\n",
    "unassigned_n = adatas_merged_HSPC.obs[\"Consensus_annotation_detailed\"].isna().sum()\n",
    "\n",
    "print(f\"Unique clusters in data: {len(all_clusters)}\")\n",
    "print(f\"Clusters missing from mapping: {missing}\")\n",
    "print(f\"Unassigned cells after mapping: {unassigned_n}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_colors' in adatas_merged_HSPC.uns:\n",
    "    del adatas_merged_HSPC.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged_HSPC, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Draft consensus detailed annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/18_Merged_datasets_hspcs__coloured_by_preliminary_consensus_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categories from both datasets\n",
    "adatas_categories = list(adatas_merged.obs['Consensus_annotation_detailed'].cat.categories)\n",
    "adatas_hspc_categories = list(adatas_merged_HSPC.obs['Consensus_annotation_detailed'].cat.categories)\n",
    "\n",
    "# Merge categories and remove duplicates while preserving order\n",
    "merged_categories = []\n",
    "for cat in adatas_categories + adatas_hspc_categories:\n",
    "    if cat not in merged_categories:\n",
    "        merged_categories.append(cat)\n",
    "\n",
    "# Set the merged categories for adatas\n",
    "adatas_merged.obs['Consensus_annotation_detailed'] = pd.Categorical(\n",
    "    adatas_merged.obs['Consensus_annotation_detailed'], \n",
    "    categories=merged_categories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged.obs.loc[adatas_merged_HSPC.obs.index, 'Consensus_annotation_detailed'] = adatas_merged_HSPC.obs['Consensus_annotation_detailed'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/19_Merged_datasets_Consensus_annotation_detailed_final_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged.obs['Consensus_annotation_broad'] = 'Mature'\n",
    "\n",
    "categories = ['Mature', 'Immature']\n",
    "\n",
    "adatas_merged.obs['Consensus_annotation_broad'] = pd.Categorical(adatas_merged.obs['Consensus_annotation_broad'], categories=categories)\n",
    "adatas_merged.obs.loc[adatas_merged.obs['Consensus_annotation_detailed'] == 'HSC', 'Consensus_annotation_broad'] = 'Immature'\n",
    "adatas_merged.obs.loc[adatas_merged.obs['Consensus_annotation_detailed'] == 'MPP', 'Consensus_annotation_broad'] = 'Immature'\n",
    "adatas_merged.obs.loc[adatas_merged.obs['Consensus_annotation_detailed'] == 'MEP', 'Consensus_annotation_broad'] = 'Immature'\n",
    "adatas_merged.obs.loc[adatas_merged.obs['Consensus_annotation_detailed'] == 'GMP', 'Consensus_annotation_broad'] = 'Immature'\n",
    "adatas_merged.obs.loc[adatas_merged.obs['Consensus_annotation_detailed'] == 'Pro-B', 'Consensus_annotation_broad'] = 'Immature'\n",
    "adatas_merged.obs.loc[adatas_merged.obs['Consensus_annotation_detailed'] == 'Pre-Pro-B', 'Consensus_annotation_broad'] = 'Immature'\n",
    "adatas_merged.obs.loc[adatas_merged.obs['Consensus_annotation_detailed'] == 'EoBaMaP', 'Consensus_annotation_broad'] = 'Immature'\n",
    "adatas_merged.obs.loc[adatas_merged.obs['Consensus_annotation_detailed'] == 'LMPP', 'Consensus_annotation_broad'] = 'Immature'\n",
    "adatas_merged.obs.loc[adatas_merged.obs['Consensus_annotation_detailed'] == 'MkP', 'Consensus_annotation_broad'] = 'Immature'\n",
    "adatas_merged.obs.loc[adatas_merged.obs['Consensus_annotation_detailed'] == 'Progenitor', 'Consensus_annotation_broad'] = 'Immature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged, \n",
    "                color='Consensus_annotation_broad', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus broad annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/20_Merged_datasets__coloured_by_intermediate_consensus_annotation_binary.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize as categorical with fixed order\n",
    "categories = [\n",
    "    'HSPC','Monocyte','NK','CD4 T','CD8 T','B',\n",
    "    'Erythroid','Doublet','Stroma','Other T','cDC','pDC','Mesenchymal'\n",
    "]\n",
    "adatas_merged.obs['Consensus_annotation_simplified'] = pd.Categorical(\n",
    "    [pd.NA] * adatas_merged.n_obs,\n",
    "    categories=categories\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# EDIT THIS ONLY\n",
    "# -------------------------------\n",
    "DETAILED_TO_SIMPLIFIED = {\n",
    "    # HSPC\n",
    "    'HSPC': [\n",
    "        'HSC', 'MPP', 'MEP', 'GMP', 'Pro-B', 'MkP', 'LMPP',\n",
    "        'Progenitor', 'EoBaMaP', 'Pre-Pro-B'\n",
    "    ],\n",
    "    # Monocyte\n",
    "    'Monocyte': ['CD14 Mono','CD16 Mono','Macrophage'],\n",
    "    # NK\n",
    "    'NK': ['NK CD56 dim','NK CD56 bright'],\n",
    "    # CD4 T\n",
    "    'CD4 T': ['CD4 T Naive','CD4 T Memory','Treg','CD4 CTL'],\n",
    "    # CD8 T\n",
    "    'CD8 T': ['CD8 T Naive','CD8 T Memory','MAIT'],\n",
    "    # B\n",
    "    'B': ['B Naive','B Memory','Plasma','Immature B','Pre-B'],\n",
    "    # Erythroid\n",
    "    'Erythroid': ['Erythroblast'],\n",
    "    # Singletons\n",
    "    'Doublet': ['Doublet'],\n",
    "    'Stroma': ['Stroma'],\n",
    "    'Other T': ['Gamma delta T', 'DnT'],\n",
    "    'cDC': ['cDC1','cDC2'],\n",
    "    'Mesenchymal': ['Mesenchymal'],\n",
    "    'pDC': ['pDC'],\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# Build reverse lookup: detailed -> simplified\n",
    "# -------------------------------\n",
    "reverse_map = {}\n",
    "for simp, detailed_list in DETAILED_TO_SIMPLIFIED.items():\n",
    "    for d in detailed_list:\n",
    "        reverse_map[d] = simp\n",
    "\n",
    "# -------------------------------\n",
    "# Apply mapping in one line\n",
    "# -------------------------------\n",
    "adatas_merged.obs['Consensus_annotation_simplified'] = (\n",
    "    adatas_merged.obs['Consensus_annotation_detailed']\n",
    "    .map(reverse_map)\n",
    "    .astype('category')\n",
    ")\n",
    "\n",
    "# Enforce category order\n",
    "adatas_merged.obs['Consensus_annotation_simplified'] = (\n",
    "    adatas_merged.obs['Consensus_annotation_simplified']\n",
    "    .cat.set_categories(categories)\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Sanity check\n",
    "# -------------------------------\n",
    "unmapped = adatas_merged.obs[\n",
    "    adatas_merged.obs['Consensus_annotation_simplified'].isna()\n",
    "]['Consensus_annotation_detailed'].value_counts()\n",
    "\n",
    "print(\"Unmapped detailed labels:\")\n",
    "print(unmapped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(adatas_merged, \n",
    "                color='Consensus_annotation_simplified', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus simplified annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/21_Merged_datasets__coloured_by_intermediate_consensus_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_merged.write_h5ad(data_path + \"/References/Merged_references.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zhang_dataset.obs['Consensus_annotation_broad']=adatas_merged.obs.loc[Zhang_dataset.obs_names, 'Consensus_annotation_broad'].values\n",
    "Zhang_dataset.obs['Consensus_annotation_simplified']=adatas_merged.obs.loc[Zhang_dataset.obs_names, 'Consensus_annotation_simplified'].values\n",
    "Zhang_dataset.obs['Consensus_annotation_detailed']=adatas_merged.obs.loc[Zhang_dataset.obs_names, 'Consensus_annotation_detailed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hao_dataset.obs['Consensus_annotation_broad']=adatas_merged.obs.loc[Hao_dataset.obs_names, 'Consensus_annotation_broad'].values\n",
    "Hao_dataset.obs['Consensus_annotation_simplified']=adatas_merged.obs.loc[Hao_dataset.obs_names, 'Consensus_annotation_simplified'].values\n",
    "Hao_dataset.obs['Consensus_annotation_detailed']=adatas_merged.obs.loc[Hao_dataset.obs_names, 'Consensus_annotation_detailed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Triana_dataset.obs['Consensus_annotation_broad']=adatas_merged.obs.loc[Triana_dataset.obs_names, 'Consensus_annotation_broad'].values\n",
    "Triana_dataset.obs['Consensus_annotation_simplified']=adatas_merged.obs.loc[Triana_dataset.obs_names, 'Consensus_annotation_simplified'].values\n",
    "Triana_dataset.obs['Consensus_annotation_detailed']=adatas_merged.obs.loc[Triana_dataset.obs_names, 'Consensus_annotation_detailed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Luecken_dataset.obs['Consensus_annotation_broad']=adatas_merged.obs.loc[Luecken_dataset.obs_names, 'Consensus_annotation_broad'].values\n",
    "Luecken_dataset.obs['Consensus_annotation_simplified']=adatas_merged.obs.loc[Luecken_dataset.obs_names, 'Consensus_annotation_simplified'].values\n",
    "Luecken_dataset.obs['Consensus_annotation_detailed']=adatas_merged.obs.loc[Luecken_dataset.obs_names, 'Consensus_annotation_detailed'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zhang dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Zhang_dataset.obs['Consensus_annotation_simplified'] = Zhang_dataset.obs['Consensus_annotation_simplified'].cat.remove_unused_categories()\n",
    "Zhang_dataset.obs['Consensus_annotation_detailed'] = Zhang_dataset.obs['Consensus_annotation_detailed'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Zhang_dataset.obs['Consensus_annotation_detailed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_categories = counts[counts >= 10].index\n",
    "Zhang_dataset = Zhang_dataset[Zhang_dataset.obs[Zhang_dataset.obs['Consensus_annotation_detailed'].isin(filtered_categories)].index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Zhang_dataset, \n",
    "                color='Level 3 Multimodal', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=2,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Zhang X. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_colors' in Zhang_dataset.uns:\n",
    "    del Zhang_dataset.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Zhang_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Zhang X. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "LEVEL_COL = \"Level 3 Multimodal\"\n",
    "OUT_BROAD = \"Consensus_annotation_broad\"\n",
    "OUT_SIMPL = \"Consensus_annotation_simplified\"\n",
    "OUT_DETAIL = \"Consensus_annotation_detailed\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Mapping rules: Level 3 Multimodal -> (broad, simplified, detailed)\n",
    "# -----------------------------------------------------------------------------\n",
    "RULES = [\n",
    "    # MEP\n",
    "    (['MEP-1', 'MEP-2', 'MEP-Eryth-1', 'MEP-Eryth-2'],\n",
    "     'Immature', 'HSPC', 'MEP'),\n",
    "\n",
    "    # Monocytes (CD14)\n",
    "    (['Intermediate Mono-1','Intermediate Mono-2','Intermediate Mono-3','Classical-Mono'],\n",
    "     'Mature', 'Monocyte', 'CD14 Mono'),\n",
    "\n",
    "    # Monocytes (CD16)\n",
    "    (['Non-Classical Mono-1','Non-Classical Mono-2'],\n",
    "     'Mature', 'Monocyte', 'CD16 Mono'),\n",
    "\n",
    "    # BMCP -> EoBaMaP\n",
    "    (['BMCP-1','BMCP-2'],\n",
    "     'Immature', 'HSPC', 'EoBaMaP'),\n",
    "\n",
    "    # cDC1-ish\n",
    "    (['pre-DC-2','pre-DC-1','cDC1'],\n",
    "     'Mature', 'cDC', 'cDC1'),\n",
    "\n",
    "    # cDC2-ish\n",
    "    (['pre-DC-3','cDC2-1','cDC2-2','ASDC'],\n",
    "     'Mature', 'cDC', 'cDC2'),\n",
    "\n",
    "    # pDC\n",
    "    (['pDC'],\n",
    "     'Mature', 'pDC', 'pDC'),\n",
    "\n",
    "    # Erythroid progenitors (ErP)\n",
    "    (['ERP-1','ERP-2','ERP-3','ERP-4','ERP-5','ERP-6','ERP-7','ERP-8'],\n",
    "     'Immature', 'Erythroid', 'ErP'),\n",
    "\n",
    "    # Erythroblasts\n",
    "    (['Erythroblast-1','Erythroblast-2','Erythroblast-3'],\n",
    "     'Mature', 'Erythroid', 'Erythroblast'),\n",
    "\n",
    "    # LMPP\n",
    "    (['LMPP-1-cycling','LMPP-1'],\n",
    "     'Immature', 'HSPC', 'MPP'),\n",
    "\n",
    "    # CLP\n",
    "    (['CLP'],\n",
    "     'Immature', 'HSPC', 'Pre-Pro-B'),\n",
    "\n",
    "    # CD8 naive\n",
    "    (['T CD8 Naive'],\n",
    "     'Mature', 'CD8 T', 'CD8 T Naive'),\n",
    "\n",
    "    # \"Myeloid intermediate\" etc -> Myeloid progenitor\n",
    "    (['Myeloid intermediate 1','Myeloid intermediate 2','Myeloid intermediate 3','Mono-1','Mono-2','cMOP'],\n",
    "     'Mature', 'Myeloid', 'Myeloid progenitor'),\n",
    "\n",
    "    # preNeu/immNeu -> GMP\n",
    "    (['preNeu','immNeu-1','immNeu-2'],\n",
    "     'Immature', 'HSPC', 'GMP'),\n",
    "\n",
    "    # MPP-MEP -> MPP\n",
    "    (['MPP-MEP'],\n",
    "     'Immature', 'HSPC', 'MPP'),\n",
    "\n",
    "    # HSC / MPP\n",
    "    (['HSC-1','HSC-2','MPP-1','MPP-2'],\n",
    "     'Immature', 'HSPC', 'HSC'),\n",
    "\n",
    "    # MultiLin -> LMPP\n",
    "    (['MultiLin-GMP-1','MultiLin-GMP-2','MultiLin-GMP-3','Multilin-1','Multilin-2','Multilin-3',\n",
    "      'LMPP-2','MDP-1','MDP-2'],\n",
    "     'Immature', 'HSPC', 'LMPP'),\n",
    "\n",
    "    # Pro-B\n",
    "    (['Pro-B-Early-cycling','Pro-B-Early','Pro-B-cycling-1','Pro-B-cycling-2','Pro-B-2','Pro-B-3','Pro-B-1'],\n",
    "     'Immature', 'B', 'Pro-B'),\n",
    "\n",
    "    # Transitional-B-2 -> Pre-B\n",
    "    (['Transitional-B-2'],\n",
    "     'Immature', 'B', 'Pre-B'),\n",
    "\n",
    "    # Transitional-B-1 / pre-B -> Immature B\n",
    "    (['Transitional-B-1','pre-B'],\n",
    "     'Mature', 'B', 'Immature B'),\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Build lookup dicts automatically from the rules\n",
    "# -----------------------------------------------------------------------------\n",
    "broad_map, simpl_map, detail_map = {}, {}, {}\n",
    "for keys, broad, simpl, detail in RULES:\n",
    "    for k in keys:\n",
    "        broad_map[k] = broad\n",
    "        simpl_map[k] = simpl\n",
    "        detail_map[k] = detail\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Ensure output columns exist and are OBJECT dtype (avoid categorical setitem)\n",
    "# -----------------------------------------------------------------------------\n",
    "for col in [OUT_BROAD, OUT_SIMPL, OUT_DETAIL]:\n",
    "    if col not in Zhang_dataset.obs.columns:\n",
    "        Zhang_dataset.obs[col] = pd.NA\n",
    "    if pd.api.types.is_categorical_dtype(Zhang_dataset.obs[col]):\n",
    "        Zhang_dataset.obs[col] = Zhang_dataset.obs[col].astype(\"object\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Apply mapping (index-aligned, write only matched rows)\n",
    "# -----------------------------------------------------------------------------\n",
    "new_broad  = Zhang_dataset.obs[LEVEL_COL].map(broad_map)\n",
    "new_simpl  = Zhang_dataset.obs[LEVEL_COL].map(simpl_map)\n",
    "new_detail = Zhang_dataset.obs[LEVEL_COL].map(detail_map)\n",
    "\n",
    "mask = Zhang_dataset.obs[LEVEL_COL].isin(broad_map.keys())\n",
    "\n",
    "Zhang_dataset.obs.loc[mask, OUT_BROAD]  = new_broad.loc[mask]\n",
    "Zhang_dataset.obs.loc[mask, OUT_SIMPL]  = new_simpl.loc[mask]\n",
    "Zhang_dataset.obs.loc[mask, OUT_DETAIL] = new_detail.loc[mask]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Optional: convert to categoricals AFTER assignment\n",
    "# -----------------------------------------------------------------------------\n",
    "for col in [OUT_BROAD, OUT_SIMPL, OUT_DETAIL]:\n",
    "    Zhang_dataset.obs[col] = pd.Categorical(Zhang_dataset.obs[col])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Sanity checks\n",
    "# -----------------------------------------------------------------------------\n",
    "unmapped = Zhang_dataset.obs.loc[~mask, LEVEL_COL].value_counts().head(30)\n",
    "print(f\"Matched rows: {int(mask.sum())} / {Zhang_dataset.n_obs}\")\n",
    "print(\"Top unmatched Level 3 Multimodal labels (first 30):\")\n",
    "print(unmapped.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Zhang_dataset.obs['Consensus_annotation_simplified'] = Zhang_dataset.obs['Consensus_annotation_simplified'].cat.remove_unused_categories()\n",
    "Zhang_dataset.obs['Consensus_annotation_detailed'] = Zhang_dataset.obs['Consensus_annotation_detailed'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smoothing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Zhang_dataset.obs['Consensus_annotation_detailed'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_categories = counts[counts >= 10].index\n",
    "Zhang_dataset = Zhang_dataset[Zhang_dataset.obs[Zhang_dataset.obs['Consensus_annotation_detailed'].isin(filtered_categories)].index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# Calculate silhouette scores for current annotations\n",
    "print(\"Calculating silhouette scores for Zhang dataset...\")\n",
    "\n",
    "# Use the UMAP representation for silhouette analysis\n",
    "X_embed = Zhang_dataset.obsm['X_umap']\n",
    "labels = Zhang_dataset.obs['Consensus_annotation_detailed'].astype('category').cat.codes\n",
    "\n",
    "# Calculate silhouette scores\n",
    "silhouette_avg = silhouette_score(X_embed, labels)\n",
    "sample_silhouette_values = silhouette_samples(X_embed, labels)\n",
    "\n",
    "print(f\"Average silhouette score: {silhouette_avg:.3f}\")\n",
    "\n",
    "# Add silhouette scores to the dataset\n",
    "Zhang_dataset.obs['silhouette_score'] = sample_silhouette_values\n",
    "\n",
    "# Identify cells with negative silhouette scores\n",
    "negative_silhouette_mask = sample_silhouette_values < 0\n",
    "print(f\"Number of cells with negative silhouette scores: {negative_silhouette_mask.sum()}\")\n",
    "print(f\"Percentage of cells with negative silhouette scores: {negative_silhouette_mask.sum()/len(sample_silhouette_values)*100:.2f}%\")\n",
    "\n",
    "# Show distribution of silhouette scores by cell type\n",
    "silhouette_by_type = Zhang_dataset.obs.groupby('Consensus_annotation_detailed')['silhouette_score'].agg(['mean', 'std', 'min', 'max', 'count'])\n",
    "print(\"\\nSilhouette scores by cell type:\")\n",
    "print(silhouette_by_type.sort_values('mean'))\n",
    "\n",
    "# Initialize refined annotations (start with original smoothed annotations)\n",
    "Zhang_dataset.obs['Consensus_annotation_detailed_refined'] = Zhang_dataset.obs['Consensus_annotation_detailed'].copy()\n",
    "\n",
    "# Perform silhouette-based reassignment\n",
    "print(\"\\n=== PERFORMING SILHOUETTE-BASED REASSIGNMENT ===\")\n",
    "\n",
    "# Identify cells with very poor silhouette scores (< -0.1)\n",
    "very_poor_silhouette = Zhang_dataset.obs['silhouette_score'] < -0.1\n",
    "\n",
    "if very_poor_silhouette.sum() > 0:\n",
    "    print(f\"Found {very_poor_silhouette.sum()} cells with very poor silhouette scores (< -0.1)\")\n",
    "    \n",
    "    # Fit nearest neighbors\n",
    "    nn = NearestNeighbors(n_neighbors=30, metric='euclidean')\n",
    "    nn.fit(X_embed)\n",
    "    \n",
    "    # Get indices of poorly assigned cells\n",
    "    poor_indices = np.where(very_poor_silhouette)[0]\n",
    "    \n",
    "    reassignments_made = 0\n",
    "    \n",
    "    for idx in poor_indices:\n",
    "        # Find neighbors for this cell\n",
    "        distances, neighbor_indices = nn.kneighbors([X_embed[idx]])\n",
    "        neighbor_indices = neighbor_indices[0][1:]  # Exclude the cell itself\n",
    "        \n",
    "        # Get annotations of neighbors\n",
    "        neighbor_annotations = Zhang_dataset.obs['Consensus_annotation_detailed'].iloc[neighbor_indices]\n",
    "\n",
    "        # Find most common annotation among neighbors\n",
    "        most_common = neighbor_annotations.mode()\n",
    "        \n",
    "        if len(most_common) > 0:\n",
    "            new_annotation = most_common.iloc[0]\n",
    "            current_annotation = Zhang_dataset.obs['Consensus_annotation_detailed'].iloc[idx]\n",
    "            \n",
    "            # Only reassign if the most common neighbor annotation is different\n",
    "            if new_annotation != current_annotation:\n",
    "                # Check if at least 40% of neighbors have this annotation\n",
    "                fraction = (neighbor_annotations == new_annotation).sum() / len(neighbor_annotations)\n",
    "                \n",
    "                if fraction >= 0.4:\n",
    "                    Zhang_dataset.obs.loc[Zhang_dataset.obs.index[idx], 'Consensus_annotation_detailed_refined'] = new_annotation\n",
    "                    reassignments_made += 1\n",
    "    \n",
    "    print(f\"Reassigned {reassignments_made} cells based on neighborhood consensus\")\n",
    "    \n",
    "    # Recalculate silhouette scores after reassignment\n",
    "    new_labels = Zhang_dataset.obs['Consensus_annotation_detailed_refined'].astype('category').cat.codes\n",
    "    new_silhouette_scores = silhouette_samples(X_embed, new_labels)\n",
    "    silhouette_avg_corrected = silhouette_score(X_embed, new_labels)\n",
    "    \n",
    "    # Store corrected scores\n",
    "    Zhang_dataset.obs['silhouette_score_corrected'] = new_silhouette_scores\n",
    "    \n",
    "    print(f\"\\n=== REASSIGNMENT RESULTS ===\")\n",
    "    print(f\"Original average silhouette: {silhouette_avg:.3f}\")\n",
    "    print(f\"Refined average silhouette: {silhouette_avg_corrected:.3f}\")\n",
    "    print(f\"Improvement: {silhouette_avg_corrected - silhouette_avg:.3f}\")\n",
    "    \n",
    "    print(f\"Original negative silhouette cells: {negative_silhouette_mask.sum()}\")\n",
    "    print(f\"Refined negative silhouette cells: {(new_silhouette_scores < 0).sum()}\")\n",
    "    \n",
    "    # Show what changes were made\n",
    "    if reassignments_made > 0:\n",
    "        changes_mask = (Zhang_dataset.obs['Consensus_annotation_detailed'] != \n",
    "                       Zhang_dataset.obs['Consensus_annotation_detailed_refined'])\n",
    "        changes = Zhang_dataset.obs[changes_mask]\n",
    "        \n",
    "        print(f\"\\n=== SPECIFIC REASSIGNMENTS ===\")\n",
    "        change_summary = changes.groupby([\n",
    "            'Consensus_annotation_detailed', \n",
    "            'Consensus_annotation_detailed_refined'\n",
    "        ]).size().reset_index(name='count')\n",
    "        \n",
    "        for _, row in change_summary.iterrows():\n",
    "            print(f\"{row['Consensus_annotation_detailed']} -> {row['Consensus_annotation_detailed_refined']}: {row['count']} cells\")\n",
    "\n",
    "else:\n",
    "    print(\"No cells with very poor silhouette scores found.\")\n",
    "    # Create corrected scores column that's identical to original\n",
    "    Zhang_dataset.obs['silhouette_score_corrected'] = Zhang_dataset.obs['silhouette_score'].copy()\n",
    "    silhouette_avg_corrected = silhouette_avg\n",
    "\n",
    "# Create a reassignment status column for visualization\n",
    "reassignment_mask = (Zhang_dataset.obs['Consensus_annotation_detailed'] != \n",
    "                    Zhang_dataset.obs['Consensus_annotation_detailed_refined'])\n",
    "Zhang_dataset.obs['reassignment_status'] = 'Unchanged'\n",
    "Zhang_dataset.obs.loc[reassignment_mask, 'reassignment_status'] = 'Reassigned'\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n=== FINAL SUMMARY ===\")\n",
    "print(f\"Total cells: {len(Zhang_dataset)}\")\n",
    "print(f\"Cells reassigned: {reassignment_mask.sum()}\")\n",
    "print(f\"Final cell type distribution:\")\n",
    "final_counts = Zhang_dataset.obs['Consensus_annotation_detailed_refined'].value_counts()\n",
    "print(final_counts)\n",
    "\n",
    "# Plot comprehensive analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Original annotations\n",
    "sc.pl.embedding(Zhang_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_umap',\n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[0,0])\n",
    "axes[0,0].set_title('Original Smoothed Annotations', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 2: Refined annotations\n",
    "sc.pl.embedding(Zhang_dataset, \n",
    "                color='Consensus_annotation_detailed_refined', \n",
    "                basis='X_umap',\n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[0,1])\n",
    "axes[0,1].set_title('Silhouette-Refined Annotations', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 3: Reassignment status\n",
    "sc.pl.embedding(Zhang_dataset, \n",
    "                color='reassignment_status', \n",
    "                basis='X_umap',\n",
    "                palette={'Unchanged': 'lightgray', 'Reassigned': 'red'},\n",
    "                add_outline=False,\n",
    "                legend_loc='right margin', \n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[1,0])\n",
    "axes[1,0].set_title('Reassignment Status', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 4: Corrected silhouette scores\n",
    "sc.pl.embedding(Zhang_dataset, \n",
    "                color='silhouette_score_corrected', \n",
    "                basis='X_umap',\n",
    "                color_map='RdBu_r',\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[1,1])\n",
    "axes[1,1].set_title('Silhouette Scores (Refined)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path + \"/22_Zhang_dataset_silhouette_refinement_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Additional histogram comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Original silhouette distribution\n",
    "ax1.hist(sample_silhouette_values, bins=50, alpha=0.7, edgecolor='black', color='lightblue')\n",
    "ax1.axvline(x=0, color='red', linestyle='--', label='Silhouette = 0')\n",
    "ax1.set_xlabel('Silhouette Score')\n",
    "ax1.set_ylabel('Number of Cells')\n",
    "ax1.set_title(f'Original Silhouette Distribution\\n(Avg: {silhouette_avg:.3f})')\n",
    "ax1.legend()\n",
    "\n",
    "# Refined silhouette distribution\n",
    "ax2.hist(Zhang_dataset.obs['silhouette_score_corrected'], bins=50, alpha=0.7, edgecolor='black', color='lightgreen')\n",
    "ax2.axvline(x=0, color='red', linestyle='--', label='Silhouette = 0')\n",
    "ax2.set_xlabel('Silhouette Score')\n",
    "ax2.set_ylabel('Number of Cells')\n",
    "ax2.set_title(f'Refined Silhouette Distribution\\n(Avg: {silhouette_avg_corrected:.3f})')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path + \"/23_Zhang_dataset_silhouette_distribution_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Zhang_dataset.obs['Consensus_annotation_simplified'] = Zhang_dataset.obs['Consensus_annotation_simplified'].cat.remove_unused_categories()\n",
    "Zhang_dataset.obs['Consensus_annotation_detailed_refined'] = Zhang_dataset.obs['Consensus_annotation_detailed_refined'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zhang_dataset_normalized = Zhang_dataset.copy()\n",
    "ep.Normalise_protein_data(Zhang_dataset_normalized, inplace=True, axis=1, flavor=\"seurat\")\n",
    "\n",
    "sc.tl.rank_genes_groups(Zhang_dataset_normalized, 'Consensus_annotation_detailed_refined', method='wilcoxon')\n",
    "sc.pl.rank_genes_groups(Zhang_dataset_normalized, n_genes=10, sharey=False, ncols = 3, fontsize = 14)\n",
    "\n",
    "plt.savefig(figures_path + \"/24_Zhang_dataset_top10_markers.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AveragedExpression = grouped_obs_mean(Zhang_dataset_normalized, 'Consensus_annotation_detailed_refined')\n",
    "df = pd.DataFrame(AveragedExpression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = df.corr(method='pearson')\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(235, 15, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "heatmap = sns.heatmap(corr, mask=mask, cmap=cmap, annot=True, \n",
    "                        square=True, linewidths=.6, cbar_kws={\"shrink\": 1},\n",
    "                        annot_kws={\"fontsize\":5})\n",
    "\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12)\n",
    "\n",
    "plt.savefig(figures_path + \"/25_Zhang_dataset_correlation_heatmap.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "LEVEL_COL  = \"Level 3 Multimodal\"\n",
    "OUT_BROAD  = \"Consensus_annotation_broad\"\n",
    "OUT_SIMPL  = \"Consensus_annotation_simplified\"\n",
    "OUT_DETAIL = \"Consensus_annotation_detailed\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Mapping rules: Level 3 Multimodal -> (broad, simplified, detailed)\n",
    "# -----------------------------------------------------------------------------\n",
    "RULES = [\n",
    "    # MEP\n",
    "    (['MEP-1', 'MEP-2', 'MEP-Eryth-1', 'MEP-Eryth-2'],\n",
    "     'Immature', 'HSPC', 'MEP'),\n",
    "\n",
    "    # Monocytes (CD14)\n",
    "    (['Intermediate Mono-1','Intermediate Mono-2','Intermediate Mono-3','Classical-Mono'],\n",
    "     'Mature', 'Monocyte', 'CD14 Mono'),\n",
    "\n",
    "    # Monocytes (CD16) - include both spellings/cases if they exist in your data\n",
    "    (['Non-classical-Mono-1','Non-classical-Mono-2', 'Non-Classical Mono-1','Non-Classical Mono-2'],\n",
    "     'Mature', 'Monocyte', 'CD16 Mono'),\n",
    "\n",
    "    # BMCP -> EoBaMaP\n",
    "    (['BMCP-1','BMCP-2'],\n",
    "     'Immature', 'HSPC', 'EoBaMaP'),\n",
    "\n",
    "    # cDC1-ish\n",
    "    (['pre-DC-2','pre-DC-1','cDC1'],\n",
    "     'Mature', 'cDC', 'cDC1'),\n",
    "\n",
    "    # cDC2-ish\n",
    "    (['pre-DC-3','cDC2-1','cDC2-2','ASDC'],\n",
    "     'Mature', 'cDC', 'cDC2'),\n",
    "\n",
    "    # pDC\n",
    "    (['pDC'],\n",
    "     'Mature', 'pDC', 'pDC'),\n",
    "\n",
    "    # Erythroid progenitors (ErP)\n",
    "    (['ERP-1','ERP-2','ERP-3','ERP-4','ERP-5','ERP-6','ERP-7','ERP-8'],\n",
    "     'Immature', 'Erythroid', 'ErP'),\n",
    "\n",
    "    # Erythroblasts\n",
    "    (['Erythroblast-1','Erythroblast-2','Erythroblast-3'],\n",
    "     'Mature', 'Erythroid', 'Erythroblast'),\n",
    "\n",
    "    # LMPP\n",
    "    (['LMPP-1-cycling','LMPP-1'],\n",
    "     'Immature', 'HSPC', 'MPP'),\n",
    "\n",
    "    # CLP\n",
    "    (['CLP'],\n",
    "     'Immature', 'HSPC', 'Pre-Pro-B'),\n",
    "\n",
    "    # CD8 naive\n",
    "    (['T CD8 Naive'],\n",
    "     'Mature', 'CD8 T', 'CD8 T Naive'),\n",
    "\n",
    "    # Myeloid intermediate etc -> Myeloid progenitor\n",
    "    (['Myeloid intermediate 1','Myeloid intermediate 2','Myeloid intermediate 3','Mono-1','Mono-2','cMOP'],\n",
    "     'Mature', 'Myeloid', 'Myeloid progenitor'),\n",
    "\n",
    "    # preNeu/immNeu -> GMP\n",
    "    (['preNeu','immNeu-1','immNeu-2'],\n",
    "     'Immature', 'HSPC', 'GMP'),\n",
    "\n",
    "    # MPP-MEP -> MPP\n",
    "    (['MPP-MEP'],\n",
    "     'Immature', 'HSPC', 'MPP'),\n",
    "\n",
    "    # HSC / MPP\n",
    "    (['HSC-1','HSC-2','MPP-1','MPP-2'],\n",
    "     'Immature', 'HSPC', 'HSC'),\n",
    "\n",
    "    # MultiLin -> LMPP\n",
    "    (['MultiLin-GMP-1','MultiLin-GMP-2','MultiLin-GMP-3','Multilin-1','Multilin-2','Multilin-3','LMPP-2','MDP-1','MDP-2'],\n",
    "     'Immature', 'HSPC', 'LMPP'),\n",
    "\n",
    "    # Pro-B\n",
    "    (['Pro-B-Early-cycling','Pro-B-Early','Pro-B-cycling-1','Pro-B-cycling-2','Pro-B-2','Pro-B-3','Pro-B-1'],\n",
    "     'Immature', 'B', 'Pro-B'),\n",
    "\n",
    "    # Transitional-B-2 -> Pre-B\n",
    "    (['Transitional-B-2'],\n",
    "     'Immature', 'B', 'Pre-B'),\n",
    "\n",
    "    # Transitional-B-1 / pre-B -> Immature B\n",
    "    (['Transitional-B-1','pre-B'],\n",
    "     'Mature', 'B', 'Immature B'),\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Build lookup dicts\n",
    "# -----------------------------------------------------------------------------\n",
    "broad_map, simpl_map, detail_map = {}, {}, {}\n",
    "for keys, broad, simpl, detail in RULES:\n",
    "    for k in keys:\n",
    "        broad_map[k]  = broad\n",
    "        simpl_map[k]  = simpl\n",
    "        detail_map[k] = detail\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Apply mapping safely (avoid categorical setitem issues on reruns)\n",
    "# -----------------------------------------------------------------------------\n",
    "for col in [OUT_BROAD, OUT_SIMPL, OUT_DETAIL]:\n",
    "    if col not in Zhang_dataset.obs.columns:\n",
    "        Zhang_dataset.obs[col] = pd.NA\n",
    "    if pd.api.types.is_categorical_dtype(Zhang_dataset.obs[col]):\n",
    "        Zhang_dataset.obs[col] = Zhang_dataset.obs[col].astype(\"object\")\n",
    "\n",
    "mask = Zhang_dataset.obs[LEVEL_COL].isin(broad_map)\n",
    "\n",
    "Zhang_dataset.obs.loc[mask, OUT_BROAD]  = Zhang_dataset.obs.loc[mask, LEVEL_COL].map(broad_map)\n",
    "Zhang_dataset.obs.loc[mask, OUT_SIMPL]  = Zhang_dataset.obs.loc[mask, LEVEL_COL].map(simpl_map)\n",
    "Zhang_dataset.obs.loc[mask, OUT_DETAIL] = Zhang_dataset.obs.loc[mask, LEVEL_COL].map(detail_map)\n",
    "\n",
    "# Optional: make these categoricals after assignment (inferred categories)\n",
    "for col in [OUT_BROAD, OUT_SIMPL, OUT_DETAIL]:\n",
    "    Zhang_dataset.obs[col] = pd.Categorical(Zhang_dataset.obs[col])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Build Consensus_annotation_simplified_final from refined detailed (or fallback)\n",
    "# -----------------------------------------------------------------------------\n",
    "SIMPL_FINAL_COL = \"Consensus_annotation_simplified_final\"\n",
    "REFINED_DETAIL_COL = \"Consensus_annotation_detailed_refined\"  # preferred input\n",
    "DETAIL_INPUT = REFINED_DETAIL_COL if REFINED_DETAIL_COL in Zhang_dataset.obs.columns else OUT_DETAIL\n",
    "\n",
    "simpl_categories = [\n",
    "    'HSPC', 'Monocyte', 'CD4 T', 'CD8 T', 'Erythroid', 'B', 'cDC', 'pDC', 'NK',\n",
    "    'Macrophage', 'Stroma', 'Myeloid', 'Doublet', 'Other T', 'Plasma', 'Mesenchymal'\n",
    "]\n",
    "\n",
    "# Ensure simplified_final exists and is OBJECT dtype (safe on reruns)\n",
    "if SIMPL_FINAL_COL not in Zhang_dataset.obs.columns:\n",
    "    Zhang_dataset.obs[SIMPL_FINAL_COL] = pd.NA\n",
    "else:\n",
    "    if pd.api.types.is_categorical_dtype(Zhang_dataset.obs[SIMPL_FINAL_COL]):\n",
    "        Zhang_dataset.obs[SIMPL_FINAL_COL] = Zhang_dataset.obs[SIMPL_FINAL_COL].astype(\"object\")\n",
    "\n",
    "# Reset each run\n",
    "Zhang_dataset.obs[SIMPL_FINAL_COL] = pd.NA\n",
    "\n",
    "s = Zhang_dataset.obs[DETAIL_INPUT]\n",
    "\n",
    "Zhang_dataset.obs.loc[s.isin(['HSC','MPP','LMPP','EoBaMaP','Pre-Pro-B','Pro-B','GMP','MkP','ErP','MEP']), SIMPL_FINAL_COL] = 'HSPC'\n",
    "Zhang_dataset.obs.loc[s.isin(['CD14 Mono','CD16 Mono']), SIMPL_FINAL_COL] = 'Monocyte'\n",
    "Zhang_dataset.obs.loc[s.isin(['NK CD56 dim','NK CD56 bright']), SIMPL_FINAL_COL] = 'NK'\n",
    "Zhang_dataset.obs.loc[s.isin(['CD4 T Naive','CD4 T Memory','Treg', 'CD4 CTL']), SIMPL_FINAL_COL] = 'CD4 T'\n",
    "Zhang_dataset.obs.loc[s.isin(['CD8 T Naive','CD8 T Memory','MAIT']), SIMPL_FINAL_COL] = 'CD8 T'\n",
    "Zhang_dataset.obs.loc[s.isin(['B Naive','B Memory','Immature B','Pre-B']), SIMPL_FINAL_COL] = 'B'\n",
    "Zhang_dataset.obs.loc[s.isin(['cDC1','cDC2']), SIMPL_FINAL_COL] = 'cDC'\n",
    "Zhang_dataset.obs.loc[s.isin(['Erythroblast','ErP']), SIMPL_FINAL_COL] = 'Erythroid'\n",
    "Zhang_dataset.obs.loc[s.isin(['Myeloid progenitor']), SIMPL_FINAL_COL] = 'Myeloid'\n",
    "Zhang_dataset.obs.loc[s.eq('pDC'), SIMPL_FINAL_COL] = 'pDC'\n",
    "Zhang_dataset.obs.loc[s.isin(['Gamma delta T']), SIMPL_FINAL_COL] = 'Other T'\n",
    "Zhang_dataset.obs.loc[s.eq('Macrophage'), SIMPL_FINAL_COL] = 'Macrophage'\n",
    "Zhang_dataset.obs.loc[s.eq('Mesenchymal'), SIMPL_FINAL_COL] = 'Mesenchymal'\n",
    "Zhang_dataset.obs.loc[s.eq('Stroma'), SIMPL_FINAL_COL] = 'Stroma'\n",
    "Zhang_dataset.obs.loc[s.eq('Plasma'), SIMPL_FINAL_COL] = 'Plasma'\n",
    "\n",
    "# Enforce fixed categories/order\n",
    "Zhang_dataset.obs[SIMPL_FINAL_COL] = pd.Categorical(Zhang_dataset.obs[SIMPL_FINAL_COL], categories=simpl_categories)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Build Consensus_annotation_broad_final (Zhang-style)\n",
    "# -----------------------------------------------------------------------------\n",
    "BROAD_FINAL_COL = \"Consensus_annotation_broad_final\"\n",
    "broad_categories = [\"Immature\", \"Mature\", \"Doublet\"]\n",
    "\n",
    "# Ensure broad_final exists and is OBJECT dtype (safe on reruns)\n",
    "if BROAD_FINAL_COL not in Zhang_dataset.obs.columns:\n",
    "    Zhang_dataset.obs[BROAD_FINAL_COL] = pd.NA\n",
    "else:\n",
    "    if pd.api.types.is_categorical_dtype(Zhang_dataset.obs[BROAD_FINAL_COL]):\n",
    "        Zhang_dataset.obs[BROAD_FINAL_COL] = Zhang_dataset.obs[BROAD_FINAL_COL].astype(\"object\")\n",
    "\n",
    "# Reset each run\n",
    "Zhang_dataset.obs[BROAD_FINAL_COL] = pd.NA\n",
    "\n",
    "sf = Zhang_dataset.obs[SIMPL_FINAL_COL]\n",
    "d = Zhang_dataset.obs[DETAIL_INPUT]\n",
    "\n",
    "# Doublet if present in simplified_final (optional)\n",
    "Zhang_dataset.obs.loc[sf.eq(\"Doublet\"), BROAD_FINAL_COL] = \"Doublet\"\n",
    "\n",
    "# Immature progenitors (align with your HSPC list)\n",
    "immature_details = ['HSC','MPP','LMPP','EoBaMaP','Pre-Pro-B','Pro-B','GMP','MkP','ErP','MEP']\n",
    "Zhang_dataset.obs.loc[d.isin(immature_details), BROAD_FINAL_COL] = \"Immature\"\n",
    "\n",
    "# Mature: anything assigned in simplified_final and not already Immature/Doublet\n",
    "Zhang_dataset.obs.loc[Zhang_dataset.obs[BROAD_FINAL_COL].isna(), BROAD_FINAL_COL] = \"Mature\"\n",
    "\n",
    "# Enforce fixed categories/order\n",
    "Zhang_dataset.obs[BROAD_FINAL_COL] = pd.Categorical(Zhang_dataset.obs[BROAD_FINAL_COL], categories=broad_categories)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Sanity checks\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"Matched Level 3 rows: {int(mask.sum())} / {Zhang_dataset.n_obs}\")\n",
    "\n",
    "unmapped_level3 = Zhang_dataset.obs.loc[~mask, LEVEL_COL].value_counts().head(30)\n",
    "print(\"\\nTop unmatched Level 3 Multimodal labels (first 30):\")\n",
    "print(unmapped_level3.to_string())\n",
    "\n",
    "unassigned_simpl_final = int(Zhang_dataset.obs[SIMPL_FINAL_COL].isna().sum())\n",
    "print(f\"\\nUnassigned '{SIMPL_FINAL_COL}' (NA) rows: {unassigned_simpl_final} / {Zhang_dataset.n_obs}\")\n",
    "\n",
    "unassigned_broad_final = int(Zhang_dataset.obs[BROAD_FINAL_COL].isna().sum())\n",
    "print(f\"Unassigned '{BROAD_FINAL_COL}' (NA) rows: {unassigned_broad_final} / {Zhang_dataset.n_obs}\")\n",
    "\n",
    "print(\"\\nBroad_final value counts:\")\n",
    "print(Zhang_dataset.obs[BROAD_FINAL_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSimplified_final value counts (top 30):\")\n",
    "print(Zhang_dataset.obs[SIMPL_FINAL_COL].value_counts(dropna=False).head(30).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zhang_dataset.obs['Consensus_annotation_detailed_final'] = Zhang_dataset.obs['Consensus_annotation_detailed_refined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Gamma delta T cells from the final dataset\n",
    "print(f\"Before removing Gamma delta T cells: {len(Zhang_dataset)} cells\")\n",
    "print(\"Cell type counts before:\")\n",
    "print(Zhang_dataset.obs['Consensus_annotation_detailed_final'].value_counts())\n",
    "\n",
    "# Create mask to exclude Gamma delta T cells\n",
    "mask_not_gdt = ~(Zhang_dataset.obs['Consensus_annotation_detailed_final'] == 'Gamma delta T')\n",
    "\n",
    "# Filter the dataset\n",
    "Zhang_dataset = Zhang_dataset[mask_not_gdt, :].copy()\n",
    "\n",
    "# Remove unused categories from all annotation columns\n",
    "Zhang_dataset.obs['Consensus_annotation_detailed_final'] = Zhang_dataset.obs['Consensus_annotation_detailed_final'].cat.remove_unused_categories()\n",
    "Zhang_dataset.obs['Consensus_annotation_simplified_final'] = Zhang_dataset.obs['Consensus_annotation_simplified_final'].cat.remove_unused_categories()\n",
    "Zhang_dataset.obs['Consensus_annotation_broad_final'] = Zhang_dataset.obs['Consensus_annotation_broad_final'].cat.remove_unused_categories()\n",
    "\n",
    "print(f\"After removing Gamma delta T cells: {len(Zhang_dataset)} cells\")\n",
    "print(\"Cell type counts after:\")\n",
    "print(Zhang_dataset.obs['Consensus_annotation_detailed_final'].value_counts())\n",
    "\n",
    "# Plot updated annotations\n",
    "sc.pl.embedding(Zhang_dataset, \n",
    "                color='Consensus_annotation_detailed_final', \n",
    "                basis='X_umap',\n",
    "                legend_loc='on data',\n",
    "                legend_fontsize=4,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Zhang_dataset.obs['Consensus_annotation_simplified_final'] = Zhang_dataset.obs['Consensus_annotation_simplified_final'].cat.remove_unused_categories()\n",
    "Zhang_dataset.obs['Consensus_annotation_detailed_final'] = Zhang_dataset.obs['Consensus_annotation_detailed_final'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Zhang_dataset, \n",
    "                color='Consensus_annotation_broad_final', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Zhang X. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus broad annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/26_Zhang_dataset_final_consensus_annotation_broad_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Zhang_dataset, \n",
    "                color='Consensus_annotation_simplified_final', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Zhang X. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus simplified annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/27_Zhang_dataset_final_consensus_annotation_simplified_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Zhang_dataset, \n",
    "                color='Consensus_annotation_detailed_final', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Zhang X. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/28_Zhang_dataset_final_Consensus_annotation_detailed_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hao dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Hao_dataset.obs['Consensus_annotation_simplified'] = Hao_dataset.obs['Consensus_annotation_simplified'].cat.remove_unused_categories()\n",
    "Hao_dataset.obs['Consensus_annotation_detailed'] = Hao_dataset.obs['Consensus_annotation_detailed'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the cells that are not labelled as 'Doublet'\n",
    "Hao_dataset = Hao_dataset[Hao_dataset.obs['celltype.l2'] != 'Doublet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Hao_dataset.obs['Consensus_annotation_detailed'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_categories = counts[counts >= 10].index\n",
    "Hao_dataset = Hao_dataset[Hao_dataset.obs[Hao_dataset.obs['Consensus_annotation_detailed'].isin(filtered_categories)].index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed' in Hao_dataset.uns:\n",
    "    del Hao_dataset.uns['Consensus_annotation_detailed']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Hao_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_wnn.umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Hao Y. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(Hao_dataset, \n",
    "                color='celltype.l2', \n",
    "                basis='X_wnn.umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Hao et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation', fontsize=8, y=0.925,\n",
    "            color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hao_dataset.obs.loc[Hao_dataset.obs['Consensus_annotation_detailed'] == 'Progenitor', 'Consensus_annotation_broad'] = 'Mature'\n",
    "Hao_dataset.obs.loc[Hao_dataset.obs['Consensus_annotation_detailed'] == 'Progenitor', 'Consensus_annotation_simplified'] = 'Monocyte'\n",
    "Hao_dataset.obs.loc[Hao_dataset.obs['Consensus_annotation_detailed'] == 'Progenitor', 'Consensus_annotation_detailed'] = 'CD14 Mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "OUT_BROAD  = \"Consensus_annotation_broad\"\n",
    "OUT_SIMPL  = \"Consensus_annotation_simplified\"\n",
    "OUT_DETAIL = \"Consensus_annotation_detailed\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 0) Ensure output columns exist and are OBJECT dtype (safe on reruns)\n",
    "# -----------------------------------------------------------------------------\n",
    "for col in [OUT_BROAD, OUT_SIMPL, OUT_DETAIL]:\n",
    "    if col not in Hao_dataset.obs.columns:\n",
    "        Hao_dataset.obs[col] = pd.NA\n",
    "    if pd.api.types.is_categorical_dtype(Hao_dataset.obs[col]):\n",
    "        Hao_dataset.obs[col] = Hao_dataset.obs[col].astype(\"object\")\n",
    "\n",
    "# Convenience handles (avoid KeyError if a column is absent)\n",
    "l2 = Hao_dataset.obs[\"celltype.l2\"] if \"celltype.l2\" in Hao_dataset.obs.columns else pd.Series(index=Hao_dataset.obs.index, dtype=\"object\")\n",
    "l3 = Hao_dataset.obs[\"celltype.l3\"] if \"celltype.l3\" in Hao_dataset.obs.columns else pd.Series(index=Hao_dataset.obs.index, dtype=\"object\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Apply your overrides\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# MAIT (from l2)\n",
    "m = l2.eq(\"MAIT\")\n",
    "Hao_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Hao_dataset.obs.loc[m, OUT_SIMPL]  = \"CD8 T\"\n",
    "Hao_dataset.obs.loc[m, OUT_DETAIL] = \"MAIT\"\n",
    "\n",
    "# Eryth (from l2)\n",
    "m = l2.eq(\"Eryth\")\n",
    "Hao_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Hao_dataset.obs.loc[m, OUT_SIMPL]  = \"Erythroid\"\n",
    "Hao_dataset.obs.loc[m, OUT_DETAIL] = \"Erythroblast\"\n",
    "\n",
    "# gdT (from l2)\n",
    "m = l2.eq(\"gdT\")\n",
    "Hao_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Hao_dataset.obs.loc[m, OUT_SIMPL]  = \"Other T\"\n",
    "Hao_dataset.obs.loc[m, OUT_DETAIL] = \"GdT\"\n",
    "\n",
    "# dnT (from l2)\n",
    "m = l2.eq(\"dnT\")\n",
    "Hao_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Hao_dataset.obs.loc[m, OUT_SIMPL]  = \"Other T\"\n",
    "Hao_dataset.obs.loc[m, OUT_DETAIL] = \"DnT\"\n",
    "\n",
    "# ASDC_mDC (from l3) -> cDC2\n",
    "m = l3.eq(\"ASDC_mDC\")\n",
    "Hao_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Hao_dataset.obs.loc[m, OUT_SIMPL]  = \"cDC\"\n",
    "Hao_dataset.obs.loc[m, OUT_DETAIL] = \"cDC2\"\n",
    "\n",
    "# HSPC (from l3) -> MPP\n",
    "m = l3.eq(\"HSPC\")\n",
    "Hao_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Hao_dataset.obs.loc[m, OUT_SIMPL]  = \"HSPC\"\n",
    "Hao_dataset.obs.loc[m, OUT_DETAIL] = \"MPP\"\n",
    "\n",
    "# CD8 TEM (from l3)\n",
    "m = l3.eq(\"CD8 TEM\")\n",
    "Hao_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Hao_dataset.obs.loc[m, OUT_SIMPL]  = \"CD8 T\"\n",
    "Hao_dataset.obs.loc[m, OUT_DETAIL] = \"CD8 T Memory\"\n",
    "\n",
    "# CD4 TCM (from l2)\n",
    "m = l2.eq(\"CD4 TCM\")\n",
    "Hao_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Hao_dataset.obs.loc[m, OUT_SIMPL]  = \"CD4 T\"\n",
    "Hao_dataset.obs.loc[m, OUT_DETAIL] = \"CD4 T Memory\"\n",
    "\n",
    "# CD4 TCM (from l2)\n",
    "m = l3.eq(\"ILC\")\n",
    "Hao_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Hao_dataset.obs.loc[m, OUT_SIMPL]  = \"ILC\"\n",
    "Hao_dataset.obs.loc[m, OUT_DETAIL] = \"ILC\"\n",
    "\n",
    "# Platelet (from l3)\n",
    "m = l3.eq(\"Platelet\")\n",
    "Hao_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Hao_dataset.obs.loc[m, OUT_SIMPL]  = \"Erythroid\"     # keeping your original choice\n",
    "Hao_dataset.obs.loc[m, OUT_DETAIL] = \"Platelet\"\n",
    "\n",
    "# Immature B -> simplified B (and keep detailed label)\n",
    "m = Hao_dataset.obs[OUT_DETAIL].eq(\"Immature B\")\n",
    "Hao_dataset.obs.loc[m, OUT_BROAD] = \"Mature\"\n",
    "Hao_dataset.obs.loc[m, OUT_SIMPL] = \"B\"\n",
    "Hao_dataset.obs.loc[m, OUT_DETAIL] = \"Immature B\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Optional: convert back to categoricals AFTER all assignments\n",
    "#    (categories inferred; safe and rerunnable)\n",
    "# -----------------------------------------------------------------------------\n",
    "for col in [OUT_BROAD, OUT_SIMPL, OUT_DETAIL]:\n",
    "    Hao_dataset.obs[col] = pd.Categorical(Hao_dataset.obs[col])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Sanity checks\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Value counts (simplified) top 20:\")\n",
    "print(Hao_dataset.obs[OUT_SIMPL].value_counts(dropna=False).head(20).to_string())\n",
    "\n",
    "print(\"\\nValue counts (detailed) top 20:\")\n",
    "print(Hao_dataset.obs[OUT_DETAIL].value_counts(dropna=False).head(20).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Hao_dataset.obs['Consensus_annotation_simplified'] = Hao_dataset.obs['Consensus_annotation_simplified'].cat.remove_unused_categories()\n",
    "Hao_dataset.obs['Consensus_annotation_detailed'] = Hao_dataset.obs['Consensus_annotation_detailed'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Hao_dataset.obs['Consensus_annotation_detailed'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Hao_dataset.obs['Consensus_annotation_detailed'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# Calculate silhouette scores for current annotations\n",
    "print(\"Calculating silhouette scores for Hao dataset...\")\n",
    "\n",
    "# Use the WNN UMAP representation for silhouette analysis\n",
    "X_embed = Hao_dataset.obsm['X_wnn.umap']\n",
    "labels = Hao_dataset.obs['Consensus_annotation_detailed'].astype('category').cat.codes\n",
    "\n",
    "# Calculate silhouette scores\n",
    "silhouette_avg = silhouette_score(X_embed, labels)\n",
    "sample_silhouette_values = silhouette_samples(X_embed, labels)\n",
    "\n",
    "print(f\"Average silhouette score: {silhouette_avg:.3f}\")\n",
    "\n",
    "# Add silhouette scores to the dataset\n",
    "Hao_dataset.obs['silhouette_score'] = sample_silhouette_values\n",
    "\n",
    "# Identify cells with negative silhouette scores\n",
    "negative_silhouette_mask = sample_silhouette_values < 0\n",
    "print(f\"Number of cells with negative silhouette scores: {negative_silhouette_mask.sum()}\")\n",
    "print(f\"Percentage of cells with negative silhouette scores: {negative_silhouette_mask.sum()/len(sample_silhouette_values)*100:.2f}%\")\n",
    "\n",
    "# Show distribution of silhouette scores by cell type\n",
    "silhouette_by_type = Hao_dataset.obs.groupby('Consensus_annotation_detailed')['silhouette_score'].agg(['mean', 'std', 'min', 'max', 'count'])\n",
    "print(\"\\nSilhouette scores by cell type:\")\n",
    "print(silhouette_by_type.sort_values('mean'))\n",
    "\n",
    "# Initialize refined annotations (start with original smoothed annotations)\n",
    "Hao_dataset.obs['Consensus_annotation_detailed_refined'] = Hao_dataset.obs['Consensus_annotation_detailed'].copy()\n",
    "\n",
    "# Perform silhouette-based reassignment\n",
    "print(\"\\n=== PERFORMING SILHOUETTE-BASED REASSIGNMENT ===\")\n",
    "\n",
    "# Identify cells with very poor silhouette scores (< -0.1)\n",
    "very_poor_silhouette = Hao_dataset.obs['silhouette_score'] < -0.1\n",
    "\n",
    "if very_poor_silhouette.sum() > 0:\n",
    "    print(f\"Found {very_poor_silhouette.sum()} cells with very poor silhouette scores (< -0.1)\")\n",
    "    \n",
    "    # Fit nearest neighbors\n",
    "    nn = NearestNeighbors(n_neighbors=30, metric='euclidean')\n",
    "    nn.fit(X_embed)\n",
    "    \n",
    "    # Get indices of poorly assigned cells\n",
    "    poor_indices = np.where(very_poor_silhouette)[0]\n",
    "    \n",
    "    reassignments_made = 0\n",
    "    \n",
    "    for idx in poor_indices:\n",
    "        # Find neighbors for this cell\n",
    "        distances, neighbor_indices = nn.kneighbors([X_embed[idx]])\n",
    "        neighbor_indices = neighbor_indices[0][1:]  # Exclude the cell itself\n",
    "        \n",
    "        # Get annotations of neighbors\n",
    "        neighbor_annotations = Hao_dataset.obs['Consensus_annotation_detailed'].iloc[neighbor_indices]\n",
    "\n",
    "        # Find most common annotation among neighbors\n",
    "        most_common = neighbor_annotations.mode()\n",
    "        \n",
    "        if len(most_common) > 0:\n",
    "            new_annotation = most_common.iloc[0]\n",
    "            current_annotation = Hao_dataset.obs['Consensus_annotation_detailed'].iloc[idx]\n",
    "            \n",
    "            # Only reassign if the most common neighbor annotation is different\n",
    "            if new_annotation != current_annotation:\n",
    "                # Check if at least 40% of neighbors have this annotation\n",
    "                fraction = (neighbor_annotations == new_annotation).sum() / len(neighbor_annotations)\n",
    "                \n",
    "                if fraction >= 0.4:\n",
    "                    Hao_dataset.obs.loc[Hao_dataset.obs.index[idx], 'Consensus_annotation_detailed_refined'] = new_annotation\n",
    "                    reassignments_made += 1\n",
    "    \n",
    "    print(f\"Reassigned {reassignments_made} cells based on neighborhood consensus\")\n",
    "    \n",
    "    # Recalculate silhouette scores after reassignment\n",
    "    new_labels = Hao_dataset.obs['Consensus_annotation_detailed_refined'].astype('category').cat.codes\n",
    "    new_silhouette_scores = silhouette_samples(X_embed, new_labels)\n",
    "    silhouette_avg_corrected = silhouette_score(X_embed, new_labels)\n",
    "    \n",
    "    # Store corrected scores\n",
    "    Hao_dataset.obs['silhouette_score_corrected'] = new_silhouette_scores\n",
    "    \n",
    "    print(f\"\\n=== REASSIGNMENT RESULTS ===\")\n",
    "    print(f\"Original average silhouette: {silhouette_avg:.3f}\")\n",
    "    print(f\"Refined average silhouette: {silhouette_avg_corrected:.3f}\")\n",
    "    print(f\"Improvement: {silhouette_avg_corrected - silhouette_avg:.3f}\")\n",
    "    \n",
    "    print(f\"Original negative silhouette cells: {negative_silhouette_mask.sum()}\")\n",
    "    print(f\"Refined negative silhouette cells: {(new_silhouette_scores < 0).sum()}\")\n",
    "    \n",
    "    # Show what changes were made\n",
    "    if reassignments_made > 0:\n",
    "        changes_mask = (Hao_dataset.obs['Consensus_annotation_detailed'] != \n",
    "                       Hao_dataset.obs['Consensus_annotation_detailed_refined'])\n",
    "        changes = Hao_dataset.obs[changes_mask]\n",
    "        \n",
    "        print(f\"\\n=== SPECIFIC REASSIGNMENTS ===\")\n",
    "        change_summary = changes.groupby([\n",
    "            'Consensus_annotation_detailed', \n",
    "            'Consensus_annotation_detailed_refined'\n",
    "        ]).size().reset_index(name='count')\n",
    "        \n",
    "        for _, row in change_summary.iterrows():\n",
    "            print(f\"{row['Consensus_annotation_detailed']} -> {row['Consensus_annotation_detailed_refined']}: {row['count']} cells\")\n",
    "\n",
    "else:\n",
    "    print(\"No cells with very poor silhouette scores found.\")\n",
    "    # Create corrected scores column that's identical to original\n",
    "    Hao_dataset.obs['silhouette_score_corrected'] = Hao_dataset.obs['silhouette_score'].copy()\n",
    "    silhouette_avg_corrected = silhouette_avg\n",
    "\n",
    "# Create a reassignment status column for visualization\n",
    "reassignment_mask = (Hao_dataset.obs['Consensus_annotation_detailed'] != \n",
    "                    Hao_dataset.obs['Consensus_annotation_detailed_refined'])\n",
    "Hao_dataset.obs['reassignment_status'] = 'Unchanged'\n",
    "Hao_dataset.obs.loc[reassignment_mask, 'reassignment_status'] = 'Reassigned'\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n=== FINAL SUMMARY ===\")\n",
    "print(f\"Total cells: {len(Hao_dataset)}\")\n",
    "print(f\"Cells reassigned: {reassignment_mask.sum()}\")\n",
    "print(f\"Final cell type distribution:\")\n",
    "final_counts = Hao_dataset.obs['Consensus_annotation_detailed_refined'].value_counts()\n",
    "print(final_counts)\n",
    "\n",
    "# Plot comprehensive analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Original annotations\n",
    "sc.pl.embedding(Hao_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_wnn.umap',\n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[0,0])\n",
    "axes[0,0].set_title('Original Smoothed Annotations', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 2: Refined annotations\n",
    "sc.pl.embedding(Hao_dataset, \n",
    "                color='Consensus_annotation_detailed_refined', \n",
    "                basis='X_wnn.umap',\n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[0,1])\n",
    "axes[0,1].set_title('Silhouette-Refined Annotations', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 3: Reassignment status\n",
    "sc.pl.embedding(Hao_dataset, \n",
    "                color='reassignment_status', \n",
    "                basis='X_wnn.umap',\n",
    "                palette={'Unchanged': 'lightgray', 'Reassigned': 'red'},\n",
    "                add_outline=False,\n",
    "                legend_loc='right margin', \n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[1,0])\n",
    "axes[1,0].set_title('Reassignment Status', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 4: Corrected silhouette scores\n",
    "sc.pl.embedding(Hao_dataset, \n",
    "                color='silhouette_score_corrected', \n",
    "                basis='X_wnn.umap',\n",
    "                color_map='RdBu_r',\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[1,1])\n",
    "axes[1,1].set_title('Silhouette Scores (Refined)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path + \"/29_Hao_dataset_silhouette_refinement_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Additional histogram comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Original silhouette distribution\n",
    "ax1.hist(sample_silhouette_values, bins=50, alpha=0.7, edgecolor='black', color='lightblue')\n",
    "ax1.axvline(x=0, color='red', linestyle='--', label='Silhouette = 0')\n",
    "ax1.set_xlabel('Silhouette Score')\n",
    "ax1.set_ylabel('Number of Cells')\n",
    "ax1.set_title(f'Original Silhouette Distribution\\n(Avg: {silhouette_avg:.3f})')\n",
    "ax1.legend()\n",
    "\n",
    "# Refined silhouette distribution\n",
    "ax2.hist(Hao_dataset.obs['silhouette_score_corrected'], bins=50, alpha=0.7, edgecolor='black', color='lightgreen')\n",
    "ax2.axvline(x=0, color='red', linestyle='--', label='Silhouette = 0')\n",
    "ax2.set_xlabel('Silhouette Score')\n",
    "ax2.set_ylabel('Number of Cells')\n",
    "ax2.set_title(f'Refined Silhouette Distribution\\n(Avg: {silhouette_avg_corrected:.3f})')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path + \"/30_Hao_dataset_silhouette_distribution_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Hao_dataset.obs['Consensus_annotation_simplified'] = Hao_dataset.obs['Consensus_annotation_simplified'].cat.remove_unused_categories()\n",
    "Hao_dataset.obs['Consensus_annotation_detailed_refined'] = Hao_dataset.obs['Consensus_annotation_detailed_refined'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hao_dataset_normalized = Hao_dataset.copy()\n",
    "ep.Normalise_protein_data(Hao_dataset_normalized, inplace=True, axis=1, flavor=\"seurat\")\n",
    "sc.tl.rank_genes_groups(Hao_dataset_normalized, 'Consensus_annotation_detailed_refined', method='wilcoxon')\n",
    "sc.pl.rank_genes_groups(Hao_dataset_normalized, n_genes=10, sharey=False, ncols = 3, fontsize = 14)\n",
    "\n",
    "plt.savefig(figures_path + \"/31_Hao_dataset_top10_markers.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AveragedExpression = grouped_obs_mean(Hao_dataset_normalized, 'Consensus_annotation_detailed_refined')\n",
    "df = pd.DataFrame(AveragedExpression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = df.corr(method='pearson')\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(235, 15, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "heatmap = sns.heatmap(corr, mask=mask, cmap=cmap, annot=True, \n",
    "                        square=True, linewidths=.6, cbar_kws={\"shrink\": 1},\n",
    "                        annot_kws={\"fontsize\":5})\n",
    "\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12)\n",
    "\n",
    "plt.savefig(figures_path + \"/32_Hao_dataset_correlation_heatmap.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# Hao_dataset: build *_final columns (broad_final + simplified_final) Zhang-style\n",
    "# - Safe on reruns (casts to object before assignment)\n",
    "# - Deterministic (resets outputs each run)\n",
    "# - Enforces fixed category orders at the end\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Column names\n",
    "# -----------------------------\n",
    "DETAIL_REFINED_COL = \"Consensus_annotation_detailed_refined\"\n",
    "DETAIL_FALLBACK_COL = \"Consensus_annotation_detailed\"\n",
    "\n",
    "BROAD_FINAL_COL = \"Consensus_annotation_broad_final\"\n",
    "SIMPL_FINAL_COL = \"Consensus_annotation_simplified_final\"\n",
    "\n",
    "# If refined detailed does not exist, fall back\n",
    "DETAIL_INPUT = DETAIL_REFINED_COL if DETAIL_REFINED_COL in Hao_dataset.obs.columns else DETAIL_FALLBACK_COL\n",
    "\n",
    "# -----------------------------\n",
    "# Fixed category orders\n",
    "# -----------------------------\n",
    "broad_categories = [\"Immature\", \"Mature\", \"Doublet\"]\n",
    "\n",
    "simpl_categories = [\n",
    "    'HSPC', 'Monocyte', 'CD4 T', 'CD8 T', 'Erythroid', 'B', 'cDC', 'pDC', 'NK',\n",
    "    'ILC', 'Other T', 'Macrophage', 'Stroma', 'Myeloid', 'Doublet', 'Plasma', 'Platelet'\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Ensure *_final columns exist and are OBJECT dtype (safe on reruns)\n",
    "# -----------------------------\n",
    "for col in [BROAD_FINAL_COL, SIMPL_FINAL_COL]:\n",
    "    if col not in Hao_dataset.obs.columns:\n",
    "        Hao_dataset.obs[col] = pd.NA\n",
    "    if pd.api.types.is_categorical_dtype(Hao_dataset.obs[col]):\n",
    "        Hao_dataset.obs[col] = Hao_dataset.obs[col].astype(\"object\")\n",
    "\n",
    "# Reset each run so reruns are deterministic\n",
    "Hao_dataset.obs[BROAD_FINAL_COL] = pd.NA\n",
    "Hao_dataset.obs[SIMPL_FINAL_COL] = pd.NA\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Build simplified_final from detailed_refined (or fallback detailed)\n",
    "# -----------------------------\n",
    "d = Hao_dataset.obs[DETAIL_INPUT]\n",
    "\n",
    "# HSPC\n",
    "Hao_dataset.obs.loc[d.isin(['MPP']), SIMPL_FINAL_COL] = 'HSPC'\n",
    "\n",
    "# Monocyte\n",
    "Hao_dataset.obs.loc[d.isin(['CD14 Mono', 'CD16 Mono']), SIMPL_FINAL_COL] = 'Monocyte'\n",
    "\n",
    "# NK\n",
    "Hao_dataset.obs.loc[d.isin(['NK CD56 dim', 'NK CD56 bright']), SIMPL_FINAL_COL] = 'NK'\n",
    "\n",
    "# CD4 T\n",
    "Hao_dataset.obs.loc[d.isin(['CD4 T Naive', 'CD4 T Memory', 'Treg', 'CD4 CTL']), SIMPL_FINAL_COL] = 'CD4 T'\n",
    "\n",
    "# CD8 T\n",
    "Hao_dataset.obs.loc[d.isin(['CD8 T Naive', 'CD8 T Memory', 'MAIT']), SIMPL_FINAL_COL] = 'CD8 T'\n",
    "\n",
    "# B\n",
    "Hao_dataset.obs.loc[d.isin(['Pre-B', 'B Naive', 'B Memory', 'Immature B']), SIMPL_FINAL_COL] = 'B'\n",
    "\n",
    "# Erythroid\n",
    "Hao_dataset.obs.loc[d.eq('Erythroblast'), SIMPL_FINAL_COL] = 'Erythroid'\n",
    "\n",
    "# Platelet\n",
    "Hao_dataset.obs.loc[d.eq('Platelet'), SIMPL_FINAL_COL] = 'Platelet'\n",
    "\n",
    "# ILC\n",
    "Hao_dataset.obs.loc[d.eq('ILC'), SIMPL_FINAL_COL] = 'ILC'\n",
    "\n",
    "# Other T\n",
    "Hao_dataset.obs.loc[d.isin(['GdT', 'DnT']), SIMPL_FINAL_COL] = 'Other T'\n",
    "\n",
    "# cDC\n",
    "Hao_dataset.obs.loc[d.isin(['cDC1', 'cDC2']), SIMPL_FINAL_COL] = 'cDC'\n",
    "\n",
    "# pDC\n",
    "Hao_dataset.obs.loc[d.eq('pDC'), SIMPL_FINAL_COL] = 'pDC'\n",
    "\n",
    "# Plasma\n",
    "Hao_dataset.obs.loc[d.eq('Plasma'), SIMPL_FINAL_COL] = 'Plasma'\n",
    "\n",
    "# If you have additional refined labels and want them routed:\n",
    "# - Macrophage, Stroma, Myeloid, Doublet can be added here similarly.\n",
    "\n",
    "# Enforce fixed categories/order for simplified_final\n",
    "Hao_dataset.obs[SIMPL_FINAL_COL] = pd.Categorical(Hao_dataset.obs[SIMPL_FINAL_COL], categories=simpl_categories)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build broad_final\n",
    "#    Priority:\n",
    "#      - If simplified_final is Doublet -> Doublet\n",
    "#      - If detailed label indicates progenitor -> Immature\n",
    "#      - Else if simplified_final assigned -> Mature\n",
    "#      - Else -> Other\n",
    "# -----------------------------\n",
    "# Start from NA (already reset)\n",
    "sf = Hao_dataset.obs[SIMPL_FINAL_COL]\n",
    "\n",
    "# Doublet (only if you ever assign it in simplified_final)\n",
    "Hao_dataset.obs.loc[sf.eq(\"Doublet\"), BROAD_FINAL_COL] = \"Doublet\"\n",
    "\n",
    "# Immature progenitors (expand this list if your refined labels include more progenitors)\n",
    "immature_details = [\n",
    "    \"HSC\", \"MPP\", \"LMPP\", \"GMP\", \"MEP\", \"ErP\", \"MkP\",\n",
    "    \"Pre-Pro-B\", \"Pro-B\", \"Pre-B\", \"CLP\"\n",
    "]\n",
    "Hao_dataset.obs.loc[d.isin(immature_details), BROAD_FINAL_COL] = \"Immature\"\n",
    "\n",
    "# Mature: anything with an assigned simplified_final (except Doublet already handled)\n",
    "Hao_dataset.obs.loc[Hao_dataset.obs[BROAD_FINAL_COL].isna(), BROAD_FINAL_COL] = \"Mature\"\n",
    "\n",
    "\n",
    "# Enforce fixed categories/order for broad_final\n",
    "Hao_dataset.obs[BROAD_FINAL_COL] = pd.Categorical(Hao_dataset.obs[BROAD_FINAL_COL], categories=broad_categories)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Sanity checks\n",
    "# -----------------------------\n",
    "na_simpl = int(Hao_dataset.obs[SIMPL_FINAL_COL].isna().sum())\n",
    "na_broad = int(Hao_dataset.obs[BROAD_FINAL_COL].isna().sum())\n",
    "\n",
    "print(f\"Using detail input column: {DETAIL_INPUT}\")\n",
    "print(f\"Unassigned '{SIMPL_FINAL_COL}' (NA) rows: {na_simpl} / {Hao_dataset.n_obs}\")\n",
    "print(f\"Unassigned '{BROAD_FINAL_COL}' (NA) rows: {na_broad} / {Hao_dataset.n_obs}\")\n",
    "\n",
    "print(\"\\nBroad final value counts:\")\n",
    "print(Hao_dataset.obs[BROAD_FINAL_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSimplified final value counts (top 30):\")\n",
    "print(Hao_dataset.obs[SIMPL_FINAL_COL].value_counts(dropna=False).head(30).to_string())\n",
    "\n",
    "# Diagnostics for what is unmapped in simplified_final\n",
    "unmapped = (\n",
    "    Hao_dataset.obs.loc[Hao_dataset.obs[SIMPL_FINAL_COL].isna(), DETAIL_INPUT]\n",
    "    .astype(\"object\")\n",
    "    .fillna(\"<<NA in detailed>>\")\n",
    "    .value_counts()\n",
    "    .head(30)\n",
    ")\n",
    "print(f\"\\nTop unmapped '{DETAIL_INPUT}' labels among NA simplified_final rows (top 30):\")\n",
    "print(unmapped.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hao_dataset.obs['Consensus_annotation_detailed_final'] = Hao_dataset.obs['Consensus_annotation_detailed_refined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Hao_dataset.obs['Consensus_annotation_simplified_final'] = Hao_dataset.obs['Consensus_annotation_simplified_final'].cat.remove_unused_categories()\n",
    "Hao_dataset.obs['Consensus_annotation_detailed_final'] = Hao_dataset.obs['Consensus_annotation_detailed_final'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Hao_dataset, \n",
    "                color='Consensus_annotation_broad_final', \n",
    "                basis='X_wnn.umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Hao Y. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus broad annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/33_Hao_dataset_final_consensus_annotation_broad_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Hao_dataset, \n",
    "                color='Consensus_annotation_simplified_final', \n",
    "                basis='X_wnn.umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Hao Y. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus simplified annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/34_Hao_dataset_final_consensus_annotation_simplified_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Hao_dataset, \n",
    "                color='Consensus_annotation_detailed_final', \n",
    "                basis='X_wnn.umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Hao Y. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/35_Hao_dataset_final_Consensus_annotation_detailed_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triana dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Triana_dataset.obs['Consensus_annotation_simplified'] = Triana_dataset.obs['Consensus_annotation_simplified'].cat.remove_unused_categories()\n",
    "Triana_dataset.obs['Consensus_annotation_detailed'] = Triana_dataset.obs['Consensus_annotation_detailed'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Triana_dataset.obs['Consensus_annotation_detailed'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_categories = counts[counts >= 10].index\n",
    "Triana_dataset = Triana_dataset[Triana_dataset.obs[Triana_dataset.obs['Consensus_annotation_detailed'].isin(filtered_categories)].index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_colors' in Triana_dataset.uns:\n",
    "    del Triana_dataset.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='CellTypes', \n",
    "                basis='X_mofaumap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Triana S. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_colors' in Triana_dataset.uns:\n",
    "    del Triana_dataset.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_mofaumap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Triana S. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "OUT_BROAD  = \"Consensus_annotation_broad\"\n",
    "OUT_SIMPL  = \"Consensus_annotation_simplified\"\n",
    "OUT_DETAIL = \"Consensus_annotation_detailed\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 0) Backup current annotations (optional but matches your intent)\n",
    "# -----------------------------------------------------------------------------\n",
    "Triana_dataset.obs[f\"{OUT_BROAD}_tmp\"]  = Triana_dataset.obs[OUT_BROAD]\n",
    "Triana_dataset.obs[f\"{OUT_SIMPL}_tmp\"]  = Triana_dataset.obs[OUT_SIMPL]\n",
    "Triana_dataset.obs[f\"{OUT_DETAIL}_tmp\"] = Triana_dataset.obs[OUT_DETAIL]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Ensure output columns exist and are OBJECT dtype (safe on reruns)\n",
    "# -----------------------------------------------------------------------------\n",
    "for col in [OUT_BROAD, OUT_SIMPL, OUT_DETAIL]:\n",
    "    if col not in Triana_dataset.obs.columns:\n",
    "        Triana_dataset.obs[col] = pd.NA\n",
    "    if pd.api.types.is_categorical_dtype(Triana_dataset.obs[col]):\n",
    "        Triana_dataset.obs[col] = Triana_dataset.obs[col].astype(\"object\")\n",
    "\n",
    "# Convenience handles\n",
    "ct = Triana_dataset.obs[\"CellTypes\"] if \"CellTypes\" in Triana_dataset.obs.columns else pd.Series(index=Triana_dataset.obs.index, dtype=\"object\")\n",
    "dtmp = Triana_dataset.obs[f\"{OUT_DETAIL}_tmp\"] if f\"{OUT_DETAIL}_tmp\" in Triana_dataset.obs.columns else pd.Series(index=Triana_dataset.obs.index, dtype=\"object\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Apply your overrides (no categorical category wrangling needed)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Early promyelocytes -> GMP (HSPC)\n",
    "m = ct.eq(\"Early promyelocytes\")\n",
    "Triana_dataset.obs.loc[m, OUT_BROAD]  = \"Immature\"\n",
    "Triana_dataset.obs.loc[m, OUT_SIMPL]  = \"HSPC\"\n",
    "Triana_dataset.obs.loc[m, OUT_DETAIL] = \"GMP\"\n",
    "\n",
    "# Plasmacytoid dendritic cell progenitors -> pDC progenitors (HSPC)\n",
    "m = ct.eq(\"Plasmacytoid dendritic cell progenitors\")\n",
    "Triana_dataset.obs.loc[m, OUT_BROAD]  = \"Immature\"\n",
    "Triana_dataset.obs.loc[m, OUT_SIMPL]  = \"HSPC\"\n",
    "Triana_dataset.obs.loc[m, OUT_DETAIL] = \"GMP\"\n",
    "\n",
    "# Late promyelocytes -> GMP (HSPC)\n",
    "m = ct.eq(\"Late promyelocytes\")\n",
    "Triana_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Triana_dataset.obs.loc[m, OUT_SIMPL]  = \"Myeloid\"\n",
    "Triana_dataset.obs.loc[m, OUT_DETAIL] = \"Myeloid progenitor\"\n",
    "\n",
    "# Late promyelocytes -> GMP (HSPC)\n",
    "m = ct.eq(\"Myelocytes\")\n",
    "Triana_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Triana_dataset.obs.loc[m, OUT_SIMPL]  = \"Myeloid\"\n",
    "Triana_dataset.obs.loc[m, OUT_DETAIL] = \"Myeloid progenitor\"\n",
    "\n",
    "# Late erythroid progenitor -> ErP (Erythroid)\n",
    "m = ct.eq(\"Late erythroid progenitor\")\n",
    "Triana_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Triana_dataset.obs.loc[m, OUT_SIMPL]  = \"Erythroid\"\n",
    "Triana_dataset.obs.loc[m, OUT_DETAIL] = \"ErP\"\n",
    "\n",
    "# Eosinophil-basophil-mast cell progenitors -> EoBaMaP (HSPC)\n",
    "m = ct.eq(\"Eosinophil-basophil-mast cell progenitors\")\n",
    "Triana_dataset.obs.loc[m, OUT_BROAD]  = \"Immature\"\n",
    "Triana_dataset.obs.loc[m, OUT_SIMPL]  = \"HSPC\"\n",
    "Triana_dataset.obs.loc[m, OUT_DETAIL] = \"EoBaMaP\"\n",
    "\n",
    "# GammaDelta T cells -> Gamma delta T (CD8 T)\n",
    "m = ct.eq(\"GammaDelta T cells\")\n",
    "Triana_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Triana_dataset.obs.loc[m, OUT_SIMPL]  = \"CD8 T\"\n",
    "Triana_dataset.obs.loc[m, OUT_DETAIL] = \"GdT\"\n",
    "\n",
    "# Conventional dendritic cell 1 -> cDC1 (cDC)\n",
    "m = ct.eq(\"Conventional dendritic cell 1\")\n",
    "Triana_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Triana_dataset.obs.loc[m, OUT_SIMPL]  = \"cDC\"\n",
    "Triana_dataset.obs.loc[m, OUT_DETAIL] = \"cDC1\"\n",
    "\n",
    "# Conventional dendritic cell 2 -> cDC2 (cDC)\n",
    "m = ct.eq(\"Conventional dendritic cell 2\")\n",
    "Triana_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Triana_dataset.obs.loc[m, OUT_SIMPL]  = \"cDC\"\n",
    "Triana_dataset.obs.loc[m, OUT_DETAIL] = \"cDC2\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Optional: convert back to categoricals AFTER all assignments\n",
    "#    (categories inferred; safe and rerunnable)\n",
    "# -----------------------------------------------------------------------------\n",
    "for col in [OUT_BROAD, OUT_SIMPL, OUT_DETAIL]:\n",
    "    Triana_dataset.obs[col] = pd.Categorical(Triana_dataset.obs[col])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Sanity checks\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Value counts (broad) top 20:\")\n",
    "print(Triana_dataset.obs[OUT_BROAD].value_counts(dropna=False).head(20).to_string())\n",
    "\n",
    "print(\"\\nValue counts (simplified) top 20:\")\n",
    "print(Triana_dataset.obs[OUT_SIMPL].value_counts(dropna=False).head(20).to_string())\n",
    "\n",
    "print(\"\\nValue counts (detailed) top 20:\")\n",
    "print(Triana_dataset.obs[OUT_DETAIL].value_counts(dropna=False).head(20).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_colors' in Triana_dataset.uns:\n",
    "    del Triana_dataset.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_mofaumap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Triana S. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HSC cells from Triana dataset\n",
    "HSC_mask = Triana_dataset.obs['Consensus_annotation_detailed'] == 'HSC'\n",
    "hsc_subset = Triana_dataset[HSC_mask].copy()\n",
    "\n",
    "print(f\"Number of HSC cells: {hsc_subset.n_obs}\")\n",
    "print(f\"Original clusters containing HSC: {hsc_subset.obs['CellTypes'].unique()}\")\n",
    "\n",
    "# Check distribution of original cell types within HSC\n",
    "print(\"\\nDistribution of original CellTypes within HSC:\")\n",
    "print(hsc_subset.obs['CellTypes'].value_counts())\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Perform subclustering on HSC cells\n",
    "sc.pp.neighbors(hsc_subset, use_rep=\"X_mofaumap\", n_neighbors=15, metric='euclidean', random_state=42)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.tl.leiden(hsc_subset, resolution=0.5, random_state=42, key_added='hsc_subclusters')\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create UMAP for the HSC subset\n",
    "sc.tl.umap(hsc_subset, random_state=42, min_dist=0.3)\n",
    "\n",
    "# Plot the subclusters\n",
    "sc.pl.embedding(hsc_subset, \n",
    "                color='hsc_subclusters', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=6,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "ax.set_title('HSC Subclustering', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Check original annotations within each subcluster\n",
    "print(\"\\nOriginal CellTypes per subcluster:\")\n",
    "for cluster in sorted(hsc_subset.obs['hsc_subclusters'].unique()):\n",
    "    cluster_cells = hsc_subset.obs[hsc_subset.obs['hsc_subclusters'] == cluster]\n",
    "    print(f\"\\nSubcluster {cluster}:\")\n",
    "    print(cluster_cells['CellTypes'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FULL_BASIS = \"X_mofaumap\"\n",
    "SUBCOL = \"hsc_subclusters\"\n",
    "OUTCOL = \"hsc_subclusters_on_full\"\n",
    "\n",
    "# 1) Create a column in the full dataset and fill with NA\n",
    "Triana_dataset.obs[OUTCOL] = pd.NA\n",
    "\n",
    "# 2) Transfer subcluster labels from subset -> full by index\n",
    "Triana_dataset.obs.loc[hsc_subset.obs_names, OUTCOL] = hsc_subset.obs[SUBCOL].astype(str)\n",
    "\n",
    "# 3) Plot: full embedding, but color by gmp subclusters (non-GMP will be NA)\n",
    "sc.pl.embedding(\n",
    "    Triana_dataset,\n",
    "    color=OUTCOL,\n",
    "    basis=FULL_BASIS,\n",
    "    legend_loc=\"on data\",\n",
    "    legend_fontsize=6,\n",
    "    legend_fontoutline=2,\n",
    "    add_outline=False,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel(\"UMAP 1\", fontsize=12)\n",
    "ax.set_ylabel(\"UMAP 2\", fontsize=12)\n",
    "ax.set_title(\"Triana dataset: HSC subclusters on full embedding\", fontsize=12, fontweight=\"bold\", y=1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SUBCLUSTER_COL = \"hsc_subclusters\"\n",
    "TARGET_COL = \"Consensus_annotation_detailed\"\n",
    "DEFAULT_LABEL = \"MPP\"\n",
    "\n",
    "subcluster_to_pop = {\n",
    "    \"5\": \"HSC\",\n",
    "    \"7\": \"HSC\",\n",
    "    \"1\": \"LMPP\",\n",
    "    \"3\": \"LMPP\",\n",
    "    \"10\": \"LMPP\",\n",
    "    \"4\": \"LMPP\",\n",
    "}\n",
    "\n",
    "# Map subclusters -> labels\n",
    "mapped = hsc_subset.obs[SUBCLUSTER_COL].astype(str).map(subcluster_to_pop)\n",
    "\n",
    "mask_mapped = mapped.notna()\n",
    "mask_unmapped = mapped.isna()\n",
    "\n",
    "mapped_cell_ids = hsc_subset.obs.index[mask_mapped]\n",
    "unmapped_cell_ids = hsc_subset.obs.index[mask_unmapped]\n",
    "\n",
    "print(f\"Mapped via dict: {mask_mapped.sum()} cells\")\n",
    "print(f\"Default to '{DEFAULT_LABEL}': {mask_unmapped.sum()} cells\")\n",
    "\n",
    "# Ensure categories exist if TARGET_COL is categorical\n",
    "new_labels = pd.Index(mapped.loc[mask_mapped].unique()).append(pd.Index([DEFAULT_LABEL])).unique()\n",
    "\n",
    "for ad in [hsc_subset, Triana_dataset]:\n",
    "    if TARGET_COL not in ad.obs.columns:\n",
    "        ad.obs[TARGET_COL] = pd.NA\n",
    "\n",
    "    if pd.api.types.is_categorical_dtype(ad.obs[TARGET_COL]):\n",
    "        missing = new_labels.difference(ad.obs[TARGET_COL].cat.categories)\n",
    "        if len(missing) > 0:\n",
    "            ad.obs[TARGET_COL] = ad.obs[TARGET_COL].cat.add_categories(list(missing))\n",
    "\n",
    "# Assign mapped labels (HSC/MPP/MEP) first\n",
    "hsc_subset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "Triana_dataset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "\n",
    "# Assign default label (LMPP) to the rest\n",
    "hsc_subset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "Triana_dataset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "\n",
    "print(\"\\nUpdated label counts in subset:\")\n",
    "print(hsc_subset.obs[TARGET_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSubcluster -> label breakdown (subset):\")\n",
    "print(hsc_subset.obs.groupby(SUBCLUSTER_COL)[TARGET_COL].value_counts().unstack(fill_value=0).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_colors' in Triana_dataset.uns:\n",
    "    del Triana_dataset.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_mofaumap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Triana S. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HSC cells from Triana dataset\n",
    "GMP_mask = Triana_dataset.obs['Consensus_annotation_detailed'] == 'GMP'\n",
    "gmp_subset = Triana_dataset[GMP_mask].copy()\n",
    "\n",
    "print(f\"Number of GMP cells: {gmp_subset.n_obs}\")\n",
    "print(f\"Original clusters containing GMP: {gmp_subset.obs['CellTypes'].unique()}\")\n",
    "# Check distribution of original cell types within GMP\n",
    "print(\"\\nDistribution of original CellTypes within GMP:\")\n",
    "print(gmp_subset.obs['CellTypes'].value_counts())\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Perform subclustering on GMP cells\n",
    "sc.pp.neighbors(gmp_subset, use_rep=\"X_mofaumap\", n_neighbors=15, metric='euclidean', random_state=42)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.tl.leiden(gmp_subset, resolution=0.5, random_state=42, key_added='gmp_subclusters')\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create UMAP for the GMP subset\n",
    "sc.tl.umap(gmp_subset, random_state=42, min_dist=0.3)\n",
    "\n",
    "# Plot the subclusters\n",
    "sc.pl.embedding(gmp_subset, \n",
    "                color='gmp_subclusters', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=6,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "ax.set_title('GMP Subclustering', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Check original annotations within each subcluster\n",
    "print(\"\\nOriginal CellTypes per subcluster:\")\n",
    "for cluster in sorted(gmp_subset.obs['gmp_subclusters'].unique()):\n",
    "    cluster_cells = gmp_subset.obs[gmp_subset.obs['gmp_subclusters'] == cluster]\n",
    "    print(f\"\\nSubcluster {cluster}:\")\n",
    "    print(cluster_cells['CellTypes'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FULL_BASIS = \"X_mofaumap\"\n",
    "SUBCOL = \"gmp_subclusters\"\n",
    "OUTCOL = \"gmp_subclusters_on_full\"\n",
    "\n",
    "# 1) Create a column in the full dataset and fill with NA\n",
    "Triana_dataset.obs[OUTCOL] = pd.NA\n",
    "\n",
    "# 2) Transfer subcluster labels from subset -> full by index\n",
    "Triana_dataset.obs.loc[gmp_subset.obs_names, OUTCOL] = gmp_subset.obs[SUBCOL].astype(str)\n",
    "\n",
    "# 3) Plot: full embedding, but color by gmp subclusters (non-GMP will be NA)\n",
    "sc.pl.embedding(\n",
    "    Triana_dataset,\n",
    "    color=OUTCOL,\n",
    "    basis=FULL_BASIS,\n",
    "    legend_loc=\"on data\",\n",
    "    legend_fontsize=6,\n",
    "    legend_fontoutline=2,\n",
    "    add_outline=False,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel(\"UMAP 1\", fontsize=12)\n",
    "ax.set_ylabel(\"UMAP 2\", fontsize=12)\n",
    "ax.set_title(\"Triana dataset: GMP subclusters on full embedding\", fontsize=12, fontweight=\"bold\", y=1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SUBCLUSTER_COL = \"gmp_subclusters\"\n",
    "TARGET_COL = \"Consensus_annotation_detailed\"\n",
    "DEFAULT_LABEL = \"GMP\"\n",
    "\n",
    "subcluster_to_pop = {\n",
    "    \"4\": \"LMPP\",\n",
    "    \"5\": \"LMPP\",\n",
    "    \"2\": \"LMPP\",\n",
    "    \"10\": \"LMPP\",\n",
    "    \"17\": \"MPP\",\n",
    "    \"14\": \"MEP\"\n",
    "}\n",
    "\n",
    "# Map subclusters -> labels\n",
    "mapped = gmp_subset.obs[SUBCLUSTER_COL].astype(str).map(subcluster_to_pop)\n",
    "\n",
    "mask_mapped = mapped.notna()\n",
    "mask_unmapped = mapped.isna()\n",
    "\n",
    "mapped_cell_ids = gmp_subset.obs.index[mask_mapped]\n",
    "unmapped_cell_ids = gmp_subset.obs.index[mask_unmapped]\n",
    "\n",
    "print(f\"Mapped via dict: {mask_mapped.sum()} cells\")\n",
    "print(f\"Default to '{DEFAULT_LABEL}': {mask_unmapped.sum()} cells\")\n",
    "\n",
    "# Ensure categories exist if TARGET_COL is categorical\n",
    "new_labels = pd.Index(mapped.loc[mask_mapped].unique()).append(pd.Index([DEFAULT_LABEL])).unique()\n",
    "\n",
    "for ad in [gmp_subset, Triana_dataset]:\n",
    "    if TARGET_COL not in ad.obs.columns:\n",
    "        ad.obs[TARGET_COL] = pd.NA\n",
    "\n",
    "    if pd.api.types.is_categorical_dtype(ad.obs[TARGET_COL]):\n",
    "        missing = new_labels.difference(ad.obs[TARGET_COL].cat.categories)\n",
    "        if len(missing) > 0:\n",
    "            ad.obs[TARGET_COL] = ad.obs[TARGET_COL].cat.add_categories(list(missing))\n",
    "\n",
    "# Assign mapped labels (HSC/MPP/MEP) first\n",
    "gmp_subset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "Triana_dataset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "\n",
    "# Assign default label (LMPP) to the rest\n",
    "gmp_subset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "Triana_dataset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "\n",
    "print(\"\\nUpdated label counts in subset:\")\n",
    "print(gmp_subset.obs[TARGET_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSubcluster -> label breakdown (subset):\")\n",
    "print(gmp_subset.obs.groupby(SUBCLUSTER_COL)[TARGET_COL].value_counts().unstack(fill_value=0).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_colors' in Triana_dataset.uns:\n",
    "    del Triana_dataset.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_mofaumap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Triana S. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HSC cells from Triana dataset\n",
    "LMPP_mask = Triana_dataset.obs['Consensus_annotation_detailed'] == 'LMPP'\n",
    "lmpp_subset = Triana_dataset[LMPP_mask].copy()\n",
    "\n",
    "print(f\"Number of LMPP cells: {lmpp_subset.n_obs}\")\n",
    "print(f\"Original clusters containing LMPP: {lmpp_subset.obs['CellTypes'].unique()}\")\n",
    "# Check distribution of original cell types within LMPP\n",
    "print(\"\\nDistribution of original CellTypes within LMPP:\")\n",
    "print(lmpp_subset.obs['CellTypes'].value_counts())\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Perform subclustering on LMPP cells\n",
    "sc.pp.neighbors(lmpp_subset, use_rep=\"X_mofaumap\", n_neighbors=15, metric='euclidean', random_state=42)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.tl.leiden(lmpp_subset, resolution=0.5, random_state=42, key_added='lmpp_subclusters')\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create UMAP for the LMPP subset\n",
    "sc.tl.umap(lmpp_subset, random_state=42, min_dist=0.3)\n",
    "\n",
    "# Plot the subclusters\n",
    "sc.pl.embedding(lmpp_subset, \n",
    "                color='lmpp_subclusters', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=6,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "ax.set_title('LMPP Subclustering', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Check original annotations within each subcluster\n",
    "print(\"\\nOriginal CellTypes per subcluster:\")\n",
    "for cluster in sorted(lmpp_subset.obs['lmpp_subclusters'].unique()):\n",
    "    cluster_cells = lmpp_subset.obs[lmpp_subset.obs['lmpp_subclusters'] == cluster]\n",
    "    print(f\"\\nSubcluster {cluster}:\")\n",
    "    print(cluster_cells['CellTypes'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FULL_BASIS = \"X_mofaumap\"\n",
    "SUBCOL = \"lmpp_subclusters\"\n",
    "OUTCOL = \"lmpp_subclusters_on_full\"\n",
    "\n",
    "# 1) Create a column in the full dataset and fill with NA\n",
    "Triana_dataset.obs[OUTCOL] = pd.NA\n",
    "\n",
    "# 2) Transfer subcluster labels from subset -> full by index\n",
    "Triana_dataset.obs.loc[lmpp_subset.obs_names, OUTCOL] = lmpp_subset.obs[SUBCOL].astype(str)\n",
    "\n",
    "# 3) Plot: full embedding, but color by lmpp subclusters (non-LMPP will be NA)\n",
    "sc.pl.embedding(\n",
    "    Triana_dataset,\n",
    "    color=OUTCOL,\n",
    "    basis=FULL_BASIS,\n",
    "    legend_loc=\"on data\",\n",
    "    legend_fontsize=6,\n",
    "    legend_fontoutline=2,\n",
    "    add_outline=False,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel(\"UMAP 1\", fontsize=12)\n",
    "ax.set_ylabel(\"UMAP 2\", fontsize=12)\n",
    "ax.set_title(\"Triana dataset: LMPP subclusters on full embedding\", fontsize=12, fontweight=\"bold\", y=1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SUBCLUSTER_COL = \"lmpp_subclusters\"\n",
    "TARGET_COL = \"Consensus_annotation_detailed\"\n",
    "DEFAULT_LABEL = \"LMPP\"\n",
    "\n",
    "subcluster_to_pop = {\n",
    "    \"6\": \"Pre-Pro-B\",\n",
    "}\n",
    "\n",
    "# Map subclusters -> labels\n",
    "mapped = lmpp_subset.obs[SUBCLUSTER_COL].astype(str).map(subcluster_to_pop)\n",
    "\n",
    "mask_mapped = mapped.notna()\n",
    "mask_unmapped = mapped.isna()\n",
    "\n",
    "mapped_cell_ids = lmpp_subset.obs.index[mask_mapped]\n",
    "unmapped_cell_ids = lmpp_subset.obs.index[mask_unmapped]\n",
    "\n",
    "print(f\"Mapped via dict: {mask_mapped.sum()} cells\")\n",
    "print(f\"Default to '{DEFAULT_LABEL}': {mask_unmapped.sum()} cells\")\n",
    "\n",
    "# Ensure categories exist if TARGET_COL is categorical\n",
    "new_labels = pd.Index(mapped.loc[mask_mapped].unique()).append(pd.Index([DEFAULT_LABEL])).unique()\n",
    "\n",
    "for ad in [lmpp_subset, Triana_dataset]:\n",
    "    if TARGET_COL not in ad.obs.columns:\n",
    "        ad.obs[TARGET_COL] = pd.NA\n",
    "\n",
    "    if pd.api.types.is_categorical_dtype(ad.obs[TARGET_COL]):\n",
    "        missing = new_labels.difference(ad.obs[TARGET_COL].cat.categories)\n",
    "        if len(missing) > 0:\n",
    "            ad.obs[TARGET_COL] = ad.obs[TARGET_COL].cat.add_categories(list(missing))\n",
    "\n",
    "# Assign mapped labels (HSC/MPP/MEP) first\n",
    "lmpp_subset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "Triana_dataset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "\n",
    "# Assign default label (LMPP) to the rest\n",
    "lmpp_subset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "Triana_dataset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "\n",
    "print(\"\\nUpdated label counts in subset:\")\n",
    "print(lmpp_subset.obs[TARGET_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSubcluster -> label breakdown (subset):\")\n",
    "print(lmpp_subset.obs.groupby(SUBCLUSTER_COL)[TARGET_COL].value_counts().unstack(fill_value=0).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "OUT_BROAD  = \"Consensus_annotation_broad\"\n",
    "OUT_SIMPL  = \"Consensus_annotation_simplified\"\n",
    "OUT_DETAIL = \"Consensus_annotation_detailed\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 0) Backup current annotations (optional but matches your intent)\n",
    "# -----------------------------------------------------------------------------\n",
    "Triana_dataset.obs[f\"{OUT_BROAD}_tmp\"]  = Triana_dataset.obs[OUT_BROAD]\n",
    "Triana_dataset.obs[f\"{OUT_SIMPL}_tmp\"]  = Triana_dataset.obs[OUT_SIMPL]\n",
    "Triana_dataset.obs[f\"{OUT_DETAIL}_tmp\"] = Triana_dataset.obs[OUT_DETAIL]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Ensure output columns exist and are OBJECT dtype (safe on reruns)\n",
    "# -----------------------------------------------------------------------------\n",
    "for col in [OUT_BROAD, OUT_SIMPL, OUT_DETAIL]:\n",
    "    if col not in Triana_dataset.obs.columns:\n",
    "        Triana_dataset.obs[col] = pd.NA\n",
    "    if pd.api.types.is_categorical_dtype(Triana_dataset.obs[col]):\n",
    "        Triana_dataset.obs[col] = Triana_dataset.obs[col].astype(\"object\")\n",
    "\n",
    "# Convenience handles\n",
    "ct = Triana_dataset.obs[\"CellTypes\"] if \"CellTypes\" in Triana_dataset.obs.columns else pd.Series(index=Triana_dataset.obs.index, dtype=\"object\")\n",
    "dtmp = Triana_dataset.obs[f\"{OUT_DETAIL}_tmp\"] if f\"{OUT_DETAIL}_tmp\" in Triana_dataset.obs.columns else pd.Series(index=Triana_dataset.obs.index, dtype=\"object\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Apply your overrides (no categorical category wrangling needed)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Pro-B cells\n",
    "m = ct.eq(\"Pro-B cells\")\n",
    "Triana_dataset.obs.loc[m, OUT_BROAD]  = \"Immature\"\n",
    "Triana_dataset.obs.loc[m, OUT_SIMPL]  = \"HSPC\"\n",
    "Triana_dataset.obs.loc[m, OUT_DETAIL] = \"Pro-B\"\n",
    "\n",
    "# Pre-B cells\n",
    "m = ct.eq(\"Pre-B cells\")\n",
    "Triana_dataset.obs.loc[m, OUT_BROAD]  = \"Mature\"\n",
    "Triana_dataset.obs.loc[m, OUT_SIMPL]  = \"B\"\n",
    "Triana_dataset.obs.loc[m, OUT_DETAIL] = \"Pre-B\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Optional: convert back to categoricals AFTER all assignments\n",
    "#    (categories inferred; safe and rerunnable)\n",
    "# -----------------------------------------------------------------------------\n",
    "for col in [OUT_BROAD, OUT_SIMPL, OUT_DETAIL]:\n",
    "    Triana_dataset.obs[col] = pd.Categorical(Triana_dataset.obs[col])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Sanity checks\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Value counts (broad) top 20:\")\n",
    "print(Triana_dataset.obs[OUT_BROAD].value_counts(dropna=False).head(20).to_string())\n",
    "\n",
    "print(\"\\nValue counts (simplified) top 20:\")\n",
    "print(Triana_dataset.obs[OUT_SIMPL].value_counts(dropna=False).head(20).to_string())\n",
    "\n",
    "print(\"\\nValue counts (detailed) top 20:\")\n",
    "print(Triana_dataset.obs[OUT_DETAIL].value_counts(dropna=False).head(20).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_colors' in Triana_dataset.uns:\n",
    "    del Triana_dataset.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_mofaumap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Triana S. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Triana_dataset.obs['Consensus_annotation_detailed'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# Calculate silhouette scores for current annotations\n",
    "print(\"Calculating silhouette scores for Triana dataset...\")\n",
    "\n",
    "# Use the harmony-corrected PCA representation for silhouette analysis\n",
    "X_embed = Triana_dataset.obsm['X_mofaumap']\n",
    "labels = Triana_dataset.obs['Consensus_annotation_detailed'].astype('category').cat.codes\n",
    "\n",
    "# Calculate silhouette scores\n",
    "silhouette_avg = silhouette_score(X_embed, labels)\n",
    "sample_silhouette_values = silhouette_samples(X_embed, labels)\n",
    "\n",
    "print(f\"Average silhouette score: {silhouette_avg:.3f}\")\n",
    "\n",
    "# Add silhouette scores to the dataset\n",
    "Triana_dataset.obs['silhouette_score'] = sample_silhouette_values\n",
    "\n",
    "# Identify cells with negative silhouette scores\n",
    "negative_silhouette_mask = sample_silhouette_values < 0\n",
    "print(f\"Number of cells with negative silhouette scores: {negative_silhouette_mask.sum()}\")\n",
    "print(f\"Percentage of cells with negative silhouette scores: {negative_silhouette_mask.sum()/len(sample_silhouette_values)*100:.2f}%\")\n",
    "\n",
    "# Show distribution of silhouette scores by cell type\n",
    "silhouette_by_type = Triana_dataset.obs.groupby('Consensus_annotation_detailed')['silhouette_score'].agg(['mean', 'std', 'min', 'max', 'count'])\n",
    "print(\"\\nSilhouette scores by cell type:\")\n",
    "print(silhouette_by_type.sort_values('mean'))\n",
    "\n",
    "# Initialize refined annotations (start with original smoothed annotations)\n",
    "Triana_dataset.obs['Consensus_annotation_detailed_refined'] = Triana_dataset.obs['Consensus_annotation_detailed'].copy()\n",
    "\n",
    "# Perform silhouette-based reassignment\n",
    "print(\"\\n=== PERFORMING SILHOUETTE-BASED REASSIGNMENT ===\")\n",
    "\n",
    "# Identify cells with very poor silhouette scores (< -0.1)\n",
    "very_poor_silhouette = Triana_dataset.obs['silhouette_score'] < -0.1\n",
    "\n",
    "if very_poor_silhouette.sum() > 0:\n",
    "    print(f\"Found {very_poor_silhouette.sum()} cells with very poor silhouette scores (< -0.1)\")\n",
    "    \n",
    "    # Fit nearest neighbors\n",
    "    nn = NearestNeighbors(n_neighbors=30, metric='euclidean')\n",
    "    nn.fit(X_embed)\n",
    "    \n",
    "    # Get indices of poorly assigned cells\n",
    "    poor_indices = np.where(very_poor_silhouette)[0]\n",
    "    \n",
    "    reassignments_made = 0\n",
    "    \n",
    "    for idx in poor_indices:\n",
    "        # Find neighbors for this cell\n",
    "        distances, neighbor_indices = nn.kneighbors([X_embed[idx]])\n",
    "        neighbor_indices = neighbor_indices[0][1:]  # Exclude the cell itself\n",
    "        \n",
    "        # Get annotations of neighbors\n",
    "        neighbor_annotations = Triana_dataset.obs['Consensus_annotation_detailed'].iloc[neighbor_indices]\n",
    "\n",
    "        # Find most common annotation among neighbors\n",
    "        most_common = neighbor_annotations.mode()\n",
    "        \n",
    "        if len(most_common) > 0:\n",
    "            new_annotation = most_common.iloc[0]\n",
    "            current_annotation = Triana_dataset.obs['Consensus_annotation_detailed'].iloc[idx]\n",
    "            \n",
    "            # Only reassign if the most common neighbor annotation is different\n",
    "            if new_annotation != current_annotation:\n",
    "                # Check if at least 40% of neighbors have this annotation\n",
    "                fraction = (neighbor_annotations == new_annotation).sum() / len(neighbor_annotations)\n",
    "                \n",
    "                if fraction >= 0.4:\n",
    "                    Triana_dataset.obs.loc[Triana_dataset.obs.index[idx], 'Consensus_annotation_detailed_refined'] = new_annotation\n",
    "                    reassignments_made += 1\n",
    "    \n",
    "    print(f\"Reassigned {reassignments_made} cells based on neighborhood consensus\")\n",
    "    \n",
    "    # Recalculate silhouette scores after reassignment\n",
    "    new_labels = Triana_dataset.obs['Consensus_annotation_detailed_refined'].astype('category').cat.codes\n",
    "    new_silhouette_scores = silhouette_samples(X_embed, new_labels)\n",
    "    silhouette_avg_corrected = silhouette_score(X_embed, new_labels)\n",
    "    \n",
    "    # Store corrected scores\n",
    "    Triana_dataset.obs['silhouette_score_corrected'] = new_silhouette_scores\n",
    "    \n",
    "    print(f\"\\n=== REASSIGNMENT RESULTS ===\")\n",
    "    print(f\"Original average silhouette: {silhouette_avg:.3f}\")\n",
    "    print(f\"Refined average silhouette: {silhouette_avg_corrected:.3f}\")\n",
    "    print(f\"Improvement: {silhouette_avg_corrected - silhouette_avg:.3f}\")\n",
    "    \n",
    "    print(f\"Original negative silhouette cells: {negative_silhouette_mask.sum()}\")\n",
    "    print(f\"Refined negative silhouette cells: {(new_silhouette_scores < 0).sum()}\")\n",
    "    \n",
    "    # Show what changes were made\n",
    "    if reassignments_made > 0:\n",
    "        changes_mask = (Triana_dataset.obs['Consensus_annotation_detailed'] != \n",
    "                       Triana_dataset.obs['Consensus_annotation_detailed_refined'])\n",
    "        changes = Triana_dataset.obs[changes_mask]\n",
    "        \n",
    "        print(f\"\\n=== SPECIFIC REASSIGNMENTS ===\")\n",
    "        change_summary = changes.groupby([\n",
    "            'Consensus_annotation_detailed', \n",
    "            'Consensus_annotation_detailed_refined'\n",
    "        ]).size().reset_index(name='count')\n",
    "        \n",
    "        for _, row in change_summary.iterrows():\n",
    "            print(f\"{row['Consensus_annotation_detailed']} -> {row['Consensus_annotation_detailed_refined']}: {row['count']} cells\")\n",
    "\n",
    "else:\n",
    "    print(\"No cells with very poor silhouette scores found.\")\n",
    "    # Create corrected scores column that's identical to original\n",
    "    Triana_dataset.obs['silhouette_score_corrected'] = Triana_dataset.obs['silhouette_score'].copy()\n",
    "    silhouette_avg_corrected = silhouette_avg\n",
    "\n",
    "# Create a reassignment status column for visualization\n",
    "reassignment_mask = (Triana_dataset.obs['Consensus_annotation_detailed'] != \n",
    "                    Triana_dataset.obs['Consensus_annotation_detailed_refined'])\n",
    "Triana_dataset.obs['reassignment_status'] = 'Unchanged'\n",
    "Triana_dataset.obs.loc[reassignment_mask, 'reassignment_status'] = 'Reassigned'\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n=== FINAL SUMMARY ===\")\n",
    "print(f\"Total cells: {len(Triana_dataset)}\")\n",
    "print(f\"Cells reassigned: {reassignment_mask.sum()}\")\n",
    "print(f\"Final cell type distribution:\")\n",
    "final_counts = Triana_dataset.obs['Consensus_annotation_detailed_refined'].value_counts()\n",
    "print(final_counts)\n",
    "\n",
    "# Plot comprehensive analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Original annotations\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_mofaumap',\n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[0,0])\n",
    "axes[0,0].set_title('Original Smoothed Annotations', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 2: Refined annotations\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='Consensus_annotation_detailed_refined', \n",
    "                basis='X_mofaumap',\n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[0,1])\n",
    "axes[0,1].set_title('Silhouette-Refined Annotations', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 3: Reassignment status\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='reassignment_status', \n",
    "                basis='X_mofaumap',\n",
    "                palette={'Unchanged': 'lightgray', 'Reassigned': 'red'},\n",
    "                add_outline=False,\n",
    "                legend_loc='right margin', \n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[1,0])\n",
    "axes[1,0].set_title('Reassignment Status', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 4: Corrected silhouette scores\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='silhouette_score_corrected', \n",
    "                basis='X_mofaumap',\n",
    "                color_map='RdBu_r',\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[1,1])\n",
    "axes[1,1].set_title('Silhouette Scores (Refined)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path + \"/36_Triana_dataset_silhouette_refinement_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Additional histogram comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Original silhouette distribution\n",
    "ax1.hist(sample_silhouette_values, bins=50, alpha=0.7, edgecolor='black', color='lightblue')\n",
    "ax1.axvline(x=0, color='red', linestyle='--', label='Silhouette = 0')\n",
    "ax1.set_xlabel('Silhouette Score')\n",
    "ax1.set_ylabel('Number of Cells')\n",
    "ax1.set_title(f'Original Silhouette Distribution\\n(Avg: {silhouette_avg:.3f})')\n",
    "ax1.legend()\n",
    "\n",
    "# Refined silhouette distribution\n",
    "ax2.hist(Triana_dataset.obs['silhouette_score_corrected'], bins=50, alpha=0.7, edgecolor='black', color='lightgreen')\n",
    "ax2.axvline(x=0, color='red', linestyle='--', label='Silhouette = 0')\n",
    "ax2.set_xlabel('Silhouette Score')\n",
    "ax2.set_ylabel('Number of Cells')\n",
    "ax2.set_title(f'Refined Silhouette Distribution\\n(Avg: {silhouette_avg_corrected:.3f})')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path + \"/37_Triana_dataset_silhouette_distribution_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Triana_dataset.obs['Consensus_annotation_simplified'] = Triana_dataset.obs['Consensus_annotation_simplified'].cat.remove_unused_categories()\n",
    "Triana_dataset.obs['Consensus_annotation_detailed_refined'] = Triana_dataset.obs['Consensus_annotation_detailed_refined'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Triana_dataset.obs['Consensus_annotation_detailed_refined'].value_counts()\n",
    "filtered_categories = counts[counts >= 10].index\n",
    "Triana_dataset = Triana_dataset[Triana_dataset.obs[Triana_dataset.obs['Consensus_annotation_detailed_refined'].isin(filtered_categories)].index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Triana_dataset_normalized = Triana_dataset.copy()\n",
    "ep.Normalise_protein_data(Triana_dataset_normalized, inplace=True, axis=1, flavor=\"seurat\")\n",
    "sc.tl.rank_genes_groups(Triana_dataset_normalized, 'Consensus_annotation_detailed_refined', method='wilcoxon')\n",
    "sc.pl.rank_genes_groups(Triana_dataset_normalized, n_genes=10, sharey=False, ncols = 3, fontsize = 14)\n",
    "\n",
    "plt.savefig(figures_path + \"/38_Triana_dataset_top10_markers.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AveragedExpression = grouped_obs_mean(Triana_dataset_normalized, 'Consensus_annotation_detailed_refined')\n",
    "df = pd.DataFrame(AveragedExpression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = df.corr(method='pearson')\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(235, 15, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "heatmap = sns.heatmap(corr, mask=mask, cmap=cmap, annot=True, \n",
    "                        square=True, linewidths=.6, cbar_kws={\"shrink\": 1},\n",
    "                        annot_kws={\"fontsize\":5})\n",
    "\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12)\n",
    "\n",
    "plt.savefig(figures_path + \"/39_Triana_dataset_correlation_heatmap.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# Triana_dataset: build *_final columns (broad_final + simplified_final) Zhang-style\n",
    "# - Safe on reruns (casts to object before assignment)\n",
    "# - Deterministic (resets outputs each run)\n",
    "# - Enforces fixed category orders at the end\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Column names\n",
    "# -----------------------------\n",
    "DETAIL_REFINED_COL  = \"Consensus_annotation_detailed_refined\"\n",
    "DETAIL_FALLBACK_COL = \"Consensus_annotation_detailed\"\n",
    "\n",
    "BROAD_FINAL_COL = \"Consensus_annotation_broad_final\"\n",
    "SIMPL_FINAL_COL = \"Consensus_annotation_simplified_final\"\n",
    "\n",
    "# If refined detailed does not exist, fall back\n",
    "DETAIL_INPUT = DETAIL_REFINED_COL if DETAIL_REFINED_COL in Triana_dataset.obs.columns else DETAIL_FALLBACK_COL\n",
    "\n",
    "# -----------------------------\n",
    "# Fixed category orders (from your Triana simplified_final spec)\n",
    "# -----------------------------\n",
    "broad_categories = [\"Immature\", \"Mature\", \"Doublet\"]\n",
    "\n",
    "simpl_categories = [\n",
    "    'HSPC', 'Monocyte', 'CD4 T', 'CD8 T', 'Erythroid', 'B', 'cDC', 'pDC', 'NK',\n",
    "    'ILC', 'Stroma', 'Myeloid', 'Other T', 'Plasma', 'Mesenchymal'\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Ensure *_final columns exist and are OBJECT dtype (safe on reruns)\n",
    "# -----------------------------\n",
    "for col in [BROAD_FINAL_COL, SIMPL_FINAL_COL]:\n",
    "    if col not in Triana_dataset.obs.columns:\n",
    "        Triana_dataset.obs[col] = pd.NA\n",
    "    if pd.api.types.is_categorical_dtype(Triana_dataset.obs[col]):\n",
    "        Triana_dataset.obs[col] = Triana_dataset.obs[col].astype(\"object\")\n",
    "\n",
    "# Reset each run so reruns are deterministic\n",
    "Triana_dataset.obs[BROAD_FINAL_COL] = pd.NA\n",
    "Triana_dataset.obs[SIMPL_FINAL_COL] = pd.NA\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Build simplified_final from detailed_refined (or fallback detailed)\n",
    "# -----------------------------\n",
    "d = Triana_dataset.obs[DETAIL_INPUT]\n",
    "\n",
    "# HSPC\n",
    "Triana_dataset.obs.loc[d.isin(['HSC', 'MPP', 'LMPP', 'EoBaMaP', 'MkP', 'MEP', 'Pre-Pro-B', 'Pro-B', 'GMP']),\n",
    "                       SIMPL_FINAL_COL] = 'HSPC'\n",
    "\n",
    "# Monocyte\n",
    "Triana_dataset.obs.loc[d.isin(['CD14 Mono', 'CD16 Mono']), SIMPL_FINAL_COL] = 'Monocyte'\n",
    "\n",
    "# Myeloid\n",
    "Triana_dataset.obs.loc[d.isin(['Myeloid progenitor']), SIMPL_FINAL_COL] = 'Myeloid'\n",
    "\n",
    "# NK\n",
    "Triana_dataset.obs.loc[d.isin(['NK CD56 dim', 'NK CD56 bright']), SIMPL_FINAL_COL] = 'NK'\n",
    "\n",
    "# CD4 T\n",
    "Triana_dataset.obs.loc[d.isin(['CD4 T Naive', 'CD4 T Memory', 'Treg', 'CD4 CTL']), SIMPL_FINAL_COL] = 'CD4 T'\n",
    "\n",
    "# CD8 T\n",
    "Triana_dataset.obs.loc[d.isin(['CD8 T Naive', 'CD8 T Memory', 'MAIT']), SIMPL_FINAL_COL] = 'CD8 T'\n",
    "\n",
    "# B\n",
    "Triana_dataset.obs.loc[d.isin(['B Naive', 'B Memory', 'Immature B', 'Pre-B']), SIMPL_FINAL_COL] = 'B'\n",
    "\n",
    "# Erythroid\n",
    "Triana_dataset.obs.loc[d.isin(['ErP', 'Erythroblast']), SIMPL_FINAL_COL] = 'Erythroid'\n",
    "\n",
    "# Mesenchymal\n",
    "Triana_dataset.obs.loc[d.eq('Mesenchymal'), SIMPL_FINAL_COL] = 'Mesenchymal'\n",
    "\n",
    "# cDC\n",
    "Triana_dataset.obs.loc[d.isin(['cDC1', 'cDC2']), SIMPL_FINAL_COL] = 'cDC'\n",
    "\n",
    "# Other T\n",
    "Triana_dataset.obs.loc[d.isin(['GdT']), SIMPL_FINAL_COL] = 'Other T'\n",
    "\n",
    "# pDC\n",
    "Triana_dataset.obs.loc[d.eq('pDC'), SIMPL_FINAL_COL] = 'pDC'\n",
    "\n",
    "# Stroma\n",
    "Triana_dataset.obs.loc[d.eq('Stroma'), SIMPL_FINAL_COL] = 'Stroma'\n",
    "\n",
    "# Plasma\n",
    "Triana_dataset.obs.loc[d.eq('Plasma'), SIMPL_FINAL_COL] = 'Plasma'\n",
    "\n",
    "# NOTE: You included 'Pro-B' as a simplified category but did not map anything to it.\n",
    "# If you intended Pro-B to be a simplified bucket (distinct from HSPC), uncomment:\n",
    "# Triana_dataset.obs.loc[d.eq('Pro-B'), SIMPL_FINAL_COL] = 'Pro-B'\n",
    "# (Doing so would override the HSPC assignment for 'Pro-B'.)\n",
    "\n",
    "# Enforce fixed categories/order for simplified_final\n",
    "Triana_dataset.obs[SIMPL_FINAL_COL] = pd.Categorical(Triana_dataset.obs[SIMPL_FINAL_COL], categories=simpl_categories)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build broad_final\n",
    "#    Priority:\n",
    "#      - If simplified_final is Doublet -> Doublet\n",
    "#      - If detailed label indicates progenitor -> Immature\n",
    "#      - Else if simplified_final assigned -> Mature\n",
    "#      - Else -> Other\n",
    "# -----------------------------\n",
    "sf = Triana_dataset.obs[SIMPL_FINAL_COL]\n",
    "\n",
    "# Doublet (only if you ever assign it in simplified_final)\n",
    "Triana_dataset.obs.loc[sf.eq(\"Doublet\"), BROAD_FINAL_COL] = \"Doublet\"\n",
    "\n",
    "# Immature progenitors (expand if needed)\n",
    "immature_details = ['HSC', 'MPP', 'LMPP', 'EoBaMaP', 'MkP', 'MEP', 'Pre-Pro-B', 'Pro-B', 'GMP', 'ErP']\n",
    "Triana_dataset.obs.loc[d.isin(immature_details), BROAD_FINAL_COL] = \"Immature\"\n",
    "\n",
    "# Mature: anything with an assigned simplified_final (and not already Immature/Doublet)\n",
    "Triana_dataset.obs.loc[Triana_dataset.obs[BROAD_FINAL_COL].isna(), BROAD_FINAL_COL] = \"Mature\"\n",
    "\n",
    "# Enforce fixed categories/order for broad_final\n",
    "Triana_dataset.obs[BROAD_FINAL_COL] = pd.Categorical(Triana_dataset.obs[BROAD_FINAL_COL], categories=broad_categories)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Sanity checks\n",
    "# -----------------------------\n",
    "na_simpl = int(Triana_dataset.obs[SIMPL_FINAL_COL].isna().sum())\n",
    "na_broad = int(Triana_dataset.obs[BROAD_FINAL_COL].isna().sum())\n",
    "\n",
    "print(f\"Using detail input column: {DETAIL_INPUT}\")\n",
    "print(f\"Unassigned '{SIMPL_FINAL_COL}' (NA) rows: {na_simpl} / {Triana_dataset.n_obs}\")\n",
    "print(f\"Unassigned '{BROAD_FINAL_COL}' (NA) rows: {na_broad} / {Triana_dataset.n_obs}\")\n",
    "\n",
    "print(\"\\nBroad final value counts:\")\n",
    "print(Triana_dataset.obs[BROAD_FINAL_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSimplified final value counts (top 30):\")\n",
    "print(Triana_dataset.obs[SIMPL_FINAL_COL].value_counts(dropna=False).head(30).to_string())\n",
    "\n",
    "# Diagnostics for what is unmapped in simplified_final\n",
    "unmapped = (\n",
    "    Triana_dataset.obs.loc[Triana_dataset.obs[SIMPL_FINAL_COL].isna(), DETAIL_INPUT]\n",
    "    .astype(\"object\")\n",
    "    .fillna(\"<<NA in detailed>>\")\n",
    "    .value_counts()\n",
    "    .head(30)\n",
    ")\n",
    "print(f\"\\nTop unmapped '{DETAIL_INPUT}' labels among NA simplified_final rows (top 30):\")\n",
    "print(unmapped.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Triana_dataset.obs['Consensus_annotation_detailed_final'] = Triana_dataset.obs['Consensus_annotation_detailed_refined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Triana_dataset.obs['Consensus_annotation_simplified_final'] = Triana_dataset.obs['Consensus_annotation_simplified_final'].cat.remove_unused_categories()\n",
    "Triana_dataset.obs['Consensus_annotation_detailed_final'] = Triana_dataset.obs['Consensus_annotation_detailed_final'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_final_colors' in Triana_dataset.uns:\n",
    "    del Triana_dataset.uns['Consensus_annotation_detailed_final_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='Consensus_annotation_detailed_final', \n",
    "                basis='X_mofaumap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Triana S. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HSC cells from Triana dataset\n",
    "NK_mask = Triana_dataset.obs['Consensus_annotation_detailed_final'] == 'NK CD56 dim'\n",
    "nk_subset = Triana_dataset[NK_mask].copy()\n",
    "\n",
    "print(f\"Number of NK CD56 dim cells: {nk_subset.n_obs}\")\n",
    "print(f\"Original clusters containing NK CD56 dim: {nk_subset.obs['CellTypes'].unique()}\")\n",
    "# Check distribution of original cell types within NK CD56 dim\n",
    "print(\"\\nDistribution of original CellTypes within NK CD56 dim:\")\n",
    "print(nk_subset.obs['CellTypes'].value_counts())\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Perform subclustering on NK CD56 dim cells\n",
    "sc.pp.neighbors(nk_subset, use_rep=\"X_mofaumap\", n_neighbors=15, metric='euclidean', random_state=42)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.tl.leiden(nk_subset, resolution=0.5, random_state=42, key_added='nk_subclusters')\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create UMAP for the NK CD56 dim subset\n",
    "sc.tl.umap(nk_subset, random_state=42, min_dist=0.3)\n",
    "\n",
    "# Plot the subclusters\n",
    "sc.pl.embedding(nk_subset, \n",
    "                color='nk_subclusters', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=6,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "ax.set_title('NK CD56 dim Subclustering', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Check original annotations within each subcluster\n",
    "print(\"\\nOriginal CellTypes per subcluster:\")\n",
    "for cluster in sorted(nk_subset.obs['nk_subclusters'].unique()):\n",
    "    cluster_cells = nk_subset.obs[nk_subset.obs['nk_subclusters'] == cluster]\n",
    "    print(f\"\\nSubcluster {cluster}:\")\n",
    "    print(cluster_cells['CellTypes'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FULL_BASIS = \"X_mofaumap\"\n",
    "SUBCOL = \"nk_subclusters\"\n",
    "OUTCOL = \"nk_subclusters_on_full\"\n",
    "\n",
    "# 1) Create a column in the full dataset and fill with NA\n",
    "Triana_dataset.obs[OUTCOL] = pd.NA\n",
    "\n",
    "# 2) Transfer subcluster labels from subset -> full by index\n",
    "Triana_dataset.obs.loc[nk_subset.obs_names, OUTCOL] = nk_subset.obs[SUBCOL].astype(str)\n",
    "\n",
    "# 3) Plot: full embedding, but color by gmp subclusters (non-GMP will be NA)\n",
    "sc.pl.embedding(\n",
    "    Triana_dataset,\n",
    "    color=OUTCOL,\n",
    "    basis=FULL_BASIS,\n",
    "    legend_loc=\"on data\",\n",
    "    legend_fontsize=6,\n",
    "    legend_fontoutline=2,\n",
    "    add_outline=False,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel(\"UMAP 1\", fontsize=12)\n",
    "ax.set_ylabel(\"UMAP 2\", fontsize=12)\n",
    "ax.set_title(\"Triana dataset: NK CD56 dim subclusters on full embedding\", fontsize=12, fontweight=\"bold\", y=1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SUBCLUSTER_COL = \"nk_subclusters\"\n",
    "TARGET_COL = \"Consensus_annotation_detailed_final\"\n",
    "DEFAULT_LABEL = \"NK CD56 dim\"\n",
    "\n",
    "subcluster_to_pop = {\n",
    "    \"23\": \"MPP\",\n",
    "    \"22\": \"NK CD56 bright\",\n",
    "}\n",
    "\n",
    "# Map subclusters -> labels\n",
    "mapped = nk_subset.obs[SUBCLUSTER_COL].astype(str).map(subcluster_to_pop)\n",
    "mask_mapped = mapped.notna()\n",
    "mask_unmapped = mapped.isna()\n",
    "\n",
    "mapped_cell_ids = nk_subset.obs.index[mask_mapped]\n",
    "unmapped_cell_ids = nk_subset.obs.index[mask_unmapped]\n",
    "\n",
    "print(f\"Mapped via dict: {mask_mapped.sum()} cells\")\n",
    "print(f\"Default to '{DEFAULT_LABEL}': {mask_unmapped.sum()} cells\")\n",
    "\n",
    "# Ensure categories exist if TARGET_COL is categorical\n",
    "new_labels = pd.Index(mapped.loc[mask_mapped].unique()).append(pd.Index([DEFAULT_LABEL])).unique()\n",
    "\n",
    "for ad in [nk_subset, Triana_dataset]:\n",
    "    if TARGET_COL not in ad.obs.columns:\n",
    "        ad.obs[TARGET_COL] = pd.NA\n",
    "\n",
    "    if pd.api.types.is_categorical_dtype(ad.obs[TARGET_COL]):\n",
    "        missing = new_labels.difference(ad.obs[TARGET_COL].cat.categories)\n",
    "        if len(missing) > 0:\n",
    "            ad.obs[TARGET_COL] = ad.obs[TARGET_COL].cat.add_categories(list(missing))\n",
    "\n",
    "# Assign mapped labels (HSC/MPP/MEP) first\n",
    "nk_subset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "Triana_dataset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "\n",
    "# Assign default label (LMPP) to the rest\n",
    "nk_subset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "Triana_dataset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "\n",
    "print(\"\\nUpdated label counts in subset:\")\n",
    "print(nk_subset.obs[TARGET_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSubcluster -> label breakdown (subset):\")\n",
    "print(nk_subset.obs.groupby(SUBCLUSTER_COL)[TARGET_COL].value_counts().unstack(fill_value=0).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HSC cells from Triana dataset\n",
    "CD8_mask = Triana_dataset.obs['Consensus_annotation_detailed_final'] == 'CD8 T Memory'\n",
    "cd8_subset = Triana_dataset[CD8_mask].copy()\n",
    "\n",
    "print(f\"Number of CD8 T Memory cells: {cd8_subset.n_obs}\")\n",
    "print(f\"Original clusters containing CD8 T Memory: {cd8_subset.obs['CellTypes'].unique()}\")\n",
    "# Check distribution of original cell types within CD8 T Memory\n",
    "print(\"\\nDistribution of original CellTypes within CD8 T Memory:\")\n",
    "print(cd8_subset.obs['CellTypes'].value_counts())\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Perform subclustering on CD8 T Memory cells\n",
    "sc.pp.neighbors(cd8_subset, use_rep=\"X_mofaumap\", n_neighbors=15, metric='euclidean', random_state=42)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.tl.leiden(cd8_subset, resolution=0.5, random_state=42, key_added='cd8_subclusters')\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create UMAP for the CD8 T Memory subset\n",
    "sc.tl.umap(cd8_subset, random_state=42, min_dist=0.3)\n",
    "# Plot the subclusters\n",
    "sc.pl.embedding(cd8_subset, \n",
    "                color='cd8_subclusters', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=6,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "ax.set_title('CD8 T Memory Subclustering', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Check original annotations within each subcluster\n",
    "print(\"\\nOriginal CellTypes per subcluster:\")\n",
    "for cluster in sorted(cd8_subset.obs['cd8_subclusters'].unique()):\n",
    "    cluster_cells = cd8_subset.obs[cd8_subset.obs['cd8_subclusters'] == cluster]\n",
    "    print(f\"\\nSubcluster {cluster}:\")\n",
    "    print(cluster_cells['CellTypes'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FULL_BASIS = \"X_mofaumap\"\n",
    "SUBCOL = \"cd8_subclusters\"\n",
    "OUTCOL = \"cd8_subclusters_on_full\"\n",
    "\n",
    "# 1) Create a column in the full dataset and fill with NA\n",
    "Triana_dataset.obs[OUTCOL] = pd.NA\n",
    "\n",
    "# 2) Transfer subcluster labels from subset -> full by index\n",
    "Triana_dataset.obs.loc[cd8_subset.obs_names, OUTCOL] = cd8_subset.obs[SUBCOL].astype(str)\n",
    "\n",
    "# 3) Plot: full embedding, but color by gmp subclusters (non-GMP will be NA)\n",
    "sc.pl.embedding(\n",
    "    Triana_dataset,\n",
    "    color=OUTCOL,\n",
    "    basis=FULL_BASIS,\n",
    "    legend_loc=\"on data\",\n",
    "    legend_fontsize=6,\n",
    "    legend_fontoutline=2,\n",
    "    add_outline=False,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel(\"UMAP 1\", fontsize=12)\n",
    "ax.set_ylabel(\"UMAP 2\", fontsize=12)\n",
    "ax.set_title(\"Triana dataset: CD8 T Memory subclusters on full embedding\", fontsize=12, fontweight=\"bold\", y=1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SUBCLUSTER_COL = \"cd8_subclusters\"\n",
    "TARGET_COL = \"Consensus_annotation_detailed_final\"\n",
    "DEFAULT_LABEL = \"CD8 T Memory\"\n",
    "\n",
    "subcluster_to_pop = {\n",
    "    \"13\": \"GdT\",\n",
    "    \"25\": \"CD4 T Memory\",\n",
    "}\n",
    "\n",
    "# Map subclusters -> labels\n",
    "mapped = cd8_subset.obs[SUBCLUSTER_COL].astype(str).map(subcluster_to_pop)\n",
    "mask_mapped = mapped.notna()\n",
    "mask_unmapped = mapped.isna()\n",
    "\n",
    "mapped_cell_ids = cd8_subset.obs.index[mask_mapped]\n",
    "unmapped_cell_ids = cd8_subset.obs.index[mask_unmapped]\n",
    "\n",
    "print(f\"Mapped via dict: {mask_mapped.sum()} cells\")\n",
    "print(f\"Default to '{DEFAULT_LABEL}': {mask_unmapped.sum()} cells\")\n",
    "\n",
    "# Ensure categories exist if TARGET_COL is categorical\n",
    "new_labels = pd.Index(mapped.loc[mask_mapped].unique()).append(pd.Index([DEFAULT_LABEL])).unique()\n",
    "\n",
    "for ad in [cd8_subset, Triana_dataset]:\n",
    "    if TARGET_COL not in ad.obs.columns:\n",
    "        ad.obs[TARGET_COL] = pd.NA\n",
    "\n",
    "    if pd.api.types.is_categorical_dtype(ad.obs[TARGET_COL]):\n",
    "        missing = new_labels.difference(ad.obs[TARGET_COL].cat.categories)\n",
    "        if len(missing) > 0:\n",
    "            ad.obs[TARGET_COL] = ad.obs[TARGET_COL].cat.add_categories(list(missing))\n",
    "\n",
    "# Assign mapped labels (HSC/MPP/MEP) first\n",
    "cd8_subset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "Triana_dataset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "\n",
    "# Assign default label (LMPP) to the rest\n",
    "cd8_subset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "Triana_dataset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "\n",
    "print(\"\\nUpdated label counts in subset:\")\n",
    "print(cd8_subset.obs[TARGET_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSubcluster -> label breakdown (subset):\")\n",
    "print(cd8_subset.obs.groupby(SUBCLUSTER_COL)[TARGET_COL].value_counts().unstack(fill_value=0).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_colors' in Triana_dataset.uns:\n",
    "    del Triana_dataset.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_mofaumap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Triana S. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# Triana_dataset: build *_final columns (broad_final + simplified_final) Zhang-style\n",
    "# - Safe on reruns (casts to object before assignment)\n",
    "# - Deterministic (resets outputs each run)\n",
    "# - Enforces fixed category orders at the end\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Column names\n",
    "# -----------------------------\n",
    "DETAIL_REFINED_COL  = \"Consensus_annotation_detailed_final\"\n",
    "DETAIL_FALLBACK_COL = \"Consensus_annotation_detailed_refined\"\n",
    "\n",
    "BROAD_FINAL_COL = \"Consensus_annotation_broad_final\"\n",
    "SIMPL_FINAL_COL = \"Consensus_annotation_simplified_final\"\n",
    "\n",
    "# If refined detailed does not exist, fall back\n",
    "DETAIL_INPUT = DETAIL_REFINED_COL if DETAIL_REFINED_COL in Triana_dataset.obs.columns else DETAIL_FALLBACK_COL\n",
    "\n",
    "# -----------------------------\n",
    "# Fixed category orders (from your Triana simplified_final spec)\n",
    "# -----------------------------\n",
    "broad_categories = [\"Immature\", \"Mature\", \"Doublet\"]\n",
    "\n",
    "simpl_categories = [\n",
    "    'HSPC', 'Monocyte', 'CD4 T', 'CD8 T', 'Erythroid', 'B', 'cDC', 'pDC', 'NK',\n",
    "    'ILC', 'Stroma', 'Myeloid', 'Other T', 'Plasma', 'Mesenchymal'\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Ensure *_final columns exist and are OBJECT dtype (safe on reruns)\n",
    "# -----------------------------\n",
    "for col in [BROAD_FINAL_COL, SIMPL_FINAL_COL]:\n",
    "    if col not in Triana_dataset.obs.columns:\n",
    "        Triana_dataset.obs[col] = pd.NA\n",
    "    if pd.api.types.is_categorical_dtype(Triana_dataset.obs[col]):\n",
    "        Triana_dataset.obs[col] = Triana_dataset.obs[col].astype(\"object\")\n",
    "\n",
    "# Reset each run so reruns are deterministic\n",
    "Triana_dataset.obs[BROAD_FINAL_COL] = pd.NA\n",
    "Triana_dataset.obs[SIMPL_FINAL_COL] = pd.NA\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Build simplified_final from detailed_refined (or fallback detailed)\n",
    "# -----------------------------\n",
    "d = Triana_dataset.obs[DETAIL_INPUT]\n",
    "\n",
    "# HSPC\n",
    "Triana_dataset.obs.loc[d.isin(['HSC', 'MPP', 'LMPP', 'EoBaMaP', 'MkP', 'MEP', 'Pre-Pro-B', 'Pro-B', 'GMP']),\n",
    "                       SIMPL_FINAL_COL] = 'HSPC'\n",
    "\n",
    "# Monocyte\n",
    "Triana_dataset.obs.loc[d.isin(['CD14 Mono', 'CD16 Mono']), SIMPL_FINAL_COL] = 'Monocyte'\n",
    "\n",
    "# Myeloid\n",
    "Triana_dataset.obs.loc[d.isin(['Myeloid progenitor']), SIMPL_FINAL_COL] = 'Myeloid'\n",
    "\n",
    "# NK\n",
    "Triana_dataset.obs.loc[d.isin(['NK CD56 dim', 'NK CD56 bright']), SIMPL_FINAL_COL] = 'NK'\n",
    "\n",
    "# CD4 T\n",
    "Triana_dataset.obs.loc[d.isin(['CD4 T Naive', 'CD4 T Memory', 'Treg', 'CD4 CTL']), SIMPL_FINAL_COL] = 'CD4 T'\n",
    "\n",
    "# CD8 T\n",
    "Triana_dataset.obs.loc[d.isin(['CD8 T Naive', 'CD8 T Memory', 'MAIT']), SIMPL_FINAL_COL] = 'CD8 T'\n",
    "\n",
    "# B\n",
    "Triana_dataset.obs.loc[d.isin(['B Naive', 'B Memory', 'Immature B', 'Pre-B']), SIMPL_FINAL_COL] = 'B'\n",
    "\n",
    "# Erythroid\n",
    "Triana_dataset.obs.loc[d.isin(['ErP', 'Erythroblast']), SIMPL_FINAL_COL] = 'Erythroid'\n",
    "\n",
    "# Mesenchymal\n",
    "Triana_dataset.obs.loc[d.eq('Mesenchymal'), SIMPL_FINAL_COL] = 'Mesenchymal'\n",
    "\n",
    "# cDC\n",
    "Triana_dataset.obs.loc[d.isin(['cDC1', 'cDC2']), SIMPL_FINAL_COL] = 'cDC'\n",
    "\n",
    "# Other T\n",
    "Triana_dataset.obs.loc[d.isin(['GdT']), SIMPL_FINAL_COL] = 'Other T'\n",
    "\n",
    "# pDC\n",
    "Triana_dataset.obs.loc[d.eq('pDC'), SIMPL_FINAL_COL] = 'pDC'\n",
    "\n",
    "# Stroma\n",
    "Triana_dataset.obs.loc[d.eq('Stroma'), SIMPL_FINAL_COL] = 'Stroma'\n",
    "\n",
    "# Plasma\n",
    "Triana_dataset.obs.loc[d.eq('Plasma'), SIMPL_FINAL_COL] = 'Plasma'\n",
    "\n",
    "# NOTE: You included 'Pro-B' as a simplified category but did not map anything to it.\n",
    "# If you intended Pro-B to be a simplified bucket (distinct from HSPC), uncomment:\n",
    "# Triana_dataset.obs.loc[d.eq('Pro-B'), SIMPL_FINAL_COL] = 'Pro-B'\n",
    "# (Doing so would override the HSPC assignment for 'Pro-B'.)\n",
    "\n",
    "# Enforce fixed categories/order for simplified_final\n",
    "Triana_dataset.obs[SIMPL_FINAL_COL] = pd.Categorical(Triana_dataset.obs[SIMPL_FINAL_COL], categories=simpl_categories)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build broad_final\n",
    "#    Priority:\n",
    "#      - If simplified_final is Doublet -> Doublet\n",
    "#      - If detailed label indicates progenitor -> Immature\n",
    "#      - Else if simplified_final assigned -> Mature\n",
    "#      - Else -> Other\n",
    "# -----------------------------\n",
    "sf = Triana_dataset.obs[SIMPL_FINAL_COL]\n",
    "\n",
    "# Doublet (only if you ever assign it in simplified_final)\n",
    "Triana_dataset.obs.loc[sf.eq(\"Doublet\"), BROAD_FINAL_COL] = \"Doublet\"\n",
    "\n",
    "# Immature progenitors (expand if needed)\n",
    "immature_details = ['HSC', 'MPP', 'LMPP', 'EoBaMaP', 'MkP', 'MEP', 'Pre-Pro-B', 'Pro-B', 'GMP', 'ErP']\n",
    "Triana_dataset.obs.loc[d.isin(immature_details), BROAD_FINAL_COL] = \"Immature\"\n",
    "\n",
    "# Mature: anything with an assigned simplified_final (and not already Immature/Doublet)\n",
    "Triana_dataset.obs.loc[Triana_dataset.obs[BROAD_FINAL_COL].isna(), BROAD_FINAL_COL] = \"Mature\"\n",
    "\n",
    "# Enforce fixed categories/order for broad_final\n",
    "Triana_dataset.obs[BROAD_FINAL_COL] = pd.Categorical(Triana_dataset.obs[BROAD_FINAL_COL], categories=broad_categories)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Sanity checks\n",
    "# -----------------------------\n",
    "na_simpl = int(Triana_dataset.obs[SIMPL_FINAL_COL].isna().sum())\n",
    "na_broad = int(Triana_dataset.obs[BROAD_FINAL_COL].isna().sum())\n",
    "\n",
    "print(f\"Using detail input column: {DETAIL_INPUT}\")\n",
    "print(f\"Unassigned '{SIMPL_FINAL_COL}' (NA) rows: {na_simpl} / {Triana_dataset.n_obs}\")\n",
    "print(f\"Unassigned '{BROAD_FINAL_COL}' (NA) rows: {na_broad} / {Triana_dataset.n_obs}\")\n",
    "\n",
    "print(\"\\nBroad final value counts:\")\n",
    "print(Triana_dataset.obs[BROAD_FINAL_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSimplified final value counts (top 30):\")\n",
    "print(Triana_dataset.obs[SIMPL_FINAL_COL].value_counts(dropna=False).head(30).to_string())\n",
    "\n",
    "# Diagnostics for what is unmapped in simplified_final\n",
    "unmapped = (\n",
    "    Triana_dataset.obs.loc[Triana_dataset.obs[SIMPL_FINAL_COL].isna(), DETAIL_INPUT]\n",
    "    .astype(\"object\")\n",
    "    .fillna(\"<<NA in detailed>>\")\n",
    "    .value_counts()\n",
    "    .head(30)\n",
    ")\n",
    "print(f\"\\nTop unmapped '{DETAIL_INPUT}' labels among NA simplified_final rows (top 30):\")\n",
    "print(unmapped.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_colors' in Triana_dataset.uns:\n",
    "    del Triana_dataset.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_mofaumap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Triana S. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# Triana_dataset: build *_final columns (broad_final + simplified_final) Zhang-style\n",
    "# - Safe on reruns (casts to object before assignment)\n",
    "# - Deterministic (resets outputs each run)\n",
    "# - Enforces fixed category orders at the end\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Column names\n",
    "# -----------------------------\n",
    "DETAIL_REFINED_COL  = \"Consensus_annotation_detailed_final\"\n",
    "DETAIL_FALLBACK_COL = \"Consensus_annotation_detailed_refined\"\n",
    "\n",
    "BROAD_FINAL_COL = \"Consensus_annotation_broad_final\"\n",
    "SIMPL_FINAL_COL = \"Consensus_annotation_simplified_final\"\n",
    "\n",
    "# If refined detailed does not exist, fall back\n",
    "DETAIL_INPUT = DETAIL_REFINED_COL if DETAIL_REFINED_COL in Triana_dataset.obs.columns else DETAIL_FALLBACK_COL\n",
    "\n",
    "# -----------------------------\n",
    "# Fixed category orders (from your Triana simplified_final spec)\n",
    "# -----------------------------\n",
    "broad_categories = [\"Immature\", \"Mature\", \"Doublet\"]\n",
    "\n",
    "simpl_categories = [\n",
    "    'HSPC', 'Monocyte', 'CD4 T', 'CD8 T', 'Erythroid', 'B', 'cDC', 'pDC', 'NK',\n",
    "    'ILC', 'Stroma', 'Myeloid', 'Other T', 'Plasma', 'Mesenchymal'\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Ensure *_final columns exist and are OBJECT dtype (safe on reruns)\n",
    "# -----------------------------\n",
    "for col in [BROAD_FINAL_COL, SIMPL_FINAL_COL]:\n",
    "    if col not in Triana_dataset.obs.columns:\n",
    "        Triana_dataset.obs[col] = pd.NA\n",
    "    if pd.api.types.is_categorical_dtype(Triana_dataset.obs[col]):\n",
    "        Triana_dataset.obs[col] = Triana_dataset.obs[col].astype(\"object\")\n",
    "\n",
    "# Reset each run so reruns are deterministic\n",
    "Triana_dataset.obs[BROAD_FINAL_COL] = pd.NA\n",
    "Triana_dataset.obs[SIMPL_FINAL_COL] = pd.NA\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Build simplified_final from detailed_refined (or fallback detailed)\n",
    "# -----------------------------\n",
    "d = Triana_dataset.obs[DETAIL_INPUT]\n",
    "\n",
    "# HSPC\n",
    "Triana_dataset.obs.loc[d.isin(['HSC', 'MPP', 'LMPP', 'EoBaMaP', 'MkP', 'MEP', 'Pre-Pro-B', 'Pro-B', 'GMP']),\n",
    "                       SIMPL_FINAL_COL] = 'HSPC'\n",
    "\n",
    "# Monocyte\n",
    "Triana_dataset.obs.loc[d.isin(['CD14 Mono', 'CD16 Mono']), SIMPL_FINAL_COL] = 'Monocyte'\n",
    "\n",
    "# Myeloid\n",
    "Triana_dataset.obs.loc[d.isin(['Myeloid progenitor']), SIMPL_FINAL_COL] = 'Myeloid'\n",
    "\n",
    "# NK\n",
    "Triana_dataset.obs.loc[d.isin(['NK CD56 dim', 'NK CD56 bright']), SIMPL_FINAL_COL] = 'NK'\n",
    "\n",
    "# CD4 T\n",
    "Triana_dataset.obs.loc[d.isin(['CD4 T Naive', 'CD4 T Memory', 'Treg', 'CD4 CTL']), SIMPL_FINAL_COL] = 'CD4 T'\n",
    "\n",
    "# CD8 T\n",
    "Triana_dataset.obs.loc[d.isin(['CD8 T Naive', 'CD8 T Memory', 'MAIT']), SIMPL_FINAL_COL] = 'CD8 T'\n",
    "\n",
    "# B\n",
    "Triana_dataset.obs.loc[d.isin(['B Naive', 'B Memory', 'Immature B', 'Pre-B']), SIMPL_FINAL_COL] = 'B'\n",
    "\n",
    "# Erythroid\n",
    "Triana_dataset.obs.loc[d.isin(['ErP', 'Erythroblast']), SIMPL_FINAL_COL] = 'Erythroid'\n",
    "\n",
    "# Mesenchymal\n",
    "Triana_dataset.obs.loc[d.eq('Mesenchymal'), SIMPL_FINAL_COL] = 'Mesenchymal'\n",
    "\n",
    "# cDC\n",
    "Triana_dataset.obs.loc[d.isin(['cDC1', 'cDC2']), SIMPL_FINAL_COL] = 'cDC'\n",
    "\n",
    "# Other T\n",
    "Triana_dataset.obs.loc[d.isin(['GdT']), SIMPL_FINAL_COL] = 'Other T'\n",
    "\n",
    "# pDC\n",
    "Triana_dataset.obs.loc[d.eq('pDC'), SIMPL_FINAL_COL] = 'pDC'\n",
    "\n",
    "# Stroma\n",
    "Triana_dataset.obs.loc[d.eq('Stroma'), SIMPL_FINAL_COL] = 'Stroma'\n",
    "\n",
    "# Plasma\n",
    "Triana_dataset.obs.loc[d.eq('Plasma'), SIMPL_FINAL_COL] = 'Plasma'\n",
    "\n",
    "# NOTE: You included 'Pro-B' as a simplified category but did not map anything to it.\n",
    "# If you intended Pro-B to be a simplified bucket (distinct from HSPC), uncomment:\n",
    "# Triana_dataset.obs.loc[d.eq('Pro-B'), SIMPL_FINAL_COL] = 'Pro-B'\n",
    "# (Doing so would override the HSPC assignment for 'Pro-B'.)\n",
    "\n",
    "# Enforce fixed categories/order for simplified_final\n",
    "Triana_dataset.obs[SIMPL_FINAL_COL] = pd.Categorical(Triana_dataset.obs[SIMPL_FINAL_COL], categories=simpl_categories)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build broad_final\n",
    "#    Priority:\n",
    "#      - If simplified_final is Doublet -> Doublet\n",
    "#      - If detailed label indicates progenitor -> Immature\n",
    "#      - Else if simplified_final assigned -> Mature\n",
    "#      - Else -> Other\n",
    "# -----------------------------\n",
    "sf = Triana_dataset.obs[SIMPL_FINAL_COL]\n",
    "\n",
    "# Doublet (only if you ever assign it in simplified_final)\n",
    "Triana_dataset.obs.loc[sf.eq(\"Doublet\"), BROAD_FINAL_COL] = \"Doublet\"\n",
    "\n",
    "# Immature progenitors (expand if needed)\n",
    "immature_details = ['HSC', 'MPP', 'LMPP', 'EoBaMaP', 'MkP', 'MEP', 'Pre-Pro-B', 'Pro-B', 'GMP', 'ErP']\n",
    "Triana_dataset.obs.loc[d.isin(immature_details), BROAD_FINAL_COL] = \"Immature\"\n",
    "\n",
    "# Mature: anything with an assigned simplified_final (and not already Immature/Doublet)\n",
    "Triana_dataset.obs.loc[Triana_dataset.obs[BROAD_FINAL_COL].isna(), BROAD_FINAL_COL] = \"Mature\"\n",
    "\n",
    "# Enforce fixed categories/order for broad_final\n",
    "Triana_dataset.obs[BROAD_FINAL_COL] = pd.Categorical(Triana_dataset.obs[BROAD_FINAL_COL], categories=broad_categories)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Sanity checks\n",
    "# -----------------------------\n",
    "na_simpl = int(Triana_dataset.obs[SIMPL_FINAL_COL].isna().sum())\n",
    "na_broad = int(Triana_dataset.obs[BROAD_FINAL_COL].isna().sum())\n",
    "\n",
    "print(f\"Using detail input column: {DETAIL_INPUT}\")\n",
    "print(f\"Unassigned '{SIMPL_FINAL_COL}' (NA) rows: {na_simpl} / {Triana_dataset.n_obs}\")\n",
    "print(f\"Unassigned '{BROAD_FINAL_COL}' (NA) rows: {na_broad} / {Triana_dataset.n_obs}\")\n",
    "\n",
    "print(\"\\nBroad final value counts:\")\n",
    "print(Triana_dataset.obs[BROAD_FINAL_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSimplified final value counts (top 30):\")\n",
    "print(Triana_dataset.obs[SIMPL_FINAL_COL].value_counts(dropna=False).head(30).to_string())\n",
    "\n",
    "# Diagnostics for what is unmapped in simplified_final\n",
    "unmapped = (\n",
    "    Triana_dataset.obs.loc[Triana_dataset.obs[SIMPL_FINAL_COL].isna(), DETAIL_INPUT]\n",
    "    .astype(\"object\")\n",
    "    .fillna(\"<<NA in detailed>>\")\n",
    "    .value_counts()\n",
    "    .head(30)\n",
    ")\n",
    "print(f\"\\nTop unmapped '{DETAIL_INPUT}' labels among NA simplified_final rows (top 30):\")\n",
    "print(unmapped.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='Consensus_annotation_broad_final', \n",
    "                basis='X_mofaumap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Triana S. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus broad annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/40_Triana_dataset_final_consensus_annotation_broad_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='Consensus_annotation_simplified_final', \n",
    "                basis='X_mofaumap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Triana S. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus simplified annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/41_Triana_dataset_final_consensus_annotation_simplified_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_final_colors' in Triana_dataset.uns:\n",
    "    del Triana_dataset.uns['Consensus_annotation_detailed_final_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Triana_dataset, \n",
    "                color='Consensus_annotation_detailed_final', \n",
    "                basis='X_mofaumap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Triana S. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/42_Triana_dataset_final_Consensus_annotation_detailed_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luecken dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Luecken_dataset.obs['Consensus_annotation_simplified'] = Luecken_dataset.obs['Consensus_annotation_simplified'].cat.remove_unused_categories()\n",
    "Luecken_dataset.obs['Consensus_annotation_detailed'] = Luecken_dataset.obs['Consensus_annotation_detailed'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Luecken_dataset.obs['Consensus_annotation_detailed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_categories = counts[counts >= 10].index\n",
    "Luecken_dataset = Luecken_dataset[Luecken_dataset.obs[Luecken_dataset.obs['Consensus_annotation_detailed'].isin(filtered_categories)].index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Luecken_dataset, \n",
    "                color='cell_type', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Luecken M.D. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the categories in the cell_type column\n",
    "print(\"Cell type categories in Luecken dataset:\")\n",
    "print(list(Luecken_dataset.obs['cell_type'].cat.categories))\n",
    "print(f\"\\nNumber of categories: {len(Luecken_dataset.obs['cell_type'].cat.categories)}\")\n",
    "\n",
    "# Also show value counts to see distribution\n",
    "print(\"\\nValue counts:\")\n",
    "print(Luecken_dataset.obs['cell_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_colors' in Luecken_dataset.uns:\n",
    "    del Luecken_dataset.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Luecken_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Luecken M.D. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "OUT_BROAD  = \"Consensus_annotation_broad\"\n",
    "OUT_SIMPL  = \"Consensus_annotation_simplified\"\n",
    "OUT_DETAIL = \"Consensus_annotation_detailed\"\n",
    "\n",
    "CELLTYPE_COL = \"cell_type\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 0) Ensure output columns exist and are OBJECT dtype (safe on reruns)\n",
    "# -----------------------------------------------------------------------------\n",
    "for col in [OUT_BROAD, OUT_SIMPL, OUT_DETAIL]:\n",
    "    if col not in Luecken_dataset.obs.columns:\n",
    "        Luecken_dataset.obs[col] = pd.NA\n",
    "    if pd.api.types.is_categorical_dtype(Luecken_dataset.obs[col]):\n",
    "        Luecken_dataset.obs[col] = Luecken_dataset.obs[col].astype(\"object\")\n",
    "\n",
    "# Convenience handles (avoid KeyError if columns are absent)\n",
    "ct = Luecken_dataset.obs[CELLTYPE_COL] if CELLTYPE_COL in Luecken_dataset.obs.columns else pd.Series(index=Luecken_dataset.obs.index, dtype=\"object\")\n",
    "d  = Luecken_dataset.obs[OUT_DETAIL]   if OUT_DETAIL in Luecken_dataset.obs.columns   else pd.Series(index=Luecken_dataset.obs.index, dtype=\"object\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Apply your overrides (vectorized, rerunnable)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Proerythroblast / Erythroblast / Reticulocyte -> Erythroblast (Erythroid, Mature)\n",
    "m = ct.isin(['Proerythroblast', 'Erythroblast', 'Reticulocyte'])\n",
    "Luecken_dataset.obs.loc[m, OUT_BROAD]  = 'Mature'\n",
    "Luecken_dataset.obs.loc[m, OUT_SIMPL]  = 'Erythroid'\n",
    "Luecken_dataset.obs.loc[m, OUT_DETAIL] = 'Erythroblast'\n",
    "\n",
    "# MK/E prog -> ErP (Erythroid, Mature)\n",
    "m = ct.isin(['MK/E prog'])\n",
    "Luecken_dataset.obs.loc[m, OUT_BROAD]  = 'Mature'\n",
    "Luecken_dataset.obs.loc[m, OUT_SIMPL]  = 'Erythroid'\n",
    "Luecken_dataset.obs.loc[m, OUT_DETAIL] = 'ErP'\n",
    "\n",
    "m = Luecken_dataset.obs[OUT_DETAIL].isin(['MkP', 'MEP'])\n",
    "Luecken_dataset.obs.loc[m, OUT_BROAD]  = 'Mature'\n",
    "Luecken_dataset.obs.loc[m, OUT_SIMPL]  = 'HSPC'\n",
    "Luecken_dataset.obs.loc[m, OUT_DETAIL] = 'MEP'\n",
    "\n",
    "# Existing detailed == LMPP -> Myeloid progenitor (Myeloid, Mature)\n",
    "m = Luecken_dataset.obs[OUT_DETAIL].isin(['LMPP', 'GMP'])\n",
    "Luecken_dataset.obs.loc[m, OUT_BROAD]  = 'Immature'\n",
    "Luecken_dataset.obs.loc[m, OUT_SIMPL]  = 'HSPC'\n",
    "Luecken_dataset.obs.loc[m, OUT_DETAIL] = 'GMP'\n",
    "\n",
    "# MAIT -> MAIT (CD8 T, Mature)\n",
    "m = ct.isin(['MAIT'])\n",
    "Luecken_dataset.obs.loc[m, OUT_BROAD]  = 'Mature'\n",
    "Luecken_dataset.obs.loc[m, OUT_SIMPL]  = 'CD8 T'\n",
    "Luecken_dataset.obs.loc[m, OUT_DETAIL] = 'MAIT'\n",
    "\n",
    "# cDC1 -> cDC1 (cDC, Mature)\n",
    "m = ct.isin(['cDC1'])\n",
    "Luecken_dataset.obs.loc[m, OUT_BROAD]  = 'Mature'\n",
    "Luecken_dataset.obs.loc[m, OUT_SIMPL]  = 'cDC'\n",
    "Luecken_dataset.obs.loc[m, OUT_DETAIL] = 'cDC1'\n",
    "\n",
    "# gdT TCRVD2+ -> Gamma delta T (CD8 T, Mature)\n",
    "m = ct.isin(['gdT TCRVD2+'])\n",
    "Luecken_dataset.obs.loc[m, OUT_BROAD]  = 'Mature'\n",
    "Luecken_dataset.obs.loc[m, OUT_SIMPL]  = 'Other T'\n",
    "Luecken_dataset.obs.loc[m, OUT_DETAIL] = 'GdT'\n",
    "\n",
    "# dnT -> Double negative T (Other T, Mature)\n",
    "m = ct.isin(['dnT'])\n",
    "Luecken_dataset.obs.loc[m, OUT_BROAD]  = 'Mature'\n",
    "Luecken_dataset.obs.loc[m, OUT_SIMPL]  = 'Other T'\n",
    "Luecken_dataset.obs.loc[m, OUT_DETAIL] = 'DnT'\n",
    "\n",
    "# CD4 activated / cycling -> CD4 T Memory (CD4 T, Mature)\n",
    "m = ct.isin(['CD4+ T activated IntegrinB7+', 'CD4+ T activated', 'T prog cycling'])\n",
    "Luecken_dataset.obs.loc[m, OUT_BROAD]  = 'Mature'\n",
    "Luecken_dataset.obs.loc[m, OUT_SIMPL]  = 'CD4 T'\n",
    "Luecken_dataset.obs.loc[m, OUT_DETAIL] = 'CD4 T Memory'\n",
    "\n",
    "# CD4 naive -> CD4 T Naive (CD4 T, Mature)\n",
    "m = ct.isin(['CD4+ T Naive'])\n",
    "Luecken_dataset.obs.loc[m, OUT_BROAD]  = 'Mature'\n",
    "Luecken_dataset.obs.loc[m, OUT_SIMPL]  = 'CD4 T'\n",
    "Luecken_dataset.obs.loc[m, OUT_DETAIL] = 'CD4 T Naive'\n",
    "\n",
    "m = Luecken_dataset.obs[OUT_DETAIL].isin(['CD45RO+', 'MPP', 'EoBaMaP'])\n",
    "Luecken_dataset.obs.loc[m, OUT_BROAD]  = 'Immature'\n",
    "Luecken_dataset.obs.loc[m, OUT_SIMPL]  = 'HSPC'\n",
    "Luecken_dataset.obs.loc[m, OUT_DETAIL] = 'MPP'\n",
    "\n",
    "m = Luecken_dataset.obs[OUT_DETAIL].isin(['Pre-Pro-B'])\n",
    "Luecken_dataset.obs.loc[m, OUT_BROAD]  = 'Immature'\n",
    "Luecken_dataset.obs.loc[m, OUT_SIMPL]  = 'HSPC'\n",
    "Luecken_dataset.obs.loc[m, OUT_DETAIL] = 'Pre-Pro-B'\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Optional: convert back to categoricals AFTER all assignments\n",
    "# -----------------------------------------------------------------------------\n",
    "for col in [OUT_BROAD, OUT_SIMPL, OUT_DETAIL]:\n",
    "    Luecken_dataset.obs[col] = pd.Categorical(Luecken_dataset.obs[col])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Sanity checks\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Value counts (broad) top 20:\")\n",
    "print(Luecken_dataset.obs[OUT_BROAD].value_counts(dropna=False).head(20).to_string())\n",
    "\n",
    "print(\"\\nValue counts (simplified) top 20:\")\n",
    "print(Luecken_dataset.obs[OUT_SIMPL].value_counts(dropna=False).head(20).to_string())\n",
    "\n",
    "print(\"\\nValue counts (detailed) top 20:\")\n",
    "print(Luecken_dataset.obs[OUT_DETAIL].value_counts(dropna=False).head(20).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with Consensus_annotation_detailed\n",
    "sc.pl.embedding(Luecken_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(8, 6)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with Consensus_annotation_detailed\n",
    "sc.pl.embedding(Luecken_dataset, \n",
    "                color='Consensus_annotation_detailed', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(8, 6)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Merged datasets', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Luecken_dataset.obs['Consensus_annotation_simplified'] = Luecken_dataset.obs['Consensus_annotation_simplified'].cat.remove_unused_categories()\n",
    "Luecken_dataset.obs['Consensus_annotation_detailed'] = Luecken_dataset.obs['Consensus_annotation_detailed'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "# -----------------------------------------------------------------------------\n",
    "if 'Consensus_annotation_detailed_colors' in Luecken_dataset.uns:\n",
    "    del Luecken_dataset.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "if 'Consensus_annotation_detailed_refined_colors' in Luecken_dataset.uns:\n",
    "    del Luecken_dataset.uns['Consensus_annotation_detailed_refined_colors']\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Calculate silhouette scores for current annotations\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Calculating silhouette scores for Luecken dataset...\")\n",
    "\n",
    "# Use the UMAP representation for silhouette analysis\n",
    "X_embed = Luecken_dataset.obsm['X_umap']\n",
    "labels = Luecken_dataset.obs['Consensus_annotation_detailed'].astype('category').cat.codes\n",
    "\n",
    "# Calculate silhouette scores\n",
    "silhouette_avg = silhouette_score(X_embed, labels)\n",
    "sample_silhouette_values = silhouette_samples(X_embed, labels)\n",
    "\n",
    "print(f\"Average silhouette score: {silhouette_avg:.3f}\")\n",
    "\n",
    "# Add silhouette scores to the dataset\n",
    "Luecken_dataset.obs['silhouette_score'] = sample_silhouette_values\n",
    "\n",
    "# Identify cells with negative silhouette scores\n",
    "negative_silhouette_mask = sample_silhouette_values < 0\n",
    "print(f\"Number of cells with negative silhouette scores: {negative_silhouette_mask.sum()}\")\n",
    "print(f\"Percentage of cells with negative silhouette scores: {negative_silhouette_mask.sum()/len(sample_silhouette_values)*100:.2f}%\")\n",
    "\n",
    "# Show distribution of silhouette scores by cell type\n",
    "silhouette_by_type = (\n",
    "    Luecken_dataset.obs\n",
    "    .groupby('Consensus_annotation_detailed')['silhouette_score']\n",
    "    .agg(['mean', 'std', 'min', 'max', 'count'])\n",
    ")\n",
    "print(\"\\nSilhouette scores by cell type:\")\n",
    "print(silhouette_by_type.sort_values('mean'))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Initialize refined annotations (start with original smoothed annotations)\n",
    "# -----------------------------------------------------------------------------\n",
    "Luecken_dataset.obs['Consensus_annotation_detailed_refined'] = Luecken_dataset.obs['Consensus_annotation_detailed'].copy()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Perform silhouette-based reassignment with RESTRICTION\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n=== PERFORMING SILHOUETTE-BASED REASSIGNMENT (WITH RESTRICTION) ===\")\n",
    "\n",
    "# Cells with very poor silhouette scores (< -0.1)\n",
    "very_poor = Luecken_dataset.obs['silhouette_score'] < -0.1\n",
    "\n",
    "# Restriction: exclude these labels from reassignment\n",
    "protected_labels = ['cDC1', 'ErP', 'Pre-Pro-B']\n",
    "protected_mask = Luecken_dataset.obs['Consensus_annotation_detailed'].isin(protected_labels)\n",
    "\n",
    "# Eligible = very poor AND not protected\n",
    "very_poor_silhouette = very_poor & (~protected_mask)\n",
    "\n",
    "print(f\"Found {int(very_poor.sum())} cells with very poor silhouette (< -0.1) before restriction\")\n",
    "print(f\"Protected cells (never reassigned): {int(protected_mask.sum())}\")\n",
    "print(f\"Cells eligible for reassignment after restriction: {int(very_poor_silhouette.sum())}\")\n",
    "\n",
    "if very_poor_silhouette.sum() > 0:\n",
    "    # Fit nearest neighbors\n",
    "    nn = NearestNeighbors(n_neighbors=30, metric='euclidean')\n",
    "    nn.fit(X_embed)\n",
    "\n",
    "    # Indices of eligible poorly assigned cells\n",
    "    poor_indices = np.where(very_poor_silhouette.values)[0]\n",
    "\n",
    "    reassignments_made = 0\n",
    "\n",
    "    for idx in poor_indices:\n",
    "        # Find neighbors for this cell\n",
    "        distances, neighbor_indices = nn.kneighbors([X_embed[idx]])\n",
    "        neighbor_indices = neighbor_indices[0][1:]  # exclude the cell itself\n",
    "\n",
    "        # Get annotations of neighbors (use ORIGINAL labels as in your script)\n",
    "        neighbor_annotations = Luecken_dataset.obs['Consensus_annotation_detailed'].iloc[neighbor_indices]\n",
    "\n",
    "        # Most common annotation among neighbors\n",
    "        most_common = neighbor_annotations.mode()\n",
    "\n",
    "        if len(most_common) > 0:\n",
    "            new_annotation = most_common.iloc[0]\n",
    "            current_annotation = Luecken_dataset.obs['Consensus_annotation_detailed'].iloc[idx]\n",
    "\n",
    "            # Only reassign if different\n",
    "            if new_annotation != current_annotation:\n",
    "                # Require at least 40% of neighbors to agree\n",
    "                fraction = (neighbor_annotations == new_annotation).sum() / len(neighbor_annotations)\n",
    "\n",
    "                if fraction >= 0.4:\n",
    "                    Luecken_dataset.obs.loc[Luecken_dataset.obs.index[idx], 'Consensus_annotation_detailed_refined'] = new_annotation\n",
    "                    reassignments_made += 1\n",
    "\n",
    "    print(f\"Reassigned {reassignments_made} cells based on neighborhood consensus\")\n",
    "\n",
    "    # Recalculate silhouette scores after reassignment\n",
    "    new_labels = Luecken_dataset.obs['Consensus_annotation_detailed_refined'].astype('category').cat.codes\n",
    "    new_silhouette_scores = silhouette_samples(X_embed, new_labels)\n",
    "    silhouette_avg_corrected = silhouette_score(X_embed, new_labels)\n",
    "\n",
    "    # Store corrected scores\n",
    "    Luecken_dataset.obs['silhouette_score_corrected'] = new_silhouette_scores\n",
    "\n",
    "    print(f\"\\n=== REASSIGNMENT RESULTS ===\")\n",
    "    print(f\"Original average silhouette: {silhouette_avg:.3f}\")\n",
    "    print(f\"Refined average silhouette: {silhouette_avg_corrected:.3f}\")\n",
    "    print(f\"Improvement: {silhouette_avg_corrected - silhouette_avg:.3f}\")\n",
    "\n",
    "    print(f\"Original negative silhouette cells: {int(negative_silhouette_mask.sum())}\")\n",
    "    print(f\"Refined negative silhouette cells: {int((new_silhouette_scores < 0).sum())}\")\n",
    "\n",
    "    # Show what changes were made\n",
    "    if reassignments_made > 0:\n",
    "        changes_mask = (\n",
    "            Luecken_dataset.obs['Consensus_annotation_detailed'] !=\n",
    "            Luecken_dataset.obs['Consensus_annotation_detailed_refined']\n",
    "        )\n",
    "        changes = Luecken_dataset.obs[changes_mask]\n",
    "\n",
    "        print(f\"\\n=== SPECIFIC REASSIGNMENTS ===\")\n",
    "        change_summary = (\n",
    "            changes.groupby(['Consensus_annotation_detailed', 'Consensus_annotation_detailed_refined'])\n",
    "            .size()\n",
    "            .reset_index(name='count')\n",
    "        )\n",
    "\n",
    "        for _, row in change_summary.iterrows():\n",
    "            print(f\"{row['Consensus_annotation_detailed']} -> {row['Consensus_annotation_detailed_refined']}: {row['count']} cells\")\n",
    "\n",
    "else:\n",
    "    print(\"No eligible cells with very poor silhouette scores found (after restriction).\")\n",
    "    # Create corrected scores column that's identical to original\n",
    "    Luecken_dataset.obs['silhouette_score_corrected'] = Luecken_dataset.obs['silhouette_score'].copy()\n",
    "    silhouette_avg_corrected = silhouette_avg\n",
    "    reassignments_made = 0\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Create a reassignment status column for visualization\n",
    "# -----------------------------------------------------------------------------\n",
    "reassignment_mask = (\n",
    "    Luecken_dataset.obs['Consensus_annotation_detailed'] !=\n",
    "    Luecken_dataset.obs['Consensus_annotation_detailed_refined']\n",
    ")\n",
    "Luecken_dataset.obs['reassignment_status'] = 'Unchanged'\n",
    "Luecken_dataset.obs.loc[reassignment_mask, 'reassignment_status'] = 'Reassigned'\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n=== FINAL SUMMARY ===\")\n",
    "print(f\"Total cells: {len(Luecken_dataset)}\")\n",
    "print(f\"Cells reassigned: {int(reassignment_mask.sum())}\")\n",
    "print(f\"Final cell type distribution:\")\n",
    "final_counts = Luecken_dataset.obs['Consensus_annotation_detailed_refined'].value_counts()\n",
    "print(final_counts)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Clear ALL color palettes before plotting to ensure fresh colors\n",
    "# -----------------------------------------------------------------------------\n",
    "color_keys_to_clear = [\n",
    "    'Consensus_annotation_detailed_colors',\n",
    "    'Consensus_annotation_detailed_refined_colors',\n",
    "    'reassignment_status_colors',\n",
    "    'silhouette_score_corrected_colors'\n",
    "]\n",
    "for key in color_keys_to_clear:\n",
    "    if key in Luecken_dataset.uns:\n",
    "        del Luecken_dataset.uns[key]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Plot comprehensive analysis\n",
    "# -----------------------------------------------------------------------------\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Original annotations\n",
    "sc.pl.embedding(\n",
    "    Luecken_dataset,\n",
    "    color='Consensus_annotation_detailed',\n",
    "    basis='X_umap',\n",
    "    legend_loc='on data',\n",
    "    legend_fontsize=5,\n",
    "    legend_fontoutline=2,\n",
    "    add_outline=False,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    "    ax=axes[0, 0]\n",
    ")\n",
    "axes[0, 0].set_title('Original Smoothed Annotations', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 2: Refined annotations\n",
    "sc.pl.embedding(\n",
    "    Luecken_dataset,\n",
    "    color='Consensus_annotation_detailed_refined',\n",
    "    basis='X_umap',\n",
    "    legend_loc='on data',\n",
    "    legend_fontsize=5,\n",
    "    legend_fontoutline=2,\n",
    "    add_outline=False,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    "    ax=axes[0, 1]\n",
    ")\n",
    "axes[0, 1].set_title('Silhouette-Refined Annotations', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 3: Reassignment status\n",
    "sc.pl.embedding(\n",
    "    Luecken_dataset,\n",
    "    color='reassignment_status',\n",
    "    basis='X_umap',\n",
    "    palette={'Unchanged': 'lightgray', 'Reassigned': 'red'},\n",
    "    add_outline=False,\n",
    "    legend_loc='right margin',\n",
    "    frameon=False,\n",
    "    show=False,\n",
    "    ax=axes[1, 0]\n",
    ")\n",
    "axes[1, 0].set_title('Reassignment Status', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 4: Corrected silhouette scores\n",
    "sc.pl.embedding(\n",
    "    Luecken_dataset,\n",
    "    color='silhouette_score_corrected',\n",
    "    basis='X_umap',\n",
    "    color_map='RdBu_r',\n",
    "    add_outline=False,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    "    ax=axes[1, 1]\n",
    ")\n",
    "axes[1, 1].set_title('Silhouette Scores (Refined)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path + \"/43_Luecken_dataset_silhouette_refinement_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Additional histogram comparison\n",
    "# -----------------------------------------------------------------------------\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Original silhouette distribution\n",
    "ax1.hist(sample_silhouette_values, bins=50, alpha=0.7, edgecolor='black', color='lightblue')\n",
    "ax1.axvline(x=0, color='red', linestyle='--', label='Silhouette = 0')\n",
    "ax1.set_xlabel('Silhouette Score')\n",
    "ax1.set_ylabel('Number of Cells')\n",
    "ax1.set_title(f'Original Silhouette Distribution\\n(Avg: {silhouette_avg:.3f})')\n",
    "ax1.legend()\n",
    "\n",
    "# Refined silhouette distribution\n",
    "ax2.hist(Luecken_dataset.obs['silhouette_score_corrected'], bins=50, alpha=0.7, edgecolor='black', color='lightgreen')\n",
    "ax2.axvline(x=0, color='red', linestyle='--', label='Silhouette = 0')\n",
    "ax2.set_xlabel('Silhouette Score')\n",
    "ax2.set_ylabel('Number of Cells')\n",
    "ax2.set_title(f'Refined Silhouette Distribution\\n(Avg: {silhouette_avg_corrected:.3f})')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path + \"/44_Luecken_dataset_silhouette_distribution_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Luecken_dataset.obs['Consensus_annotation_simplified'] = Luecken_dataset.obs['Consensus_annotation_simplified'].cat.remove_unused_categories()\n",
    "Luecken_dataset.obs['Consensus_annotation_detailed_refined'] = Luecken_dataset.obs['Consensus_annotation_detailed_refined'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Luecken_dataset_normalized = Luecken_dataset.copy()\n",
    "ep.Normalise_protein_data(Luecken_dataset_normalized, inplace=True, axis=1, flavor=\"seurat\")\n",
    "sc.tl.rank_genes_groups(Luecken_dataset_normalized, 'Consensus_annotation_detailed_refined', method='wilcoxon')\n",
    "sc.pl.rank_genes_groups(Luecken_dataset_normalized, n_genes=10, sharey=False, ncols = 3, fontsize = 14)\n",
    "\n",
    "plt.savefig(figures_path + \"/45_Luecken_dataset_top10_markers.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AveragedExpression = grouped_obs_mean(Luecken_dataset_normalized, 'Consensus_annotation_detailed_refined')\n",
    "df = pd.DataFrame(AveragedExpression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = df.corr(method='pearson')\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(235, 15, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "heatmap = sns.heatmap(corr, mask=mask, cmap=cmap, annot=True, \n",
    "                        square=True, linewidths=.6, cbar_kws={\"shrink\": 1},\n",
    "                        annot_kws={\"fontsize\":5})\n",
    "\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12)\n",
    "\n",
    "plt.savefig(figures_path + \"/46_Luecken_dataset_correlation_heatmap.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# Luecken_dataset: build *_final columns (broad_final + simplified_final) Zhang-style\n",
    "# - Safe on reruns (casts to object before assignment)\n",
    "# - Deterministic (resets outputs each run)\n",
    "# - Enforces fixed category orders at the end\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Column names\n",
    "# -----------------------------\n",
    "DETAIL_REFINED_COL  = \"Consensus_annotation_detailed_refined\"\n",
    "DETAIL_FALLBACK_COL = \"Consensus_annotation_detailed\"\n",
    "\n",
    "BROAD_FINAL_COL = \"Consensus_annotation_broad_final\"\n",
    "SIMPL_FINAL_COL = \"Consensus_annotation_simplified_final\"\n",
    "\n",
    "# If refined detailed does not exist, fall back\n",
    "DETAIL_INPUT = DETAIL_REFINED_COL if DETAIL_REFINED_COL in Luecken_dataset.obs.columns else DETAIL_FALLBACK_COL\n",
    "\n",
    "# -----------------------------\n",
    "# Fixed category orders (from your Luecken simplified_final spec)\n",
    "# -----------------------------\n",
    "broad_categories = [\"Immature\", \"Mature\", \"Doublet\"]\n",
    "\n",
    "simpl_categories = [\n",
    "    'HSPC', 'Monocyte', 'CD4 T', 'CD8 T', 'Erythroid', 'B', 'cDC', 'pDC', 'NK',\n",
    "    'Macrophage', 'ILC', 'Stroma', 'Myeloid', 'Other T', 'Plasma'\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Ensure *_final columns exist and are OBJECT dtype (safe on reruns)\n",
    "# -----------------------------\n",
    "for col in [BROAD_FINAL_COL, SIMPL_FINAL_COL]:\n",
    "    if col not in Luecken_dataset.obs.columns:\n",
    "        Luecken_dataset.obs[col] = pd.NA\n",
    "    if pd.api.types.is_categorical_dtype(Luecken_dataset.obs[col]):\n",
    "        Luecken_dataset.obs[col] = Luecken_dataset.obs[col].astype(\"object\")\n",
    "\n",
    "# Reset each run so reruns are deterministic\n",
    "Luecken_dataset.obs[BROAD_FINAL_COL] = pd.NA\n",
    "Luecken_dataset.obs[SIMPL_FINAL_COL] = pd.NA\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Build simplified_final from detailed_refined (or fallback detailed)\n",
    "# -----------------------------\n",
    "d = Luecken_dataset.obs[DETAIL_INPUT]\n",
    "\n",
    "# HSPC\n",
    "Luecken_dataset.obs.loc[d.isin(['MPP', 'Pro-B', 'HSC', 'MEP', 'GMP', 'ErP', 'Pre-Pro-B', 'Pro-B']), SIMPL_FINAL_COL] = 'HSPC'\n",
    "\n",
    "# Monocyte\n",
    "Luecken_dataset.obs.loc[d.isin(['CD14 Mono', 'CD16 Mono']), SIMPL_FINAL_COL] = 'Monocyte'\n",
    "\n",
    "# NK\n",
    "Luecken_dataset.obs.loc[d.isin(['NK CD56 dim', 'NK CD56 bright']), SIMPL_FINAL_COL] = 'NK'\n",
    "\n",
    "# CD4 T\n",
    "Luecken_dataset.obs.loc[d.isin(['CD4 T Naive', 'CD4 T Memory', 'Treg', 'CD4 CTL']), SIMPL_FINAL_COL] = 'CD4 T'\n",
    "\n",
    "# CD8 T\n",
    "Luecken_dataset.obs.loc[d.isin(['CD8 T Naive', 'CD8 T Memory', 'MAIT']), SIMPL_FINAL_COL] = 'CD8 T'\n",
    "\n",
    "# B (NOTE: your original code included 'Plasma' here, but you also map Plasma -> Plasma below.\n",
    "# The later Plasma assignment will override this, which is usually what you want.)\n",
    "Luecken_dataset.obs.loc[d.isin(['B Naive', 'B Memory', 'Plasma', 'Immature B', 'Pre-B']), SIMPL_FINAL_COL] = 'B'\n",
    "\n",
    "# Erythroid\n",
    "Luecken_dataset.obs.loc[d.isin(['Erythroblast', 'ErP']), SIMPL_FINAL_COL] = 'Erythroid'  # noqa: E999\n",
    "# If your environment errors on the line above due to linting, use:\n",
    "# Luecken_dataset.obs.loc[d.isin(['Erythroblast', 'ErP']), SIMPL_FINAL_COL] = 'Erythroid'\n",
    "\n",
    "# Myeloid\n",
    "Luecken_dataset.obs.loc[d.eq('Myeloid progenitor'), SIMPL_FINAL_COL] = 'Myeloid'\n",
    "\n",
    "# cDC\n",
    "Luecken_dataset.obs.loc[d.isin(['cDC1', 'cDC2']), SIMPL_FINAL_COL] = 'cDC'  # noqa: E999\n",
    "# Or:\n",
    "# Luecken_dataset.obs.loc[d.isin(['cDC1', 'cDC2']), SIMPL_FINAL_COL] = 'cDC'\n",
    "\n",
    "# pDC\n",
    "Luecken_dataset.obs.loc[d.eq('pDC'), SIMPL_FINAL_COL] = 'pDC'\n",
    "\n",
    "# Other T\n",
    "Luecken_dataset.obs.loc[d.isin(['Double negative T', 'Gamma delta T']), SIMPL_FINAL_COL] = 'Other T'  # noqa: E999\n",
    "# Or:\n",
    "# Luecken_dataset.obs.loc[d.isin(['Double negative T', 'Gamma delta T']), SIMPL_FINAL_COL] = 'Other T'\n",
    "\n",
    "# Macrophage\n",
    "Luecken_dataset.obs.loc[d.eq('Macrophage'), SIMPL_FINAL_COL] = 'Macrophage'\n",
    "\n",
    "# ILC\n",
    "Luecken_dataset.obs.loc[d.eq('ILC'), SIMPL_FINAL_COL] = 'ILC'\n",
    "\n",
    "# Plasma (override the earlier 'B' assignment for Plasma)\n",
    "Luecken_dataset.obs.loc[d.eq('Plasma'), SIMPL_FINAL_COL] = 'Plasma'\n",
    "\n",
    "# Enforce fixed categories/order for simplified_final\n",
    "Luecken_dataset.obs[SIMPL_FINAL_COL] = pd.Categorical(Luecken_dataset.obs[SIMPL_FINAL_COL], categories=simpl_categories)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build broad_final\n",
    "#    Priority:\n",
    "#      - If simplified_final is Doublet -> Doublet\n",
    "#      - If detailed label indicates progenitor -> Immature\n",
    "#      - Else if simplified_final assigned -> Mature\n",
    "#      - Else -> Other\n",
    "# -----------------------------\n",
    "sf = Luecken_dataset.obs[SIMPL_FINAL_COL]\n",
    "\n",
    "# Doublet (only if you ever assign it in simplified_final)\n",
    "Luecken_dataset.obs.loc[sf.eq(\"Doublet\"), BROAD_FINAL_COL] = \"Doublet\"\n",
    "\n",
    "# Immature progenitors (adjust if your refined labels include additional progenitor states)\n",
    "immature_details = [\n",
    "    \"HSC\", \"MPP\", \"LMPP\", \"GMP\", \"MEP\", \"ErP\", \"MkP\",\n",
    "    \"Pre-Pro-B\", \"Pro-B\", \"Pre-B\", \"CLP\", \"Progenitor\",\n",
    "    \"Neutrophil progenitor\", \"pDC progenitor\", \"EoBaMaP\"\n",
    "]\n",
    "Luecken_dataset.obs.loc[d.isin(immature_details), BROAD_FINAL_COL] = \"Immature\"\n",
    "\n",
    "# Mature: anything with an assigned simplified_final (and not already Immature/Doublet)\n",
    "Luecken_dataset.obs.loc[Luecken_dataset.obs[BROAD_FINAL_COL].isna(), BROAD_FINAL_COL] = \"Mature\"\n",
    "\n",
    "# Enforce fixed categories/order for broad_final\n",
    "Luecken_dataset.obs[BROAD_FINAL_COL] = pd.Categorical(Luecken_dataset.obs[BROAD_FINAL_COL], categories=broad_categories)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Sanity checks\n",
    "# -----------------------------\n",
    "na_simpl = int(Luecken_dataset.obs[SIMPL_FINAL_COL].isna().sum())\n",
    "na_broad = int(Luecken_dataset.obs[BROAD_FINAL_COL].isna().sum())\n",
    "\n",
    "print(f\"Using detail input column: {DETAIL_INPUT}\")\n",
    "print(f\"Unassigned '{SIMPL_FINAL_COL}' (NA) rows: {na_simpl} / {Luecken_dataset.n_obs}\")\n",
    "print(f\"Unassigned '{BROAD_FINAL_COL}' (NA) rows: {na_broad} / {Luecken_dataset.n_obs}\")\n",
    "\n",
    "print(\"\\nBroad final value counts:\")\n",
    "print(Luecken_dataset.obs[BROAD_FINAL_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSimplified final value counts (top 30):\")\n",
    "print(Luecken_dataset.obs[SIMPL_FINAL_COL].value_counts(dropna=False).head(30).to_string())\n",
    "\n",
    "# Diagnostics for what is unmapped in simplified_final\n",
    "unmapped = (\n",
    "    Luecken_dataset.obs.loc[Luecken_dataset.obs[SIMPL_FINAL_COL].isna(), DETAIL_INPUT]\n",
    "    .astype(\"object\")\n",
    "    .fillna(\"<<NA in detailed>>\")\n",
    "    .value_counts()\n",
    "    .head(30)\n",
    ")\n",
    "print(f\"\\nTop unmapped '{DETAIL_INPUT}' labels among NA simplified_final rows (top 30):\")\n",
    "print(unmapped.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Luecken_dataset.obs['Consensus_annotation_detailed_final'] = Luecken_dataset.obs['Consensus_annotation_detailed_refined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused categories\n",
    "Luecken_dataset.obs['Consensus_annotation_simplified_final'] = Luecken_dataset.obs['Consensus_annotation_simplified_final'].cat.remove_unused_categories()\n",
    "Luecken_dataset.obs['Consensus_annotation_detailed_final'] = Luecken_dataset.obs['Consensus_annotation_detailed_final'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HSC cells from Triana dataset\n",
    "GMP_mask = Luecken_dataset.obs['Consensus_annotation_detailed_final'] == 'GMP'\n",
    "gmp_subset = Luecken_dataset[GMP_mask].copy()\n",
    "\n",
    "print(f\"Number of GMP cells: {gmp_subset.n_obs}\")\n",
    "print(f\"Original clusters containing GMP: {gmp_subset.obs['cell_type'].unique()}\")\n",
    "# Check distribution of original cell types within GMP\n",
    "print(\"\\nDistribution of original CellTypes within GMP:\")\n",
    "print(gmp_subset.obs['cell_type'].value_counts())\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Perform subclustering on GMP cells\n",
    "sc.pp.neighbors(gmp_subset, use_rep=\"X_umap\", n_neighbors=15, metric='euclidean', random_state=42)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.tl.leiden(gmp_subset, resolution=0.5, random_state=42, key_added='gmp_subclusters')\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create UMAP for the GMP subset\n",
    "sc.tl.umap(gmp_subset, random_state=42, min_dist=0.3)\n",
    "# Plot the subclusters\n",
    "sc.pl.embedding(gmp_subset, \n",
    "                color='gmp_subclusters', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=6,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "ax.set_title('GMP Subclustering', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Check original annotations within each subcluster\n",
    "print(\"\\nOriginal CellTypes per subcluster:\")\n",
    "for cluster in sorted(gmp_subset.obs['gmp_subclusters'].unique()):\n",
    "    cluster_cells = gmp_subset.obs[gmp_subset.obs['gmp_subclusters'] == cluster]\n",
    "    print(f\"\\nSubcluster {cluster}:\")\n",
    "    print(cluster_cells['cell_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FULL_BASIS = \"X_umap\"\n",
    "SUBCOL = \"gmp_subclusters\"\n",
    "OUTCOL = \"gmp_subclusters_on_full\"\n",
    "\n",
    "# 1) Create a column in the full dataset and fill with NA\n",
    "Luecken_dataset.obs[OUTCOL] = pd.NA\n",
    "\n",
    "# 2) Transfer subcluster labels from subset -> full by index\n",
    "Luecken_dataset.obs.loc[gmp_subset.obs_names, OUTCOL] = gmp_subset.obs[SUBCOL].astype(str)\n",
    "\n",
    "# 3) Plot: full embedding, but color by gmp subclusters (non-GMP will be NA)\n",
    "sc.pl.embedding(\n",
    "    Luecken_dataset,\n",
    "    color=OUTCOL,\n",
    "    basis=FULL_BASIS,\n",
    "    legend_loc=\"on data\",\n",
    "    legend_fontsize=6,\n",
    "    legend_fontoutline=2,\n",
    "    add_outline=False,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel(\"UMAP 1\", fontsize=12)\n",
    "ax.set_ylabel(\"UMAP 2\", fontsize=12)\n",
    "ax.set_title(\"Luecken dataset: GMP subclusters on full embedding\", fontsize=12, fontweight=\"bold\", y=1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SUBCLUSTER_COL = \"gmp_subclusters\"\n",
    "TARGET_COL = \"Consensus_annotation_detailed_final\"\n",
    "DEFAULT_LABEL = \"GMP\"\n",
    "\n",
    "subcluster_to_pop = {\n",
    "    \"0\": \"Myeloid progenitor\",\n",
    "}\n",
    "\n",
    "# Map subclusters -> labels\n",
    "mapped = gmp_subset.obs[SUBCLUSTER_COL].astype(str).map(subcluster_to_pop)\n",
    "mask_mapped = mapped.notna()\n",
    "mask_unmapped = mapped.isna()\n",
    "\n",
    "mapped_cell_ids = gmp_subset.obs.index[mask_mapped]\n",
    "unmapped_cell_ids = gmp_subset.obs.index[mask_unmapped]\n",
    "\n",
    "print(f\"Mapped via dict: {mask_mapped.sum()} cells\")\n",
    "print(f\"Default to '{DEFAULT_LABEL}': {mask_unmapped.sum()} cells\")\n",
    "\n",
    "# Ensure categories exist if TARGET_COL is categorical\n",
    "new_labels = pd.Index(mapped.loc[mask_mapped].unique()).append(pd.Index([DEFAULT_LABEL])).unique()\n",
    "\n",
    "for ad in [gmp_subset, Luecken_dataset]:\n",
    "    if TARGET_COL not in ad.obs.columns:\n",
    "        ad.obs[TARGET_COL] = pd.NA\n",
    "\n",
    "    if pd.api.types.is_categorical_dtype(ad.obs[TARGET_COL]):\n",
    "        missing = new_labels.difference(ad.obs[TARGET_COL].cat.categories)\n",
    "        if len(missing) > 0:\n",
    "            ad.obs[TARGET_COL] = ad.obs[TARGET_COL].cat.add_categories(list(missing))\n",
    "\n",
    "# Assign mapped labels (HSC/MPP/MEP) first\n",
    "gmp_subset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "Luecken_dataset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "\n",
    "# Assign default label (LMPP) to the rest\n",
    "gmp_subset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "Luecken_dataset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "\n",
    "print(\"\\nUpdated label counts in subset:\")\n",
    "print(gmp_subset.obs[TARGET_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSubcluster -> label breakdown (subset):\")\n",
    "print(gmp_subset.obs.groupby(SUBCLUSTER_COL)[TARGET_COL].value_counts().unstack(fill_value=0).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HSC cells from Triana dataset\n",
    "Monocyte_mask = Luecken_dataset.obs['Consensus_annotation_simplified_final'] == 'Monocyte'\n",
    "monocyte_subset = Luecken_dataset[Monocyte_mask].copy()\n",
    "\n",
    "print(f\"Number of Monocyte cells: {monocyte_subset.n_obs}\")\n",
    "print(f\"Original clusters containing Monocyte: {monocyte_subset.obs['cell_type'].unique()}\")\n",
    "# Check distribution of original cell types within Monocyte\n",
    "print(\"\\nDistribution of original CellTypes within Monocyte:\")\n",
    "print(monocyte_subset.obs['cell_type'].value_counts())\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Perform subclustering on Monocyte cells\n",
    "sc.pp.neighbors(monocyte_subset, use_rep=\"X_umap\", n_neighbors=15, metric='euclidean', random_state=42)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "sc.tl.leiden(monocyte_subset, resolution=0.5, random_state=42, key_added='monocyte_subclusters')\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create UMAP for the Monocyte subset\n",
    "sc.tl.umap(monocyte_subset, random_state=42, min_dist=0.3)\n",
    "# Plot the subclusters\n",
    "sc.pl.embedding(monocyte_subset, \n",
    "                color='monocyte_subclusters', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=6,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "ax.set_title('Monocyte Subclustering', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Check original annotations within each subcluster\n",
    "print(\"\\nOriginal CellTypes per subcluster:\")\n",
    "for cluster in sorted(monocyte_subset.obs['monocyte_subclusters'].unique()):\n",
    "    cluster_cells = monocyte_subset.obs[monocyte_subset.obs['monocyte_subclusters'] == cluster]\n",
    "    print(f\"\\nSubcluster {cluster}:\")\n",
    "    print(cluster_cells['cell_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FULL_BASIS = \"X_umap\"\n",
    "SUBCOL = \"monocyte_subclusters\"\n",
    "OUTCOL = \"monocyte_subclusters_on_full\"\n",
    "\n",
    "# 1) Create a column in the full dataset and fill with NA\n",
    "Luecken_dataset.obs[OUTCOL] = pd.NA\n",
    "\n",
    "# 2) Transfer subcluster labels from subset -> full by index\n",
    "Luecken_dataset.obs.loc[monocyte_subset.obs_names, OUTCOL] = monocyte_subset.obs[SUBCOL].astype(str)\n",
    "\n",
    "# 3) Plot: full embedding, but color by monocyte subclusters (non-Monocyte will be NA)\n",
    "sc.pl.embedding(\n",
    "    Luecken_dataset,\n",
    "    color=OUTCOL,\n",
    "    basis=FULL_BASIS,\n",
    "    legend_loc=\"on data\",\n",
    "    legend_fontsize=6,\n",
    "    legend_fontoutline=2,\n",
    "    add_outline=False,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel(\"UMAP 1\", fontsize=12)\n",
    "ax.set_ylabel(\"UMAP 2\", fontsize=12)\n",
    "ax.set_title(\"Luecken dataset: Monocyte subclusters on full embedding\", fontsize=12, fontweight=\"bold\", y=1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SUBCLUSTER_COL = \"monocyte_subclusters\"\n",
    "TARGET_COL = \"Consensus_annotation_detailed_final\"\n",
    "DEFAULT_LABEL = \"CD14 Mono\"\n",
    "\n",
    "subcluster_to_pop = {\n",
    "    \"39\": \"ErP\",\n",
    "    \"34\": \"Macrophage\",\n",
    "    '13': \"CD16 Mono\",\n",
    "    '16': \"CD16 Mono\",\n",
    "    '36': \"CD16 Mono\",\n",
    "    '35': \"CD16 Mono\",\n",
    "}\n",
    "\n",
    "# Map subclusters -> labels\n",
    "mapped = monocyte_subset.obs[SUBCLUSTER_COL].astype(str).map(subcluster_to_pop)\n",
    "mask_mapped = mapped.notna()\n",
    "mask_unmapped = mapped.isna()\n",
    "\n",
    "mapped_cell_ids = monocyte_subset.obs.index[mask_mapped]\n",
    "unmapped_cell_ids = monocyte_subset.obs.index[mask_unmapped]\n",
    "\n",
    "print(f\"Mapped via dict: {mask_mapped.sum()} cells\")\n",
    "print(f\"Default to '{DEFAULT_LABEL}': {mask_unmapped.sum()} cells\")\n",
    "\n",
    "# Ensure categories exist if TARGET_COL is categorical\n",
    "new_labels = pd.Index(mapped.loc[mask_mapped].unique()).append(pd.Index([DEFAULT_LABEL])).unique()\n",
    "\n",
    "for ad in [monocyte_subset, Luecken_dataset]:\n",
    "    if TARGET_COL not in ad.obs.columns:\n",
    "        ad.obs[TARGET_COL] = pd.NA\n",
    "\n",
    "    if pd.api.types.is_categorical_dtype(ad.obs[TARGET_COL]):\n",
    "        missing = new_labels.difference(ad.obs[TARGET_COL].cat.categories)\n",
    "        if len(missing) > 0:\n",
    "            ad.obs[TARGET_COL] = ad.obs[TARGET_COL].cat.add_categories(list(missing))\n",
    "\n",
    "# Assign mapped labels (HSC/MPP/MEP) first\n",
    "monocyte_subset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "Luecken_dataset.obs.loc[mapped_cell_ids, TARGET_COL] = mapped.loc[mask_mapped].values\n",
    "\n",
    "# Assign default label (LMPP) to the rest\n",
    "monocyte_subset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "Luecken_dataset.obs.loc[unmapped_cell_ids, TARGET_COL] = DEFAULT_LABEL\n",
    "\n",
    "print(\"\\nUpdated label counts in subset:\")\n",
    "print(monocyte_subset.obs[TARGET_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSubcluster -> label breakdown (subset):\")\n",
    "print(monocyte_subset.obs.groupby(SUBCLUSTER_COL)[TARGET_COL].value_counts().unstack(fill_value=0).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_colors' in Luecken_dataset.uns:\n",
    "    del Luecken_dataset.uns['Consensus_annotation_detailed_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Luecken_dataset, \n",
    "                color='Consensus_annotation_detailed_final', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Luecken et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation - smoothed', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# Triana_dataset: build *_final columns (broad_final + simplified_final) Zhang-style\n",
    "# - Safe on reruns (casts to object before assignment)\n",
    "# - Deterministic (resets outputs each run)\n",
    "# - Enforces fixed category orders at the end\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Column names\n",
    "# -----------------------------\n",
    "DETAIL_REFINED_COL  = \"Consensus_annotation_detailed_final\"\n",
    "DETAIL_FALLBACK_COL = \"Consensus_annotation_detailed_refined\"\n",
    "\n",
    "BROAD_FINAL_COL = \"Consensus_annotation_broad_final\"\n",
    "SIMPL_FINAL_COL = \"Consensus_annotation_simplified_final\"\n",
    "\n",
    "# If refined detailed does not exist, fall back\n",
    "DETAIL_INPUT = DETAIL_REFINED_COL if DETAIL_REFINED_COL in Luecken_dataset.obs.columns else DETAIL_FALLBACK_COL\n",
    "\n",
    "# -----------------------------\n",
    "# Fixed category orders (from your Triana simplified_final spec)\n",
    "# -----------------------------\n",
    "broad_categories = [\"Immature\", \"Mature\", \"Doublet\"]\n",
    "\n",
    "simpl_categories = [\n",
    "    'HSPC', 'Monocyte', 'CD4 T', 'CD8 T', 'Erythroid', 'B', 'cDC', 'pDC', 'NK',\n",
    "    'ILC', 'Stroma', 'Myeloid', 'Other T', 'Plasma', 'Mesenchymal', 'Macrophage'\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Ensure *_final columns exist and are OBJECT dtype (safe on reruns)\n",
    "# -----------------------------\n",
    "for col in [BROAD_FINAL_COL, SIMPL_FINAL_COL]:\n",
    "    if col not in Luecken_dataset.obs.columns:\n",
    "        Luecken_dataset.obs[col] = pd.NA\n",
    "    if pd.api.types.is_categorical_dtype(Luecken_dataset.obs[col]):\n",
    "        Luecken_dataset.obs[col] = Luecken_dataset.obs[col].astype(\"object\")\n",
    "\n",
    "# Reset each run so reruns are deterministic\n",
    "Luecken_dataset.obs[BROAD_FINAL_COL] = pd.NA\n",
    "Luecken_dataset.obs[SIMPL_FINAL_COL] = pd.NA\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Build simplified_final from detailed_refined (or fallback detailed)\n",
    "# -----------------------------\n",
    "d = Luecken_dataset.obs[DETAIL_INPUT]\n",
    "# HSPC\n",
    "Luecken_dataset.obs.loc[d.isin(['HSC', 'MPP', 'LMPP', 'EoBaMaP', 'MkP', 'MEP', 'Pre-Pro-B', 'Pro-B', 'GMP']),\n",
    "                       SIMPL_FINAL_COL] = 'HSPC'\n",
    "\n",
    "# Monocyte\n",
    "Luecken_dataset.obs.loc[d.isin(['CD14 Mono', 'CD16 Mono']), SIMPL_FINAL_COL] = 'Monocyte'\n",
    "\n",
    "# Myeloid\n",
    "Luecken_dataset.obs.loc[d.isin(['Myeloid progenitor']), SIMPL_FINAL_COL] = 'Myeloid'\n",
    "# NK\n",
    "Luecken_dataset.obs.loc[d.isin(['NK CD56 dim', 'NK CD56 bright']), SIMPL_FINAL_COL] = 'NK'\n",
    "\n",
    "# CD4 T\n",
    "Luecken_dataset.obs.loc[d.isin(['CD4 T Naive', 'CD4 T Memory', 'Treg', 'CD4 CTL']), SIMPL_FINAL_COL] = 'CD4 T'\n",
    "\n",
    "# CD8 T\n",
    "Luecken_dataset.obs.loc[d.isin(['CD8 T Naive', 'CD8 T Memory', 'MAIT']), SIMPL_FINAL_COL] = 'CD8 T'\n",
    "\n",
    "# B\n",
    "Luecken_dataset.obs.loc[d.isin(['B Naive', 'B Memory', 'Immature B', 'Pre-B']), SIMPL_FINAL_COL] = 'B'\n",
    "\n",
    "# Erythroid\n",
    "Luecken_dataset.obs.loc[d.isin(['ErP', 'Erythroblast']), SIMPL_FINAL_COL] = 'Erythroid'\n",
    "\n",
    "# Macrophage\n",
    "Luecken_dataset.obs.loc[d.isin(['Macrophage']), SIMPL_FINAL_COL] = 'Macrophage'\n",
    "\n",
    "# DnT and GdT -> Other T\n",
    "Luecken_dataset.obs.loc[d.isin(['DnT', 'GdT']), SIMPL_FINAL_COL] = 'Other T'\n",
    "\n",
    "# Mesenchymal\n",
    "Luecken_dataset.obs.loc[d.eq('Mesenchymal'), SIMPL_FINAL_COL] = 'Mesenchymal'\n",
    "# cDC\n",
    "Luecken_dataset.obs.loc[d.isin(['cDC1', 'cDC2']), SIMPL_FINAL_COL] = 'cDC'\n",
    "\n",
    "# Other T\n",
    "Luecken_dataset.obs.loc[d.isin(['GdT']), SIMPL_FINAL_COL] = 'Other T'\n",
    "\n",
    "# pDC\n",
    "Luecken_dataset.obs.loc[d.eq('pDC'), SIMPL_FINAL_COL] = 'pDC'\n",
    "\n",
    "# Stroma\n",
    "Luecken_dataset.obs.loc[d.eq('Stroma'), SIMPL_FINAL_COL] = 'Stroma'\n",
    "\n",
    "# Plasma\n",
    "Luecken_dataset.obs.loc[d.eq('Plasma'), SIMPL_FINAL_COL] = 'Plasma'\n",
    "\n",
    "# NOTE: You included 'Pro-B' as a simplified category but did not map anything to it.\n",
    "# If you intended Pro-B to be a simplified bucket (distinct from HSPC), uncomment:\n",
    "# Luecken_dataset.obs.loc[d.eq('Pro-B'), SIMPL_FINAL_COL] = 'Pro-B'\n",
    "# (Doing so would override the HSPC assignment for 'Pro-B'.)\n",
    "\n",
    "# Enforce fixed categories/order for simplified_final\n",
    "Luecken_dataset.obs[SIMPL_FINAL_COL] = pd.Categorical(Luecken_dataset.obs[SIMPL_FINAL_COL], categories=simpl_categories)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build broad_final\n",
    "#    Priority:\n",
    "#      - If simplified_final is Doublet -> Doublet\n",
    "#      - If detailed label indicates progenitor -> Immature\n",
    "#      - Else if simplified_final assigned -> Mature\n",
    "#      - Else -> Other\n",
    "# -----------------------------\n",
    "sf = Luecken_dataset.obs[SIMPL_FINAL_COL]\n",
    "\n",
    "# Doublet (only if you ever assign it in simplified_final)\n",
    "Luecken_dataset.obs.loc[sf.eq(\"Doublet\"), BROAD_FINAL_COL] = \"Doublet\"\n",
    "\n",
    "# Immature progenitors (expand if needed)\n",
    "immature_details = ['HSC', 'MPP', 'LMPP', 'EoBaMaP', 'MkP', 'MEP', 'Pre-Pro-B', 'Pro-B', 'GMP', 'ErP']\n",
    "Luecken_dataset.obs.loc[d.isin(immature_details), BROAD_FINAL_COL] = \"Immature\"\n",
    "\n",
    "# Mature: anything with an assigned simplified_final (and not already Immature/Doublet)\n",
    "Luecken_dataset.obs.loc[Luecken_dataset.obs[BROAD_FINAL_COL].isna(), BROAD_FINAL_COL] = \"Mature\"\n",
    "\n",
    "# Enforce fixed categories/order for broad_final\n",
    "Luecken_dataset.obs[BROAD_FINAL_COL] = pd.Categorical(Luecken_dataset.obs[BROAD_FINAL_COL], categories=broad_categories)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Sanity checks\n",
    "# -----------------------------\n",
    "na_simpl = int(Luecken_dataset.obs[SIMPL_FINAL_COL].isna().sum())\n",
    "na_broad = int(Luecken_dataset.obs[BROAD_FINAL_COL].isna().sum())\n",
    "print(f\"Using detail input column: {DETAIL_INPUT}\")\n",
    "print(f\"Unassigned '{SIMPL_FINAL_COL}' (NA) rows: {na_simpl} / {Luecken_dataset.n_obs}\")\n",
    "print(f\"Unassigned '{BROAD_FINAL_COL}' (NA) rows: {na_broad} / {Luecken_dataset.n_obs}\")\n",
    "\n",
    "print(\"\\nBroad final value counts:\")\n",
    "print(Luecken_dataset.obs[BROAD_FINAL_COL].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\nSimplified final value counts (top 30):\")\n",
    "print(Luecken_dataset.obs[SIMPL_FINAL_COL].value_counts(dropna=False).head(30).to_string())\n",
    "# Diagnostics for what is unmapped in simplified_final\n",
    "unmapped = (\n",
    "    Luecken_dataset.obs.loc[Luecken_dataset.obs[SIMPL_FINAL_COL].isna(), DETAIL_INPUT]\n",
    "    .astype(\"object\")\n",
    "    .fillna(\"<<NA in detailed>>\")\n",
    "    .value_counts()\n",
    "    .head(30)\n",
    ")\n",
    "print(f\"\\nTop unmapped '{DETAIL_INPUT}' labels among NA simplified_final rows (top 30):\")\n",
    "print(unmapped.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Luecken_dataset, \n",
    "                color='Consensus_annotation_broad_final', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Luecken M.D. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus broad annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/Luecken_dataset_final_consensus_annotation_broad_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_simplified_final_colors' in Luecken_dataset.uns:\n",
    "    del Luecken_dataset.uns['Consensus_annotation_simplified_final_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Luecken_dataset, \n",
    "                color='Consensus_annotation_simplified_final', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Luecken M.D. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus simplified annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/Luecken_dataset_final_consensus_annotation_simplified_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any existing color palettes to force scanpy to regenerate them\n",
    "if 'Consensus_annotation_detailed_final_colors' in Luecken_dataset.uns:\n",
    "    del Luecken_dataset.uns['Consensus_annotation_detailed_final_colors']\n",
    "\n",
    "# Plot UMAP with color\n",
    "sc.pl.embedding(Luecken_dataset, \n",
    "                color='Consensus_annotation_detailed_final', \n",
    "                basis='X_umap', \n",
    "                legend_loc='on data', \n",
    "                legend_fontsize=5,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False)\n",
    "\n",
    "# Get the current axis and set axis labels and tick labels\n",
    "ax = plt.gca()\n",
    "ax.figure.set_size_inches(6, 5)\n",
    "ax.set_xlabel('UMAP 1', fontsize=12)\n",
    "ax.set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Set the title with font size 14, bold, and increased distance from the plot\n",
    "ax.set_title('Luecken M.D. et al. dataset', fontsize=12, fontweight='bold', y=1.1)\n",
    "\n",
    "# Add a subtitle\n",
    "plt.suptitle('Consensus detailed annotation', fontsize=8, y=0.925, color=(0.5, 0.5, 0.5))\n",
    "\n",
    "# Save the figure at 300 dpi\n",
    "plt.savefig(figures_path + \"/Luecken_dataset_final_Consensus_annotation_detailed_annotation.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the remaining cell barcodes from all four processed datasets\n",
    "print(\"Getting remaining cell barcodes from all processed datasets...\")\n",
    "\n",
    "remaining_barcodes = set()\n",
    "remaining_barcodes.update(Zhang_dataset.obs_names)\n",
    "remaining_barcodes.update(Hao_dataset.obs_names)\n",
    "remaining_barcodes.update(Triana_dataset.obs_names)\n",
    "remaining_barcodes.update(Luecken_dataset.obs_names)\n",
    "\n",
    "print(f\"Total remaining cells across all datasets: {len(remaining_barcodes)}\")\n",
    "\n",
    "# Filter the original adatas object to keep only remaining cells\n",
    "print(\"Filtering original merged adatas object...\")\n",
    "remaining_mask = adatas_merged.obs_names.isin(remaining_barcodes)\n",
    "adatas_final = adatas_merged[remaining_mask].copy()\n",
    "\n",
    "print(f\"Original adatas shape: {adatas_merged.shape}\")\n",
    "print(f\"Filtered adatas_final shape: {adatas_final.shape}\")\n",
    "print(f\"Cells removed: {adatas_merged.n_obs - adatas_final.n_obs}\")\n",
    "\n",
    "# Check which cells remain from each dataset\n",
    "print(f\"\\nCells remaining per dataset:\")\n",
    "print(adatas_final.obs['dataset_name'].value_counts())\n",
    "\n",
    "# Initialize final annotation columns\n",
    "adatas_final.obs['Consensus_annotation_detailed_final'] = ''\n",
    "adatas_final.obs['Consensus_annotation_simplified_final'] = ''\n",
    "adatas_final.obs['Consensus_annotation_broad_final'] = ''\n",
    "\n",
    "# Assign final annotations from each processed dataset\n",
    "print(\"\\nAssigning final consensus annotations...\")\n",
    "\n",
    "# Zhang dataset assignments\n",
    "zhang_mask = adatas_final.obs['dataset_name'] == 'Zhang'\n",
    "zhang_indices = adatas_final.obs_names[zhang_mask]\n",
    "zhang_overlap = zhang_indices.intersection(Zhang_dataset.obs_names)\n",
    "\n",
    "if len(zhang_overlap) > 0:\n",
    "    adatas_final.obs.loc[zhang_overlap, 'Consensus_annotation_detailed_final'] = Zhang_dataset.obs.loc[zhang_overlap, 'Consensus_annotation_detailed_final'].values\n",
    "    adatas_final.obs.loc[zhang_overlap, 'Consensus_annotation_simplified_final'] = Zhang_dataset.obs.loc[zhang_overlap, 'Consensus_annotation_simplified_final'].values\n",
    "    adatas_final.obs.loc[zhang_overlap, 'Consensus_annotation_broad_final'] = Zhang_dataset.obs.loc[zhang_overlap, 'Consensus_annotation_broad_final'].values\n",
    "    print(f\"Zhang: Assigned annotations to {len(zhang_overlap)} cells\")\n",
    "\n",
    "# Hao dataset assignments\n",
    "hao_mask = adatas_final.obs['dataset_name'] == 'Hao'\n",
    "hao_indices = adatas_final.obs_names[hao_mask]\n",
    "hao_overlap = hao_indices.intersection(Hao_dataset.obs_names)\n",
    "\n",
    "if len(hao_overlap) > 0:\n",
    "    adatas_final.obs.loc[hao_overlap, 'Consensus_annotation_detailed_final'] = Hao_dataset.obs.loc[hao_overlap, 'Consensus_annotation_detailed_final'].values\n",
    "    adatas_final.obs.loc[hao_overlap, 'Consensus_annotation_simplified_final'] = Hao_dataset.obs.loc[hao_overlap, 'Consensus_annotation_simplified_final'].values\n",
    "    adatas_final.obs.loc[hao_overlap, 'Consensus_annotation_broad_final'] = Hao_dataset.obs.loc[hao_overlap, 'Consensus_annotation_broad_final'].values\n",
    "    print(f\"Hao: Assigned annotations to {len(hao_overlap)} cells\")\n",
    "\n",
    "# Triana dataset assignments\n",
    "triana_mask = adatas_final.obs['dataset_name'] == 'Triana'\n",
    "triana_indices = adatas_final.obs_names[triana_mask]\n",
    "triana_overlap = triana_indices.intersection(Triana_dataset.obs_names)\n",
    "\n",
    "if len(triana_overlap) > 0:\n",
    "    adatas_final.obs.loc[triana_overlap, 'Consensus_annotation_detailed_final'] = Triana_dataset.obs.loc[triana_overlap, 'Consensus_annotation_detailed_final'].values\n",
    "    adatas_final.obs.loc[triana_overlap, 'Consensus_annotation_simplified_final'] = Triana_dataset.obs.loc[triana_overlap, 'Consensus_annotation_simplified_final'].values\n",
    "    adatas_final.obs.loc[triana_overlap, 'Consensus_annotation_broad_final'] = Triana_dataset.obs.loc[triana_overlap, 'Consensus_annotation_broad_final'].values\n",
    "    print(f\"Triana: Assigned annotations to {len(triana_overlap)} cells\")\n",
    "\n",
    "# Luecken dataset assignments\n",
    "luecken_mask = adatas_final.obs['dataset_name'] == 'Luecken'\n",
    "luecken_indices = adatas_final.obs_names[luecken_mask]\n",
    "luecken_overlap = luecken_indices.intersection(Luecken_dataset.obs_names)\n",
    "\n",
    "if len(luecken_overlap) > 0:\n",
    "    adatas_final.obs.loc[luecken_overlap, 'Consensus_annotation_detailed_final'] = Luecken_dataset.obs.loc[luecken_overlap, 'Consensus_annotation_detailed_final'].values\n",
    "    adatas_final.obs.loc[luecken_overlap, 'Consensus_annotation_simplified_final'] = Luecken_dataset.obs.loc[luecken_overlap, 'Consensus_annotation_simplified_final'].values\n",
    "    adatas_final.obs.loc[luecken_overlap, 'Consensus_annotation_broad_final'] = Luecken_dataset.obs.loc[luecken_overlap, 'Consensus_annotation_broad_final'].values\n",
    "    print(f\"Luecken: Assigned annotations to {len(luecken_overlap)} cells\")\n",
    "\n",
    "# Convert to categorical\n",
    "adatas_final.obs['Consensus_annotation_detailed_final'] = pd.Categorical(adatas_final.obs['Consensus_annotation_detailed_final'])\n",
    "adatas_final.obs['Consensus_annotation_simplified_final'] = pd.Categorical(adatas_final.obs['Consensus_annotation_simplified_final'])\n",
    "adatas_final.obs['Consensus_annotation_broad_final'] = pd.Categorical(adatas_final.obs['Consensus_annotation_broad_final'])\n",
    "\n",
    "# Remove any cells that didn't get annotations assigned (shouldn't happen but safety check)\n",
    "unassigned_mask = adatas_final.obs['Consensus_annotation_detailed_final'] == ''\n",
    "if unassigned_mask.sum() > 0:\n",
    "    print(f\"Warning: {unassigned_mask.sum()} cells did not receive final annotations. Removing them.\")\n",
    "    adatas_final = adatas_final[~unassigned_mask]\n",
    "\n",
    "print(f\"\\n=== FINAL DATASET SUMMARY ===\")\n",
    "print(f\"Final dataset shape: {adatas_final.shape}\")\n",
    "print(f\"Final cells per dataset:\")\n",
    "print(adatas_final.obs['dataset_name'].value_counts())\n",
    "\n",
    "print(f\"\\nFinal broad annotation distribution:\")\n",
    "print(adatas_final.obs['Consensus_annotation_broad_final'].value_counts())\n",
    "\n",
    "print(f\"\\nFinal simplified annotation distribution:\")\n",
    "print(adatas_final.obs['Consensus_annotation_simplified_final'].value_counts())\n",
    "\n",
    "print(f\"\\nFinal detailed annotation distribution:\")\n",
    "print(adatas_final.obs['Consensus_annotation_detailed_final'].value_counts())\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Plot 1: Dataset distribution\n",
    "sc.pl.embedding(adatas_final, \n",
    "                color='dataset_name', \n",
    "                basis='X_umap', \n",
    "                legend_loc='right margin',\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[0,0])\n",
    "axes[0,0].set_title('Dataset Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_xlabel('UMAP 1', fontsize=12)\n",
    "axes[0,0].set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Plot 2: Final broad annotations\n",
    "sc.pl.embedding(adatas_final, \n",
    "                color='Consensus_annotation_broad_final', \n",
    "                basis='X_umap',\n",
    "                legend_loc='right margin',\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[0,1])\n",
    "axes[0,1].set_title('Final Broad Annotations', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_xlabel('UMAP 1', fontsize=12)\n",
    "axes[0,1].set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Plot 3: Final simplified annotations\n",
    "sc.pl.embedding(adatas_final, \n",
    "                color='Consensus_annotation_simplified_final', \n",
    "                basis='X_umap',\n",
    "                legend_loc='on data',\n",
    "                legend_fontsize=6,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[0,2])\n",
    "axes[0,2].set_title('Final Simplified Annotations', fontsize=14, fontweight='bold')\n",
    "axes[0,2].set_xlabel('UMAP 1', fontsize=12)\n",
    "axes[0,2].set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Plot 4: Final detailed annotations\n",
    "sc.pl.embedding(adatas_final, \n",
    "                color='Consensus_annotation_detailed_final', \n",
    "                basis='X_umap',\n",
    "                legend_loc='on data',\n",
    "                legend_fontsize=4,\n",
    "                legend_fontoutline=2,\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[1,0])\n",
    "axes[1,0].set_title('Final Detailed Annotations', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('UMAP 1', fontsize=12)\n",
    "axes[1,0].set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Plot 5: Chemistry distribution\n",
    "sc.pl.embedding(adatas_final, \n",
    "                color='Chemistry', \n",
    "                basis='X_umap',\n",
    "                legend_loc='right margin',\n",
    "                add_outline=False,\n",
    "                frameon=False,\n",
    "                show=False,\n",
    "                ax=axes[1,1])\n",
    "axes[1,1].set_title('Chemistry Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('UMAP 1', fontsize=12)\n",
    "axes[1,1].set_ylabel('UMAP 2', fontsize=12)\n",
    "\n",
    "# Plot 6: Summary statistics as text\n",
    "axes[1,2].axis('off')\n",
    "summary_text = f\"\"\"\n",
    "Final Dataset Summary:\n",
    "\n",
    "Total cells: {len(adatas_final):,}\n",
    "Total features: {adatas_final.n_vars}\n",
    "\n",
    "Cells per dataset:\n",
    "Zhang: {(adatas_final.obs['dataset_name'] == 'Zhang').sum():,}\n",
    "Hao: {(adatas_final.obs['dataset_name'] == 'Hao').sum():,}\n",
    "Triana: {(adatas_final.obs['dataset_name'] == 'Triana').sum():,}\n",
    "Luecken: {(adatas_final.obs['dataset_name'] == 'Luecken').sum():,}\n",
    "\n",
    "Broad categories:\n",
    "{chr(10).join([f\"{cat}: {count:,}\" for cat, count in adatas_final.obs['Consensus_annotation_broad_final'].value_counts().items()])}\n",
    "\n",
    "Cell types identified:\n",
    "Detailed: {adatas_final.obs['Consensus_annotation_detailed_final'].nunique()}\n",
    "Simplified: {adatas_final.obs['Consensus_annotation_simplified_final'].nunique()}\n",
    "\"\"\"\n",
    "\n",
    "axes[1,2].text(0.05, 0.95, summary_text, transform=axes[1,2].transAxes, \n",
    "               fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_path + \"/Final_merged_datasets_comprehensive_overview.png\", \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFinal merged dataset with consensus annotations is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# ---------------------------\n",
    "# Output dir (fallback if not preset)\n",
    "# ---------------------------\n",
    "if \"figures_path\" not in globals():\n",
    "    figures_path = \"./figures\"\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "# ---------- Custom palette ----------\n",
    "custom_palette = {\n",
    "    'B Memory': \"#68D827\", 'B Naive': '#1C511D', 'CD14 Mono': \"#D27CE3\",\n",
    "    'CD16 Mono': \"#8D43CD\", 'CD4 T Memory': \"#C1AF93\", 'CD4 T Naive': \"#C99546\",\n",
    "    'CD8 T Memory': \"#6B3317\", 'CD8 T Naive': \"#4D382E\", 'ErP': \"#D1235A\",\n",
    "    'Erythroblast': \"#F30A1A\", 'GMP': \"#C5E4FF\", 'HSC': '#0079ea', 'MPP': \"#79b6ac\",\n",
    "    'Immature B': \"#91FF7B\", 'LMPP': \"#17BECF\", 'MAIT': \"#BCBD22\",\n",
    "    'Myeloid progenitor': \"#AEC7E8\", 'NK CD56 bright': \"#F3AC1F\",\n",
    "    'NK CD56 dim': \"#FBEF0D\", 'Plasma': \"#9DC012\", 'Pro-B': \"#66BB6A\",\n",
    "    'Small': \"#292929\", 'cDC1': \"#76A7CB\", 'cDC2': \"#16D2E3\", 'GdT': \"#EDB416\",\n",
    "    'pDC': \"#69FFCB\", 'CD4 CTL': \"#D7D2CB\", 'MEP': \"#E364B0\", 'Pre-B': \"#2DBD67\",\n",
    "    'Pre-Pro-B': '#92AC8E', 'EoBaMaP': \"#728245\", 'MkP': \"#69424D\",\n",
    "    'Stroma': \"#727272\", 'Macrophage': \"#5F4761\", 'ILC': \"#F7CF94\", 'DnT': \"#504423\",\n",
    "    'GdT_DnT': \"#B07A2A\",\n",
    "}\n",
    "fallback = \"#BBBBBB\"\n",
    "\n",
    "# ---------- Column to plot ----------\n",
    "col = \"Consensus_annotation_detailed_final\"\n",
    "if col not in adatas_final.obs:\n",
    "    raise KeyError(f\"Column '{col}' not found in adatas_final.obs\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1) PERMANENTLY DROP unwanted cell types\n",
    "# =============================================================================\n",
    "remove_labels = {\"Mesenchymal\", \"Platelet\", \"Macrophage\", \"ILC\", \"DnT\"}\n",
    "\n",
    "mask_keep = ~adatas_final.obs[col].astype(str).isin(remove_labels)\n",
    "adatas_final = adatas_final[mask_keep].copy()\n",
    "\n",
    "# Drop unused categories if categorical\n",
    "if pd.api.types.is_categorical_dtype(adatas_final.obs[col]):\n",
    "    adatas_final.obs[col] = adatas_final.obs[col].cat.remove_unused_categories()\n",
    "\n",
    "# =============================================================================\n",
    "# 2) DEFINE GLOBAL CATEGORY ORDER + GLOBAL NUMBERING\n",
    "# =============================================================================\n",
    "plot_col = f\"{col}_plot\"\n",
    "adatas_final.obs[plot_col] = pd.Categorical(adatas_final.obs[col].astype(str))\n",
    "cats_global = list(adatas_final.obs[plot_col].cat.categories)\n",
    "cat_to_num_global = {cat: i + 1 for i, cat in enumerate(cats_global)}\n",
    "\n",
    "# ---------- Color alignment ----------\n",
    "palette_list = [custom_palette.get(cat, fallback) for cat in cats_global]\n",
    "adatas_final.uns[f\"{plot_col}_colors\"] = palette_list\n",
    "\n",
    "# ---------- Compute centroids ----------\n",
    "umap_key = \"X_umap\"\n",
    "if umap_key not in adatas_final.obsm_keys():\n",
    "    raise KeyError(f\"Embedding '{umap_key}' not found in adatas_final.obsm\")\n",
    "\n",
    "umap_coords = adatas_final.obsm[umap_key]\n",
    "df = pd.DataFrame(umap_coords[:, :2], columns=[\"UMAP1\", \"UMAP2\"], index=adatas_final.obs_names)\n",
    "df[plot_col] = adatas_final.obs[plot_col].astype(str)\n",
    "\n",
    "centroids = (\n",
    "    df.groupby(plot_col)[[\"UMAP1\", \"UMAP2\"]]\n",
    "      .mean()\n",
    "      .reindex(cats_global)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 3) UMAP PLOT\n",
    "# =============================================================================\n",
    "fig, ax = plt.subplots(figsize=(5.5, 4.5), dpi=300)\n",
    "\n",
    "sc.pl.embedding(\n",
    "    adatas_final,\n",
    "    color=plot_col,\n",
    "    basis=umap_key,\n",
    "    title=\"\",\n",
    "    legend_loc=None,\n",
    "    outline_width=(1, 0.1),\n",
    "    add_outline=True,\n",
    "    size=1,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_aspect(\"auto\")\n",
    "\n",
    "# ---------- Draw centroid circles ----------\n",
    "for _, row in centroids.iterrows():\n",
    "    label = row[plot_col]\n",
    "    color = custom_palette.get(label, fallback)\n",
    "    num = cat_to_num_global[label]\n",
    "\n",
    "    ax.scatter(\n",
    "        row[\"UMAP1\"], row[\"UMAP2\"],\n",
    "        s=120, facecolor=color, edgecolor=\"black\",\n",
    "        alpha=0.6, linewidth=0.7, zorder=10\n",
    "    )\n",
    "\n",
    "    txt = ax.text(\n",
    "        row[\"UMAP1\"], row[\"UMAP2\"], str(num),\n",
    "        ha=\"center\", va=\"center\",\n",
    "        fontsize=5.5, color=\"white\", weight=\"bold\", zorder=11\n",
    "    )\n",
    "    txt.set_path_effects([PathEffects.withStroke(linewidth=1.1, foreground=\"black\")])\n",
    "\n",
    "plt.tight_layout(pad=0.2)\n",
    "\n",
    "# ---------- Save UMAP plot ----------\n",
    "plot_png = os.path.join(figures_path, \"Final_merged_datasets_annotation_plot.png\")\n",
    "plot_pdf = os.path.join(figures_path, \"Final_merged_datasets_annotation_plot.pdf\")\n",
    "fig.savefig(plot_png, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "fig.savefig(plot_pdf, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# =============================================================================\n",
    "# 4) LEGEND FIGURE\n",
    "# =============================================================================\n",
    "handles, labels = [], []\n",
    "for cat in cats_global:\n",
    "    color = custom_palette.get(cat, fallback)\n",
    "    handles.append(\n",
    "        Line2D(\n",
    "            [0], [0], marker=\"o\", color=\"none\",\n",
    "            markerfacecolor=color, markeredgecolor=\"black\",\n",
    "            lw=0, markersize=6\n",
    "        )\n",
    "    )\n",
    "    labels.append(f\"{cat_to_num_global[cat]}. {cat}\")\n",
    "\n",
    "fig_leg = plt.figure(figsize=(5.5, 1.2), dpi=300)\n",
    "fig_leg.legend(\n",
    "    handles, labels,\n",
    "    loc=\"center\",\n",
    "    ncol=5,\n",
    "    frameon=False,\n",
    "    fontsize=5.0,\n",
    "    handletextpad=0.5,\n",
    "    columnspacing=0.9,\n",
    "    labelspacing=0.3\n",
    ")\n",
    "fig_leg.gca().axis(\"off\")\n",
    "\n",
    "legend_png = os.path.join(figures_path, \"Final_merged_datasets_annotation_legend.png\")\n",
    "legend_pdf = os.path.join(figures_path, \"Final_merged_datasets_annotation_legend.pdf\")\n",
    "fig_leg.savefig(legend_png, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "fig_leg.savefig(legend_pdf, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "plt.close(fig_leg)\n",
    "\n",
    "# =============================================================================\n",
    "# 5) EXPORT number -> cell type mapping\n",
    "# =============================================================================\n",
    "mapping_df = pd.DataFrame({\n",
    "    \"Number\": [cat_to_num_global[c] for c in cats_global],\n",
    "    \"CellType\": cats_global,\n",
    "    \"Color\": [custom_palette.get(c, fallback) for c in cats_global],\n",
    "})\n",
    "mapping_csv = os.path.join(figures_path, \"Final_merged_datasets_annotation_mapping.csv\")\n",
    "mapping_df.to_csv(mapping_csv, index=False)\n",
    "\n",
    "print(\"[INFO] Saved plot, legend, and mapping:\")\n",
    "print(\" -\", plot_png)\n",
    "print(\" -\", plot_pdf)\n",
    "print(\" -\", legend_png)\n",
    "print(\" -\", legend_pdf)\n",
    "print(\" -\", mapping_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_final.obs['Chemistry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# ---------------------------\n",
    "# Output dir (fallback if not preset)\n",
    "# ---------------------------\n",
    "if \"figures_path\" not in globals():\n",
    "    figures_path = \"./figures\"\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Plot Chemistry (3 categories) with fixed colours\n",
    "# ---------------------------\n",
    "col = \"Chemistry\"\n",
    "if col not in adatas_final.obs:\n",
    "    raise KeyError(f\"Column '{col}' not found in adatas_final.obs\")\n",
    "\n",
    "chem_palette = {\n",
    "    \"BD AbSeq\": \"#D1235A\",\n",
    "    \"BioLegend TotalSeqA\": \"#F3AC1F\",\n",
    "    \"BioLegend TotalSeqB\": \"#8D43CD\",\n",
    "}\n",
    "fallback = \"#BBBBBB\"\n",
    "\n",
    "# Optional: filter nothing (keep all)\n",
    "remove_labels = set()\n",
    "mask_keep = ~adatas_final.obs[col].astype(\"object\").isin(remove_labels)\n",
    "adatas_plot = adatas_final[mask_keep].copy()\n",
    "\n",
    "plot_col = f\"{col}_plot\"\n",
    "adatas_plot.obs[plot_col] = adatas_plot.obs[col].astype(\"object\")\n",
    "adatas_plot.obs[plot_col] = pd.Categorical(adatas_plot.obs[plot_col])\n",
    "\n",
    "# Align colours to categories present (in category order)\n",
    "cats = list(adatas_plot.obs[plot_col].cat.categories)\n",
    "adatas_plot.uns[f\"{plot_col}_colors\"] = [chem_palette.get(c, fallback) for c in cats]\n",
    "\n",
    "# Compute centroids\n",
    "umap_coords = adatas_plot.obsm[\"X_umap\"]\n",
    "df = pd.DataFrame(umap_coords, columns=[\"UMAP1\", \"UMAP2\"], index=adatas_plot.obs_names)\n",
    "df[plot_col] = adatas_plot.obs[plot_col].astype(str)\n",
    "\n",
    "centroids = (\n",
    "    df.groupby(plot_col)[[\"UMAP1\", \"UMAP2\"]]\n",
    "      .mean()\n",
    "      .reindex(cats)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "cat_to_num = {cat: i + 1 for i, cat in enumerate(cats)}\n",
    "\n",
    "# ---------------------------\n",
    "# Main plot\n",
    "# ---------------------------\n",
    "fig, ax = plt.subplots(figsize=(5.5, 4.5), dpi=300)\n",
    "\n",
    "sc.pl.embedding(\n",
    "    adatas_plot,\n",
    "    color=plot_col,\n",
    "    basis=\"X_umap\",\n",
    "    title=\"\",\n",
    "    legend_loc=None,\n",
    "    outline_width=(1, 0.1),\n",
    "    add_outline=True,\n",
    "    size=1,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_aspect(\"auto\")\n",
    "\n",
    "# (Your current settings: invisible centroid markers/text)\n",
    "for _, row in centroids.iterrows():\n",
    "    label = row[plot_col]\n",
    "    color = chem_palette.get(label, fallback)\n",
    "    num = cat_to_num[label]\n",
    "\n",
    "    ax.scatter(\n",
    "        row[\"UMAP1\"], row[\"UMAP2\"],\n",
    "        s=120, facecolor=color, edgecolor=\"black\",\n",
    "        alpha=0, linewidth=0.7, zorder=10\n",
    "    )\n",
    "\n",
    "    txt = ax.text(\n",
    "        row[\"UMAP1\"], row[\"UMAP2\"], str(num),\n",
    "        ha=\"center\", va=\"center\",\n",
    "        fontsize=0, color=\"white\", weight=\"bold\", zorder=11\n",
    "    )\n",
    "    txt.set_path_effects([PathEffects.withStroke(linewidth=1.1, foreground=\"black\")])\n",
    "\n",
    "plt.tight_layout(pad=0.2)\n",
    "\n",
    "# Save (PNG + PDF, transparent)\n",
    "plot_png = os.path.join(figures_path, \"Final_merged_datasets_Chemistry_plot.png\")\n",
    "plot_pdf = os.path.join(figures_path, \"Final_merged_datasets_Chemistry_plot.pdf\")\n",
    "fig.savefig(plot_png, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "fig.savefig(plot_pdf, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# ---------------------------\n",
    "# Legend figure (only) - max 2 columns\n",
    "# ---------------------------\n",
    "handles, labels = [], []\n",
    "for cat in cats:\n",
    "    color = chem_palette.get(cat, fallback)\n",
    "    handles.append(\n",
    "        Line2D([0], [0],\n",
    "               marker='o', color='none',\n",
    "               markerfacecolor=color, markeredgecolor='black',\n",
    "               lw=0, markersize=6)\n",
    "    )\n",
    "    labels.append(f\"{cat_to_num[cat]}. {cat}\")\n",
    "\n",
    "fig_leg = plt.figure(figsize=(5.5, 1.2), dpi=300)\n",
    "fig_leg.legend(\n",
    "    handles, labels,\n",
    "    loc='center',\n",
    "    ncol=min(2, max(1, len(labels))),\n",
    "    frameon=False,\n",
    "    fontsize=6.0,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    labelspacing=0.4\n",
    ")\n",
    "fig_leg.gca().axis('off')\n",
    "\n",
    "legend_png = os.path.join(figures_path, \"Final_merged_datasets_Chemistry_legend.png\")\n",
    "legend_pdf = os.path.join(figures_path, \"Final_merged_datasets_Chemistry_legend.pdf\")\n",
    "fig_leg.savefig(legend_png, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "fig_leg.savefig(legend_pdf, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "plt.close(fig_leg)\n",
    "\n",
    "# ---------------------------\n",
    "# Export number->chemistry mapping\n",
    "# ---------------------------\n",
    "mapping_df = pd.DataFrame({\n",
    "    \"Number\": [cat_to_num[c] for c in cats],\n",
    "    \"Chemistry\": cats,\n",
    "    \"Color\": [chem_palette.get(c, fallback) for c in cats],\n",
    "})\n",
    "mapping_csv = os.path.join(figures_path, \"Final_merged_datasets_Chemistry_mapping.csv\")\n",
    "mapping_df.to_csv(mapping_csv, index=False)\n",
    "\n",
    "print(\"[INFO] Saved Chemistry plot, legend, and mapping:\")\n",
    "print(\" -\", plot_png)\n",
    "print(\" -\", plot_pdf)\n",
    "print(\" -\", legend_png)\n",
    "print(\" -\", legend_pdf)\n",
    "print(\" -\", mapping_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_final.obs['dataset_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# ---------------------------\n",
    "# Output dir (fallback if not preset)\n",
    "# ---------------------------\n",
    "if \"figures_path\" not in globals():\n",
    "    figures_path = \"./figures\"\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Plot dataset_name with fixed colours\n",
    "# ---------------------------\n",
    "col = \"dataset_name\"\n",
    "if col not in adatas_final.obs:\n",
    "    raise KeyError(f\"Column '{col}' not found in adatas_final.obs\")\n",
    "\n",
    "dataset_palette = {\n",
    "    \"Zhang\": \"#CDA72B\",\n",
    "    \"Hao\": \"#D23A3A\",\n",
    "    \"Triana\": \"#3381D0\",\n",
    "    \"Luecken\": \"#31AF33\",\n",
    "}\n",
    "fallback = \"#BBBBBB\"\n",
    "\n",
    "# Optional: filter nothing (keep all)\n",
    "remove_labels = set()\n",
    "mask_keep = ~adatas_final.obs[col].astype(\"object\").isin(remove_labels)\n",
    "adatas_plot = adatas_final[mask_keep].copy()\n",
    "\n",
    "plot_col = f\"{col}_plot\"\n",
    "adatas_plot.obs[plot_col] = adatas_plot.obs[col].astype(\"object\")\n",
    "adatas_plot.obs[plot_col] = pd.Categorical(adatas_plot.obs[plot_col])\n",
    "\n",
    "# ---------------------------\n",
    "# Force draw order: Luecken bottom, Hao top\n",
    "# ---------------------------\n",
    "cats0 = list(adatas_plot.obs[plot_col].cat.categories)\n",
    "middle = [c for c in cats0 if c not in [\"Hao\", \"Luecken\"]]\n",
    "\n",
    "new_order = []\n",
    "if \"Luecken\" in cats0:\n",
    "    new_order.append(\"Luecken\")\n",
    "new_order += middle\n",
    "if \"Hao\" in cats0:\n",
    "    new_order.append(\"Hao\")\n",
    "\n",
    "adatas_plot.obs[plot_col] = adatas_plot.obs[plot_col].cat.reorder_categories(\n",
    "    new_order, ordered=True\n",
    ")\n",
    "\n",
    "# Align colours to categories present (in the new category order)\n",
    "cats = list(adatas_plot.obs[plot_col].cat.categories)\n",
    "adatas_plot.uns[f\"{plot_col}_colors\"] = [dataset_palette.get(c, fallback) for c in cats]\n",
    "\n",
    "# Compute centroids (centroids will also follow category order)\n",
    "umap_coords = adatas_plot.obsm[\"X_umap\"]\n",
    "df = pd.DataFrame(umap_coords, columns=[\"UMAP1\", \"UMAP2\"], index=adatas_plot.obs_names)\n",
    "df[plot_col] = adatas_plot.obs[plot_col].astype(str)\n",
    "\n",
    "centroids = (\n",
    "    df.groupby(plot_col)[[\"UMAP1\", \"UMAP2\"]]\n",
    "      .mean()\n",
    "      .reindex(cats)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "cat_to_num = {cat: i + 1 for i, cat in enumerate(cats)}\n",
    "\n",
    "# ---------------------------\n",
    "# Main plot\n",
    "# ---------------------------\n",
    "fig, ax = plt.subplots(figsize=(5.5, 4.5), dpi=300)\n",
    "\n",
    "sc.pl.embedding(\n",
    "    adatas_plot,\n",
    "    color=plot_col,\n",
    "    basis=\"X_umap\",\n",
    "    title=\"\",\n",
    "    legend_loc=None,\n",
    "    outline_width=(1, 0.1),\n",
    "    add_outline=True,\n",
    "    size=1,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_aspect(\"auto\")\n",
    "\n",
    "# (Match your prior behaviour: invisible centroid markers/text)\n",
    "for _, row in centroids.iterrows():\n",
    "    label = row[plot_col]\n",
    "    color = dataset_palette.get(label, fallback)\n",
    "    num = cat_to_num[label]\n",
    "\n",
    "    ax.scatter(\n",
    "        row[\"UMAP1\"], row[\"UMAP2\"],\n",
    "        s=120, facecolor=color, edgecolor=\"black\",\n",
    "        alpha=0, linewidth=0.7, zorder=10\n",
    "    )\n",
    "\n",
    "    txt = ax.text(\n",
    "        row[\"UMAP1\"], row[\"UMAP2\"], str(num),\n",
    "        ha=\"center\", va=\"center\",\n",
    "        fontsize=0, color=\"white\", weight=\"bold\", zorder=11\n",
    "    )\n",
    "    txt.set_path_effects([PathEffects.withStroke(linewidth=1.1, foreground=\"black\")])\n",
    "\n",
    "plt.tight_layout(pad=0.2)\n",
    "\n",
    "plot_png = os.path.join(figures_path, \"Final_merged_datasets_dataset_name_plot.png\")\n",
    "plot_pdf = os.path.join(figures_path, \"Final_merged_datasets_dataset_name_plot.pdf\")\n",
    "fig.savefig(plot_png, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "fig.savefig(plot_pdf, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# ---------------------------\n",
    "# Legend figure (only)\n",
    "# ---------------------------\n",
    "handles, labels = [], []\n",
    "for cat in cats:\n",
    "    color = dataset_palette.get(cat, fallback)\n",
    "    handles.append(\n",
    "        Line2D([0], [0],\n",
    "               marker='o', color='none',\n",
    "               markerfacecolor=color, markeredgecolor='black',\n",
    "               lw=0, markersize=6)\n",
    "    )\n",
    "    labels.append(f\"{cat_to_num[cat]}. {cat}\")\n",
    "\n",
    "fig_leg = plt.figure(figsize=(5.5, 1.2), dpi=300)\n",
    "fig_leg.legend(\n",
    "    handles, labels,\n",
    "    loc='center',\n",
    "    ncol=2,\n",
    "    frameon=False,\n",
    "    fontsize=6.0,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    labelspacing=0.4\n",
    ")\n",
    "fig_leg.gca().axis('off')\n",
    "\n",
    "legend_png = os.path.join(figures_path, \"Final_merged_datasets_dataset_name_legend.png\")\n",
    "legend_pdf = os.path.join(figures_path, \"Final_merged_datasets_dataset_name_legend.pdf\")\n",
    "fig_leg.savefig(legend_png, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "fig_leg.savefig(legend_pdf, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "plt.close(fig_leg)\n",
    "\n",
    "# ---------------------------\n",
    "# Mapping CSV\n",
    "# ---------------------------\n",
    "mapping_df = pd.DataFrame({\n",
    "    \"Number\": [cat_to_num[c] for c in cats],\n",
    "    \"dataset_name\": cats,\n",
    "    \"Color\": [dataset_palette.get(c, fallback) for c in cats],\n",
    "})\n",
    "mapping_csv = os.path.join(figures_path, \"Final_merged_datasets_dataset_name_mapping.csv\")\n",
    "mapping_df.to_csv(mapping_csv, index=False)\n",
    "\n",
    "print(\"[INFO] Saved dataset_name plot, legend, and mapping:\")\n",
    "print(\" -\", plot_png)\n",
    "print(\" -\", plot_pdf)\n",
    "print(\" -\", legend_png)\n",
    "print(\" -\", legend_pdf)\n",
    "print(\" -\", mapping_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# Permanently remove selected cell types (if present) BEFORE exporting h5ad\n",
    "# ============================================================\n",
    "\n",
    "# Cell types to remove\n",
    "REMOVE_LABELS = {\"Mesenchymal\", \"Platelet\", \"Macrophage\", \"ILC\", \"DnT\"}\n",
    "\n",
    "# Which annotation columns to try (first found will be used)\n",
    "ANNOT_COL_CANDIDATES = [\n",
    "    \"Consensus_annotation_detailed_final\",\n",
    "    \"Consensus_annotation_detailed_refined\",\n",
    "    \"Consensus_annotation_detailed\",\n",
    "    \"Consensus_annotation_simplified_final\",\n",
    "    \"Consensus_annotation_simplified\",\n",
    "]\n",
    "\n",
    "def remove_celltypes_if_exist(\n",
    "    adata,\n",
    "    remove_labels=REMOVE_LABELS,\n",
    "    col_candidates=ANNOT_COL_CANDIDATES,\n",
    "    dataset_name=\"adata\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Permanently drops cells whose annotation label is in remove_labels, using the\n",
    "    first available annotation column in col_candidates.\n",
    "\n",
    "    Returns:\n",
    "        AnnData (possibly filtered). If filtered, this is a fresh .copy() (not a view).\n",
    "    \"\"\"\n",
    "    # pick first available annotation column\n",
    "    ann_col = next((c for c in col_candidates if c in adata.obs.columns), None)\n",
    "    if ann_col is None:\n",
    "        print(f\"[WARN] {dataset_name}: none of {col_candidates} found in .obs; skipping removal.\")\n",
    "        return adata\n",
    "\n",
    "    remove_set = set(remove_labels)\n",
    "\n",
    "    s = adata.obs[ann_col].astype(\"object\")\n",
    "    present = sorted(set(s.dropna().unique()) & remove_set)\n",
    "\n",
    "    if not present:\n",
    "        print(f\"[INFO] {dataset_name}: none of {sorted(remove_set)} present in '{ann_col}'. No filtering applied.\")\n",
    "        return adata\n",
    "\n",
    "    mask_keep = ~s.isin(remove_set)\n",
    "    removed_n = int((~mask_keep).sum())\n",
    "    kept_n = int(mask_keep.sum())\n",
    "    print(\n",
    "        f\"[INFO] {dataset_name}: permanently removing {removed_n} cells \"\n",
    "        f\"(keeping {kept_n}) with labels {present} using column '{ann_col}'.\"\n",
    "    )\n",
    "\n",
    "    # slice + copy to ensure permanent removal downstream (no views)\n",
    "    adata2 = adata[mask_keep].copy()\n",
    "\n",
    "    # clean unused categories for any categorical annotation columns we care about\n",
    "    for col in col_candidates:\n",
    "        if col in adata2.obs.columns and pd.api.types.is_categorical_dtype(adata2.obs[col]):\n",
    "            adata2.obs[col] = adata2.obs[col].cat.remove_unused_categories()\n",
    "\n",
    "    return adata2\n",
    "\n",
    "# -------------------\n",
    "# Apply to each dataset (PERMANENT filtering)\n",
    "# -------------------\n",
    "Zhang_dataset   = remove_celltypes_if_exist(Zhang_dataset,   dataset_name=\"Zhang_dataset\")\n",
    "Hao_dataset     = remove_celltypes_if_exist(Hao_dataset,     dataset_name=\"Hao_dataset\")\n",
    "Triana_dataset  = remove_celltypes_if_exist(Triana_dataset,  dataset_name=\"Triana_dataset\")\n",
    "Luecken_dataset = remove_celltypes_if_exist(Luecken_dataset, dataset_name=\"Luecken_dataset\")\n",
    "\n",
    "# -------------------\n",
    "# Export (ensure dirs exist)\n",
    "# -------------------\n",
    "os.makedirs(data_path + \"/References/Zhang\",   exist_ok=True)\n",
    "os.makedirs(data_path + \"/References/Hao\",     exist_ok=True)\n",
    "os.makedirs(data_path + \"/References/Triana\",  exist_ok=True)\n",
    "os.makedirs(data_path + \"/References/Luecken\", exist_ok=True)\n",
    "\n",
    "def make_obs_h5ad_safe_no_nullable_strings(adata, dataset_name=\"adata\"):\n",
    "    \"\"\"\n",
    "    Sanitizes adata.obs to avoid pandas nullable string dtype issues during h5ad export:\n",
    "      - converts non-object string dtype to object\n",
    "      - normalizes object columns to pure python str (keeping missing values)\n",
    "      - casts object columns to categorical for compactness / stable export\n",
    "    \"\"\"\n",
    "    for c in list(adata.obs.columns):\n",
    "        s = adata.obs[c]\n",
    "\n",
    "        # If it's pandas nullable string or other non-object string dtype, convert to object\n",
    "        if pd.api.types.is_string_dtype(s) and not pd.api.types.is_object_dtype(s):\n",
    "            adata.obs[c] = s.astype(\"object\")\n",
    "\n",
    "        # If it's object, force all non-missing values to plain Python str\n",
    "        if pd.api.types.is_object_dtype(adata.obs[c]):\n",
    "            adata.obs[c] = (\n",
    "                adata.obs[c]\n",
    "                .where(pd.notna(adata.obs[c]), pd.NA)\n",
    "                .map(lambda x: str(x) if x is not pd.NA else pd.NA)\n",
    "            )\n",
    "            # Optional: categorical for compactness and stable export\n",
    "            adata.obs[c] = pd.Categorical(adata.obs[c])\n",
    "\n",
    "    print(f\"[INFO] {dataset_name}: obs columns sanitized for h5ad export (no nullable strings).\")\n",
    "\n",
    "make_obs_h5ad_safe_no_nullable_strings(Zhang_dataset, \"Zhang_dataset\")\n",
    "make_obs_h5ad_safe_no_nullable_strings(Hao_dataset, \"Hao_dataset\")\n",
    "make_obs_h5ad_safe_no_nullable_strings(Triana_dataset, \"Triana_dataset\")\n",
    "make_obs_h5ad_safe_no_nullable_strings(Luecken_dataset, \"Luecken_dataset\")\n",
    "\n",
    "Zhang_dataset.write_h5ad(data_path + \"/References/Zhang\" + \"/Zhang_adata_annotated.h5ad\")\n",
    "Hao_dataset.write_h5ad(data_path + \"/References/Hao\" + \"/228AB_healthy_donors_PBMNCs_annotated.h5ad\")\n",
    "Triana_dataset.write_h5ad(data_path + \"/References/Triana\" + \"/97AB_young_and_old_adult_healthy_donor_BMMNCs_annotated.h5ad\")\n",
    "Luecken_dataset.write_h5ad(data_path + \"/References/Luecken\" + \"/140AB_adult_healthy_donor_BMMNCs_annotated.h5ad\")\n",
    "\n",
    "print(\"[INFO] Export complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "# ---------------------------\n",
    "# Output dir (fallback if not preset)\n",
    "# ---------------------------\n",
    "if \"figures_path\" not in globals():\n",
    "    figures_path = \"./figures\"\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "# ---------- Custom palette ----------\n",
    "custom_palette = {\n",
    "    'B Memory': \"#68D827\", 'B Naive': '#1C511D', 'CD14 Mono': \"#D27CE3\",\n",
    "    'CD16 Mono': \"#8D43CD\", 'CD4 T Memory': \"#C1AF93\", 'CD4 T Naive': \"#C99546\",\n",
    "    'CD8 T Memory': \"#6B3317\", 'CD8 T Naive': \"#4D382E\", 'ErP': \"#D1235A\",\n",
    "    'Erythroblast': \"#F30A1A\", 'GMP': \"#C5E4FF\", 'HSC': '#0079ea', 'MPP': \"#79b6ac\",\n",
    "    'Immature B': \"#91FF7B\", 'LMPP': \"#17BECF\", 'MAIT': \"#BCBD22\",\n",
    "    'Myeloid progenitor': \"#AEC7E8\", 'NK CD56 bright': \"#F3AC1F\",\n",
    "    'NK CD56 dim': \"#FBEF0D\", 'Plasma': \"#9DC012\", 'Pro-B': \"#66BB6A\",\n",
    "    'Small': \"#292929\", 'cDC1': \"#76A7CB\", 'cDC2': \"#16D2E3\", 'GdT': \"#EDB416\",\n",
    "    'pDC': \"#69FFCB\", 'CD4 CTL': \"#D7D2CB\", 'MEP': \"#E364B0\", 'Pre-B': \"#2DBD67\",\n",
    "    'Pre-Pro-B': '#92AC8E', 'EoBaMaP': \"#728245\", 'MkP': \"#69424D\",\n",
    "    'Stroma': \"#727272\", 'Macrophage': \"#5F4761\", 'ILC': \"#F7CF94\", 'DnT': \"#504423\",\n",
    "    'GdT_DnT': \"#B07A2A\",\n",
    "}\n",
    "fallback = \"#BBBBBB\"\n",
    "\n",
    "# ---------- Column to plot ----------\n",
    "col = \"Consensus_annotation_detailed_final\"\n",
    "\n",
    "# ---------- Labels to remove permanently ----------\n",
    "remove_labels = {\"Mesenchymal\", \"Platelet\", \"Macrophage\", \"ILC\", \"DnT\"}\n",
    "\n",
    "# =============================================================================\n",
    "# 0) PERMANENTLY DROP unwanted labels from ALL datasets used below\n",
    "#    (and from adatas_final if we derive global numbering from it)\n",
    "# =============================================================================\n",
    "def drop_labels_permanently(adata, dataset_name: str, col: str, remove_labels: set):\n",
    "    if col not in adata.obs:\n",
    "        raise KeyError(f\"[{dataset_name}] Column '{col}' not found in .obs\")\n",
    "\n",
    "    s = adata.obs[col].astype(\"object\")\n",
    "    mask_keep = ~s.isin(remove_labels)\n",
    "    removed_n = int((~mask_keep).sum())\n",
    "\n",
    "    if removed_n > 0:\n",
    "        present = sorted(set(s.dropna().unique()) & set(remove_labels))\n",
    "        print(\n",
    "            f\"[INFO] {dataset_name}: permanently removing {removed_n} cells with labels {present} \"\n",
    "            f\"using column '{col}'.\"\n",
    "        )\n",
    "        adata2 = adata[mask_keep].copy()\n",
    "        # clean unused categories\n",
    "        if pd.api.types.is_categorical_dtype(adata2.obs[col]):\n",
    "            adata2.obs[col] = adata2.obs[col].cat.remove_unused_categories()\n",
    "        return adata2\n",
    "\n",
    "    print(f\"[INFO] {dataset_name}: none of {sorted(remove_labels)} present in '{col}'. No filtering applied.\")\n",
    "    return adata\n",
    "\n",
    "# Permanently filter the per-dataset objects\n",
    "Zhang_dataset   = drop_labels_permanently(Zhang_dataset,   \"Zhang_dataset\",   col, remove_labels)\n",
    "Luecken_dataset = drop_labels_permanently(Luecken_dataset, \"Luecken_dataset\", col, remove_labels)\n",
    "Triana_dataset  = drop_labels_permanently(Triana_dataset,  \"Triana_dataset\",  col, remove_labels)\n",
    "Hao_dataset     = drop_labels_permanently(Hao_dataset,     \"Hao_dataset\",     col, remove_labels)\n",
    "\n",
    "# If we will derive global numbering from the integrated object, filter it permanently as well\n",
    "if (\"cats_global\" not in globals() or \"cat_to_num_global\" not in globals()) and (\"adatas_final\" in globals()):\n",
    "    adatas_final = drop_labels_permanently(adatas_final, \"adatas_final\", col, remove_labels)\n",
    "\n",
    "# =============================================================================\n",
    "# GLOBAL NUMBERING: derived from the integrated object if available.\n",
    "# This ensures every per-dataset plot uses the SAME numbering as the integrated plot.\n",
    "# Expect that you already ran the integrated plot code and have:\n",
    "#   - cats_global\n",
    "#   - cat_to_num_global\n",
    "# If not, we build them here from `adatas_final` (already filtered above).\n",
    "# =============================================================================\n",
    "if \"cats_global\" not in globals() or \"cat_to_num_global\" not in globals():\n",
    "    if \"adatas_final\" not in globals():\n",
    "        raise NameError(\n",
    "            \"Expected `cats_global`/`cat_to_num_global` from the integrated plot, or `adatas_final` to derive them.\"\n",
    "        )\n",
    "    if col not in adatas_final.obs:\n",
    "        raise KeyError(f\"[adatas_final] Column '{col}' not found in .obs\")\n",
    "\n",
    "    _plot_col_global = f\"{col}_plot\"\n",
    "    adatas_final.obs[_plot_col_global] = pd.Categorical(adatas_final.obs[col].astype(\"object\").astype(str))\n",
    "    cats_global = list(adatas_final.obs[_plot_col_global].cat.categories)\n",
    "    cat_to_num_global = {cat: i + 1 for i, cat in enumerate(cats_global)}\n",
    "\n",
    "    print(f\"[INFO] Built global numbering from adatas_final (n_categories={len(cats_global)}).\")\n",
    "\n",
    "def plot_numbered_umap(\n",
    "    adata,\n",
    "    dataset_name: str,\n",
    "    basis_key: str,\n",
    "    *,\n",
    "    col: str = col,\n",
    "    figures_path: str = figures_path,\n",
    "    custom_palette: dict = custom_palette,\n",
    "    fallback: str = fallback,\n",
    "    cats_global: list = cats_global,\n",
    "    cat_to_num_global: dict = cat_to_num_global,\n",
    "    figsize=(4, 3.5),\n",
    "    dpi=300,\n",
    "):\n",
    "    if col not in adata.obs:\n",
    "        raise KeyError(f\"[{dataset_name}] Column '{col}' not found in .obs\")\n",
    "\n",
    "    # ---- Ensure embedding exists\n",
    "    if basis_key not in adata.obsm_keys():\n",
    "        raise KeyError(f\"[{dataset_name}] Embedding '{basis_key}' not found in .obsm\")\n",
    "\n",
    "    # ---- Plot column with GLOBAL category order\n",
    "    plot_col = f\"{col}_plot\"\n",
    "\n",
    "    adata.obs[plot_col] = adata.obs[col].astype(\"object\").astype(str)\n",
    "    adata.obs[plot_col] = pd.Categorical(adata.obs[plot_col], categories=cats_global, ordered=True)\n",
    "\n",
    "    # ---- Drop cells not in global set (keeps numbering stable)\n",
    "    unknown_mask = adata.obs[plot_col].isna()\n",
    "    n_unknown = int(unknown_mask.sum())\n",
    "    if n_unknown > 0:\n",
    "        unknown_vals = sorted(set(adata.obs[col].astype(\"object\").astype(str)[unknown_mask].unique().tolist()))\n",
    "        print(\n",
    "            f\"[WARN] {dataset_name}: dropping {n_unknown} cells with labels not in global set \"\n",
    "            f\"(sample: {unknown_vals[:10]})\"\n",
    "        )\n",
    "        adata = adata[~unknown_mask].copy()\n",
    "\n",
    "    # ---- Color alignment (GLOBAL order)\n",
    "    adata.uns[f\"{plot_col}_colors\"] = [custom_palette.get(cat, fallback) for cat in cats_global]\n",
    "\n",
    "    # ---- Centroids (GLOBAL order; some cats may be absent in this dataset)\n",
    "    coords = adata.obsm[basis_key][:, :2]\n",
    "    df = pd.DataFrame(coords, columns=[\"UMAP1\", \"UMAP2\"], index=adata.obs_names)\n",
    "    df[plot_col] = adata.obs[plot_col].astype(str)\n",
    "\n",
    "    centroids = (\n",
    "        df.groupby(plot_col)[[\"UMAP1\", \"UMAP2\"]]\n",
    "          .mean()\n",
    "          .reindex(cats_global)\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    # ---- Plot\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "\n",
    "    sc.pl.embedding(\n",
    "        adata,\n",
    "        color=plot_col,\n",
    "        basis=basis_key,\n",
    "        title=\"\",\n",
    "        legend_loc=None,\n",
    "        outline_width=(0.8, 0.05),\n",
    "        add_outline=True,\n",
    "        size=3,\n",
    "        frameon=False,\n",
    "        show=False,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_aspect(\"auto\")\n",
    "\n",
    "    # ---- Numbered centroid circles (GLOBAL numbering)\n",
    "    for _, row in centroids.iterrows():\n",
    "        label = row[plot_col]\n",
    "        if pd.isna(row[\"UMAP1\"]) or pd.isna(row[\"UMAP2\"]):\n",
    "            continue\n",
    "\n",
    "        color = custom_palette.get(label, fallback)\n",
    "        num = cat_to_num_global[label]\n",
    "\n",
    "        ax.scatter(\n",
    "            row[\"UMAP1\"], row[\"UMAP2\"],\n",
    "            s=160, facecolor=color, edgecolor=\"black\",\n",
    "            alpha=0.6, linewidth=1, zorder=10\n",
    "        )\n",
    "\n",
    "        txt = ax.text(\n",
    "            row[\"UMAP1\"], row[\"UMAP2\"], str(num),\n",
    "            ha=\"center\", va=\"center\",\n",
    "            fontsize=6.5, color=\"white\", weight=\"bold\", zorder=11\n",
    "        )\n",
    "        txt.set_path_effects([PathEffects.withStroke(linewidth=1.1, foreground=\"black\")])\n",
    "\n",
    "    plt.tight_layout(pad=0.2)\n",
    "\n",
    "    # ---- Save\n",
    "    out_png = os.path.join(figures_path, f\"{dataset_name}_annotation_plot.png\")\n",
    "    out_pdf = os.path.join(figures_path, f\"{dataset_name}_annotation_plot.pdf\")\n",
    "    fig.savefig(out_png, dpi=dpi, bbox_inches=\"tight\", transparent=True)\n",
    "    fig.savefig(out_pdf, dpi=dpi, bbox_inches=\"tight\", transparent=True)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"[INFO] Saved {dataset_name}:\")\n",
    "    print(\" -\", out_png)\n",
    "    print(\" -\", out_pdf)\n",
    "\n",
    "# =============================================================================\n",
    "# Run for each dataset with your requested embeddings\n",
    "# =============================================================================\n",
    "plot_numbered_umap(Zhang_dataset,   dataset_name=\"Zhang_dataset\",   basis_key=\"X_umap\")\n",
    "plot_numbered_umap(Luecken_dataset, dataset_name=\"Luecken_dataset\", basis_key=\"X_umap\")\n",
    "plot_numbered_umap(Triana_dataset,  dataset_name=\"Triana_dataset\",  basis_key=\"X_mofaumap\")\n",
    "plot_numbered_umap(Hao_dataset,     dataset_name=\"Hao_dataset\",     basis_key=\"X_wnn.umap\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaic_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
