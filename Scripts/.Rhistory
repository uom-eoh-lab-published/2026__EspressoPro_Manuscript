plot.title = "Calibration Set",
border.size = 5,
border.density = 1,
font.size = 14
)
combined_plot <- p1 | p2
print(combined_plot)
ggsave(here("Figures/Partitioning/Hao_train_cal_umap.png"),
combined_plot, width = 12, height = 6, dpi = 300, bg = "white")
png(here("Figures/Partitioning/Hao_train_cal_correlation.png"),
width = 11, height = 11, units = "in", res = 300, bg = "white")
ht <- validate_split_correlation(
hao_splits$train,
hao_splits$cal,
label_cols["detailed"],
hao_config$assay,
title = "Hao: Train vs Calibration Expression Correlation"
)
draw(ht, heatmap_legend_side = "bottom")
dev.off()
draw(ht, heatmap_legend_side = "bottom")
save_splits_h5ad(
hao_splits,
"Hao",
hao_config$input,
here("Data/References/Hao"),
hao_config$assay
)
cat("\n✓ Saved h5ad split files\n")
for (depth_name in names(label_cols)) {
label_col <- label_cols[depth_name]
cat(sprintf("\n--- Generating barcodes for %s level ---\n", depth_name))
cat("\nTraining set (balanced):\n")
train_barcodes <- generate_ovr_barcodes(
hao_splits$train, label_col, hao_config$assay,
is_test = FALSE, seed = params$seed,
use_seurat_sketch = params$use_seurat_sketch
)
save_ovr_barcodes(
train_barcodes,
here("Data/Training_barcodes/Hao", label_col),
prefix = "training"
)
cat("\nTest set (unbalanced):\n")
test_barcodes <- generate_ovr_barcodes(
hao_splits$test, label_col, hao_config$assay,
is_test = TRUE, seed = params$seed,
use_seurat_sketch = params$use_seurat_sketch
)
save_ovr_barcodes(
test_barcodes,
here("Data/Testing_barcodes/Hao", label_col),
prefix = "testing"
)
}
cat("\n✓✓✓ Hao atlas processing complete ✓✓✓\n")
cat("\n╔═══════════════════════════════════════════════════╗\n")
cat("║             PROCESSING TRIANA ATLAS               ║\n")
cat("╚═══════════════════════════════════════════════════╝\n\n")
triana_config <- config$Triana
triana_obj <- convertFormat(
obj = here(triana_config$input),
from = "anndata",
to = "seurat",
assay = triana_config$assay,
main_layer = "counts"
)
cat(sprintf("✓ Loaded: %s cells, %s features\n",
comma(ncol(triana_obj)),
comma(nrow(triana_obj))))
triana_obj <- preprocess_object(
triana_obj,
label_col = label_cols["detailed"],
merge_labels = triana_config$merge_labels,
min_cells = params$min_cells
)
cat(sprintf("✓ After filtering: %s cells, %d classes\n",
comma(ncol(triana_obj)),
length(unique(triana_obj[[label_cols["detailed"]]][, 1]))))
triana_splits <- two_stage_split(
triana_obj,
label_col = label_cols["detailed"],
assay = triana_config$assay,
train_prop = params$train_split,
cal_prop = params$cal_split,
seed = params$seed,
use_seurat_sketch = params$use_seurat_sketch
)
cat(sprintf("\n✓ Split complete:\n"))
cat(sprintf("  Train: %s cells\n", comma(ncol(triana_splits$train))))
cat(sprintf("  Cal:   %s cells\n", comma(ncol(triana_splits$cal))))
cat(sprintf("  Test:  %s cells\n", comma(ncol(triana_splits$test))))
overlap_stats <- validate_partition_overlap(triana_splits)
knitr::kable(overlap_stats,
caption = "Triana: Partition Overlap Validation",
digits = 2,
align = 'c')
if (all(overlap_stats$Overlap_N == 0)) {
cat("\n✓ No overlap detected between partitions\n")
}
p1 <- SCpubr::do_DimPlot(
sample = triana_splits$train,
group.by = label_cols["detailed"],
reduction = triana_config$reduction,
colors.use = custom_palette,
pt.size = 0.5,
legend.position = "none",
plot.title = "Training Set",
border.size = 5,
border.density = 1,
font.size = 14
)
p2 <- SCpubr::do_DimPlot(
sample = triana_splits$test,
group.by = label_cols["detailed"],
reduction = triana_config$reduction,
colors.use = custom_palette,
pt.size = 0.5,
legend.position = "none",
plot.title = "Test Set",
border.size = 5,
border.density = 1,
font.size = 14
)
combined_plot <- p1 | p2
print(combined_plot)
ggsave(here("Figures/Partitioning/Triana_train_test_umap.png"),
combined_plot, width = 12, height = 6, dpi = 300, bg = "white")
png(here("Figures/Partitioning/Triana_train_test_correlation.png"),
width = 11, height = 11, units = "in", res = 300, bg = "white")
ht <- validate_split_correlation(
triana_splits$train,
triana_splits$test,
label_cols["detailed"],
triana_config$assay,
title = "Triana: Train vs Test Expression Correlation"
)
draw(ht, heatmap_legend_side = "bottom")
dev.off()
draw(ht, heatmap_legend_side = "bottom")
p1 <- SCpubr::do_DimPlot(
sample = triana_splits$train,
group.by = label_cols["detailed"],
reduction = triana_config$reduction,
colors.use = custom_palette,
pt.size = 0.5,
legend.position = "none",
plot.title = "Training Set",
border.size = 5,
border.density = 1,
font.size = 14
)
p2 <- SCpubr::do_DimPlot(
sample = triana_splits$cal,
group.by = label_cols["detailed"],
reduction = triana_config$reduction,
colors.use = custom_palette,
pt.size = 0.5,
legend.position = "none",
plot.title = "Calibration Set",
border.size = 5,
border.density = 1,
font.size = 14
)
combined_plot <- p1 | p2
print(combined_plot)
ggsave(here("Figures/Partitioning/Triana_train_cal_umap.png"),
combined_plot, width = 12, height = 6, dpi = 300, bg = "white")
png(here("Figures/Partitioning/Triana_train_cal_correlation.png"),
width = 11, height = 11, units = "in", res = 300, bg = "white")
ht <- validate_split_correlation(
triana_splits$train,
triana_splits$cal,
label_cols["detailed"],
triana_config$assay,
title = "Triana: Train vs Calibration Expression Correlation"
)
draw(ht, heatmap_legend_side = "bottom")
dev.off()
draw(ht, heatmap_legend_side = "bottom")
save_splits_h5ad(
triana_splits,
"Triana",
triana_config$input,
here("Data/References/Triana"),
triana_config$assay
)
cat("\n✓ Saved h5ad split files\n")
for (depth_name in names(label_cols)) {
label_col <- label_cols[depth_name]
cat(sprintf("\n--- Generating barcodes for %s level ---\n", depth_name))
cat("\nTraining set (balanced):\n")
train_barcodes <- generate_ovr_barcodes(
triana_splits$train, label_col, triana_config$assay,
is_test = FALSE, seed = params$seed,
use_seurat_sketch = params$use_seurat_sketch
)
save_ovr_barcodes(
train_barcodes,
here("Data/Training_barcodes/Triana", label_col),
prefix = "training"
)
cat("\nTest set (unbalanced):\n")
test_barcodes <- generate_ovr_barcodes(
triana_splits$test, label_col, triana_config$assay,
is_test = TRUE, seed = params$seed,
use_seurat_sketch = params$use_seurat_sketch
)
save_ovr_barcodes(
test_barcodes,
here("Data/Testing_barcodes/Triana", label_col),
prefix = "testing"
)
}
cat("\n✓✓✓ Triana atlas processing complete ✓✓✓\n")
cat("\n╔═══════════════════════════════════════════════════╗\n")
cat("║            PROCESSING LUECKEN ATLAS               ║\n")
cat("╚═══════════════════════════════════════════════════╝\n\n")
luecken_config <- config$Luecken
luecken_obj <- convertFormat(
obj = here(luecken_config$input),
from = "anndata",
to = "seurat",
assay = luecken_config$assay,
main_layer = "counts"
)
cat(sprintf("✓ Loaded: %s cells, %s features\n",
comma(ncol(luecken_obj)),
comma(nrow(luecken_obj))))
luecken_obj <- preprocess_object(
luecken_obj,
label_col = label_cols["detailed"],
merge_labels = luecken_config$merge_labels,
min_cells = params$min_cells
)
cat(sprintf("✓ After filtering: %s cells, %d classes\n",
comma(ncol(luecken_obj)),
length(unique(luecken_obj[[label_cols["detailed"]]][, 1]))))
luecken_splits <- two_stage_split(
luecken_obj,
label_col = label_cols["detailed"],
assay = luecken_config$assay,
train_prop = params$train_split,
cal_prop = params$cal_split,
seed = params$seed,
use_seurat_sketch = params$use_seurat_sketch
)
cat(sprintf("\n✓ Split complete:\n"))
cat(sprintf("  Train: %s cells\n", comma(ncol(luecken_splits$train))))
cat(sprintf("  Cal:   %s cells\n", comma(ncol(luecken_splits$cal))))
cat(sprintf("  Test:  %s cells\n", comma(ncol(luecken_splits$test))))
overlap_stats <- validate_partition_overlap(luecken_splits)
knitr::kable(overlap_stats,
caption = "Luecken: Partition Overlap Validation",
digits = 2,
align = 'c')
if (all(overlap_stats$Overlap_N == 0)) {
cat("\n✓ No overlap detected between partitions\n")
}
p1 <- SCpubr::do_DimPlot(
sample = luecken_splits$train,
group.by = label_cols["detailed"],
reduction = luecken_config$reduction,
colors.use = custom_palette,
pt.size = 0.5,
legend.position = "none",
plot.title = "Training Set",
border.size = 5,
border.density = 1,
font.size = 14
)
p2 <- SCpubr::do_DimPlot(
sample = luecken_splits$test,
group.by = label_cols["detailed"],
reduction = luecken_config$reduction,
colors.use = custom_palette,
pt.size = 0.5,
legend.position = "none",
plot.title = "Test Set",
border.size = 5,
border.density = 1,
font.size = 14
)
combined_plot <- p1 | p2
print(combined_plot)
ggsave(here("Figures/Partitioning/Luecken_train_test_umap.png"),
combined_plot, width = 12, height = 6, dpi = 300, bg = "white")
png(here("Figures/Partitioning/Luecken_train_test_correlation.png"),
width = 11, height = 11, units = "in", res = 300, bg = "white")
ht <- validate_split_correlation(
luecken_splits$train,
luecken_splits$test,
label_cols["detailed"],
luecken_config$assay,
title = "Luecken: Train vs Test Expression Correlation"
)
draw(ht, heatmap_legend_side = "bottom")
dev.off()
draw(ht, heatmap_legend_side = "bottom")
p1 <- SCpubr::do_DimPlot(
sample = luecken_splits$train,
group.by = label_cols["detailed"],
reduction = luecken_config$reduction,
colors.use = custom_palette,
pt.size = 0.5,
legend.position = "none",
plot.title = "Training Set",
border.size = 5,
border.density = 1,
font.size = 14
)
p2 <- SCpubr::do_DimPlot(
sample = luecken_splits$cal,
group.by = label_cols["detailed"],
reduction = luecken_config$reduction,
colors.use = custom_palette,
pt.size = 0.5,
legend.position = "none",
plot.title = "Calibration Set",
border.size = 5,
border.density = 1,
font.size = 14
)
combined_plot <- p1 | p2
print(combined_plot)
ggsave(here("Figures/Partitioning/Luecken_train_cal_umap.png"),
combined_plot, width = 12, height = 6, dpi = 300, bg = "white")
png(here("Figures/Partitioning/Luecken_train_cal_correlation.png"),
width = 11, height = 11, units = "in", res = 300, bg = "white")
ht <- validate_split_correlation(
luecken_splits$train,
luecken_splits$cal,
label_cols["detailed"],
luecken_config$assay,
title = "Luecken: Train vs Calibration Expression Correlation"
)
draw(ht, heatmap_legend_side = "bottom")
dev.off()
draw(ht, heatmap_legend_side = "bottom")
save_splits_h5ad(
luecken_splits,
"Luecken",
luecken_config$input,
here("Data/References/Luecken"),
luecken_config$assay
)
cat("\n✓ Saved h5ad split files\n")
for (depth_name in names(label_cols)) {
label_col <- label_cols[depth_name]
cat(sprintf("\n--- Generating barcodes for %s level ---\n", depth_name))
cat("\nTraining set (balanced):\n")
train_barcodes <- generate_ovr_barcodes(
luecken_splits$train, label_col, luecken_config$assay,
is_test = FALSE, seed = params$seed,
use_seurat_sketch = params$use_seurat_sketch
)
save_ovr_barcodes(
train_barcodes,
here("Data/Training_barcodes/Luecken", label_col),
prefix = "training"
)
cat("\nTest set (unbalanced):\n")
test_barcodes <- generate_ovr_barcodes(
luecken_splits$test, label_col, luecken_config$assay,
is_test = TRUE, seed = params$seed,
use_seurat_sketch = params$use_seurat_sketch
)
save_ovr_barcodes(
test_barcodes,
here("Data/Testing_barcodes/Luecken", label_col),
prefix = "testing"
)
}
cat("\n✓✓✓ Luecken atlas processing complete ✓✓✓\n")
summary_df <- tibble(
Atlas = names(config),
Train_Cells = c(ncol(zhang_splits$train), ncol(hao_splits$train),
ncol(triana_splits$train), ncol(luecken_splits$train)),
Cal_Cells = c(ncol(zhang_splits$cal), ncol(hao_splits$cal),
ncol(triana_splits$cal), ncol(luecken_splits$cal)),
Test_Cells = c(ncol(zhang_splits$test), ncol(hao_splits$test),
ncol(triana_splits$test), ncol(luecken_splits$test)),
Train_Classes = c(
length(unique(zhang_splits$train[[label_cols["detailed"]]][, 1])),
length(unique(hao_splits$train[[label_cols["detailed"]]][, 1])),
length(unique(triana_splits$train[[label_cols["detailed"]]][, 1])),
length(unique(luecken_splits$train[[label_cols["detailed"]]][, 1]))
),
Cal_Classes = c(
length(unique(zhang_splits$cal[[label_cols["detailed"]]][, 1])),
length(unique(hao_splits$cal[[label_cols["detailed"]]][, 1])),
length(unique(triana_splits$cal[[label_cols["detailed"]]][, 1])),
length(unique(luecken_splits$cal[[label_cols["detailed"]]][, 1]))
),
Test_Classes = c(
length(unique(zhang_splits$test[[label_cols["detailed"]]][, 1])),
length(unique(hao_splits$test[[label_cols["detailed"]]][, 1])),
length(unique(triana_splits$test[[label_cols["detailed"]]][, 1])),
length(unique(luecken_splits$test[[label_cols["detailed"]]][, 1]))
)
) %>%
mutate(
Total_Cells = Train_Cells + Cal_Cells + Test_Cells,
Train_Pct = sprintf("%.1f%%", Train_Cells / Total_Cells * 100),
Cal_Pct = sprintf("%.1f%%", Cal_Cells / Total_Cells * 100),
Test_Pct = sprintf("%.1f%%", Test_Cells / Total_Cells * 100)
)
knitr::kable(summary_df,
caption = "Dataset Split Summary (Detailed Annotation Level)",
format.args = list(big.mark = ","),
align = 'c')
# Prepare data for visualization
partition_data <- summary_df %>%
select(Atlas, Train_Cells, Cal_Cells, Test_Cells) %>%
pivot_longer(cols = -Atlas, names_to = "Partition", values_to = "Cells") %>%
mutate(
Partition = str_remove(Partition, "_Cells"),
Partition = factor(Partition, levels = c("Train", "Cal", "Test"))
)
# Stacked bar chart
p1 <- ggplot(partition_data, aes(x = Atlas, y = Cells, fill = Partition)) +
geom_bar(stat = "identity", color = "black", size = 0.3) +
scale_fill_manual(values = c("Train" = "#4CAF50", "Cal" = "#FFC107", "Test" = "#2196F3")) +
labs(title = "Partition Size Distribution",
y = "Number of Cells",
x = NULL) +
theme_minimal(base_size = 14) +
theme(
plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
legend.position = "top",
panel.grid.minor = element_blank()
) +
scale_y_continuous(labels = comma)
# Proportional bar chart
p2 <- ggplot(partition_data, aes(x = Atlas, y = Cells, fill = Partition)) +
geom_bar(stat = "identity", position = "fill", color = "black", size = 0.3) +
scale_fill_manual(values = c("Train" = "#4CAF50", "Cal" = "#FFC107", "Test" = "#2196F3")) +
labs(title = "Partition Proportions",
y = "Proportion",
x = NULL) +
theme_minimal(base_size = 14) +
theme(
plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
legend.position = "top",
panel.grid.minor = element_blank()
) +
scale_y_continuous(labels = percent)
combined <- p1 / p2
print(combined)
ggsave(here("Figures/Partitioning/Partition_distribution_summary.png"),
combined, width = 12, height = 8, dpi = 300, bg = "white")
all_overlaps <- bind_rows(
validate_partition_overlap(zhang_splits) %>% mutate(Atlas = "Zhang"),
validate_partition_overlap(hao_splits) %>% mutate(Atlas = "Hao"),
validate_partition_overlap(triana_splits) %>% mutate(Atlas = "Triana"),
validate_partition_overlap(luecken_splits) %>% mutate(Atlas = "Luecken")
) %>%
select(Atlas, everything())
knitr::kable(all_overlaps,
caption = "Partition Overlap Summary (All Atlases)",
digits = 2,
align = 'c')
# Final validation
if (all(all_overlaps$Overlap_N == 0)) {
cat("\n╔═══════════════════════════════════════════════════╗\n")
cat("║                                                   ║\n")
cat("║   ✓✓✓ SUCCESS: ALL PARTITIONS VALIDATED ✓✓✓     ║\n")
cat("║                                                   ║\n")
cat("║   • 0% overlap across all atlases                ║\n")
cat("║   • Train/Test/Cal splits completed              ║\n")
cat("║   • OVR barcodes generated                       ║\n")
cat("║   • All files saved successfully                 ║\n")
cat("║                                                   ║\n")
cat("╚═══════════════════════════════════════════════════╝\n")
} else {
cat("\n⚠️  WARNING: OVERLAP DETECTED IN PARTITIONS ⚠️\n")
cat("Please review the overlap statistics above.\n")
}
cat("\n╔═══════════════════════════════════════════════════╗\n")
cat("║              OUTPUT FILES GENERATED               ║\n")
cat("╚═══════════════════════════════════════════════════╝\n\n")
cat("H5AD Split Files:\n")
for (atlas in names(config)) {
cat(sprintf("  %s/\n", atlas))
cat(sprintf("    ├─ %s_train.h5ad\n", atlas))
cat(sprintf("    ├─ %s_cal.h5ad\n", atlas))
cat(sprintf("    └─ %s_test.h5ad\n\n", atlas))
}
cat("OVR Barcode Files (per annotation level):\n")
for (atlas in names(config)) {
cat(sprintf("  %s/\n", atlas))
for (depth in names(label_cols)) {
cat(sprintf("    └─ %s/\n", depth))
cat("       ├─ training_*.csv (balanced)\n")
cat("       └─ testing_*.csv (unbalanced)\n")
}
cat("\n")
}
cat("Visualization Files:\n")
cat("  Figures/Partitioning/\n")
cat("    ├─ *_train_test_umap.png (no legend)\n")
cat("    ├─ *_train_cal_umap.png (no legend)\n")
cat("    ├─ *_train_test_correlation.png (bottom legend)\n")
cat("    ├─ *_train_cal_correlation.png (bottom legend)\n")
cat("    └─ Partition_distribution_summary.png\n\n")
cat("═══════════════════════════════════════════════════\n")
cat("\n╔═══════════════════════════════════════════════════╗\n")
cat("║              SESSION INFORMATION                  ║\n")
cat("╚═══════════════════════════════════════════════════╝\n\n")
sessionInfo()
library(usethis)
usethis::edit_r_environ()
